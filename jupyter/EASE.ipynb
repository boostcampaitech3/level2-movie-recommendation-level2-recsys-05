{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ug-br-pPu9vZ"},"outputs":[],"source":["import math\n","import numpy as np\n","import scipy.sparse as sp\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import defaultdict\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from box import Box\n","\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","torch.set_printoptions(sci_mode=True)"]},{"cell_type":"markdown","metadata":{"id":"pbRKDSg4u9vc"},"source":["# 1. 학습 설정"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MEhK_fLIu9vd"},"outputs":[],"source":["config = {\n","    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n","    \n","    'submission_path' : \"../submission\",\n","    'submission_name' : 'EASE_v1_submission.csv',\n","\n","    'valid_samples' : 10, # 검증에 사용할 sample 수\n","    'seed' : 22,\n","    'reg' : 0.001,\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","config = Box(config)"]},{"cell_type":"markdown","metadata":{"id":"wjDxy0fJu9vf"},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"W64BYWl0u9vg"},"outputs":[],"source":["class MakeMatrixDataSet():\n","    \"\"\"\n","    MatrixDataSet 생성\n","    \"\"\"\n","    def __init__(self, config):\n","        self.config = config\n","        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n","        \n","        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n","        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n","        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n","\n","        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n","        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n","\n","        self.user_train, self.user_valid = self.generate_sequence_data()\n","\n","    def generate_encoder_decoder(self, col : str) -> dict:\n","        \"\"\"\n","        encoder, decoder 생성\n","\n","        Args:\n","            col (str): 생성할 columns 명\n","        Returns:\n","            dict: 생성된 user encoder, decoder\n","        \"\"\"\n","\n","        encoder = {}\n","        decoder = {}\n","        ids = self.df[col].unique()\n","\n","        for idx, _id in enumerate(ids):\n","            encoder[_id] = idx\n","            decoder[idx] = _id\n","\n","        return encoder, decoder\n","    \n","    def generate_sequence_data(self) -> dict:\n","        \"\"\"\n","        sequence_data 생성\n","\n","        Returns:\n","            dict: train user sequence / valid user sequence\n","        \"\"\"\n","        users = defaultdict(list)\n","        user_train = {}\n","        user_valid = {}\n","        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n","            users[user].append(item)\n","        \n","        for user in users:\n","            np.random.seed(self.config.seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            user_train[user] = train\n","            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n","\n","        return user_train, user_valid\n","    \n","    def get_train_valid_data(self):\n","        return self.user_train, self.user_valid\n","\n","    def make_matrix(self, user_list, train = True):\n","        \"\"\"\n","        user_item_dict를 바탕으로 행렬 생성\n","        \"\"\"\n","        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n","        for idx, user in enumerate(user_list):\n","            if train:\n","                mat[idx, self.user_train[user.item()]] = 1\n","            else:\n","                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n","        return mat\n","\n","    def make_sparse_matrix(self, test = False):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        for user in self.user_train.keys():\n","            item_list = self.user_train[user]\n","            for item in item_list:\n","                X[user, item] = 1.0\n","        \n","        if test:\n","            for user in self.user_valid.keys():\n","                item_list = self.user_valid[user]\n","                for item in item_list:\n","                    X[user, item] = 1.0\n","\n","        return X.tocsr()\n","    \n","\n","    def make_candidate_item(self, train = True):\n","        user_pro_df = pd.read_csv(os.path.join(self.config.data_path, 'user_pro.csv'))\n","        item_pro_df = pd.read_csv(os.path.join(self.config.data_path, 'item_pro.csv'))\n","\n","        item_pro_df['item'] = item_pro_df['item'].apply(lambda x : self.item_encoder[x])\n","        item_pro_df['year'] = item_pro_df['year'].astype(int)\n","\n","        user_pro_df['user'] = user_pro_df['user'].apply(lambda x : self.user_encoder[x])\n","        user_pro_df['max_year'] = user_pro_df['max_year'].astype(int)\n","        \n","        year2item_list = {}\n","        year_list = user_pro_df['max_year'].unique().tolist()\n","        for year in year_list:\n","            item_list = item_pro_df[item_pro_df['year'] <= year + 1]['item'].tolist()\n","            year2item_list[year + 1] = item_list\n","\n","        all_item_list = [i for i in range(self.num_item)]\n","        group_df = user_pro_df.groupby('user')\n","        candidate = {}\n","        if train:\n","            for user, df in group_df:\n","                max_year = df['max_year'].values[0]\n","                candidate_item_list = year2item_list[max_year + 1]\n","                candidate_item_list = set(all_item_list) - set(candidate_item_list)\n","                candidate_item_list = list(candidate_item_list | set(self.user_train[user]))\n","                candidate[user] = candidate_item_list\n","        else:\n","            for user, df in group_df:\n","                max_year = df['max_year'].values[0]\n","                candidate_item_list = year2item_list[max_year + 1]\n","                candidate_item_list = set(all_item_list) - set(candidate_item_list)\n","                candidate_item_list = candidate_item_list | set(self.user_train[user])\n","                candidate_item_list = list(candidate_item_list | set(self.user_valid[user]))\n","                candidate[user] = candidate_item_list\n","\n","        return candidate\n","\n","    def m_s_m(self, candidate):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        for user in candidate.keys():\n","            item_list = candidate[user]\n","            X[user, item_list] = 1.0\n","\n","        return X"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"IldCGmY8u9vh"},"outputs":[],"source":["class AEDataSet(Dataset):\n","    def __init__(self, num_user):\n","        self.num_user = num_user\n","        self.users = [i for i in range(num_user)]\n","\n","    def __len__(self):\n","        return self.num_user\n","\n","    def __getitem__(self, idx): \n","        user = self.users[idx]\n","        return torch.LongTensor([user])"]},{"cell_type":"markdown","metadata":{"id":"ysia457Su9vi"},"source":["# 3. 모델"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"TVXWUTLpSh8_"},"outputs":[],"source":["class EASE():\n","    def __init__(self, X, reg):\n","        self.X = self._convert_sp_mat_to_sp_tensor(X)\n","        self.reg = reg\n","    \n","    def _convert_sp_mat_to_sp_tensor(self, X):\n","        \"\"\"\n","        Convert scipy sparse matrix to PyTorch sparse matrix\n","\n","        Arguments:\n","        ----------\n","        X = Adjacency matrix, scipy sparse matrix\n","        \"\"\"\n","        coo = X.tocoo().astype(np.float32)\n","        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n","        v = torch.FloatTensor(coo.data)\n","        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n","        return res\n","    \n","    def fit(self):\n","        '''\n","\n","        진짜 정말 간단한 식으로 모델을 만듬\n","\n","        '''\n","        G = self.X.to_dense().t() @ self.X.to_dense()\n","        diagIndices = torch.eye(G.shape[0]) == 1\n","        G[diagIndices] += self.reg\n","\n","        P = G.inverse()\n","        B = P / (-1 * P.diag())\n","        B[diagIndices] = 0\n","\n","        self.pred = self.X.to_dense() @ B"]},{"cell_type":"markdown","metadata":{"id":"GwSexh43u9vk"},"source":["# 4. 학습 함수"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"nws4JO2_rgQP"},"outputs":[],"source":["def get_ndcg(pred_list, true_list):\n","    ndcg = 0\n","    for rank, pred in enumerate(pred_list):\n","        if pred in true_list:\n","            ndcg += 1 / np.log2(rank + 2)\n","    return ndcg\n","\n","# hit == recall == precision\n","def get_hit(pred_list, true_list):\n","    hit_list = set(true_list) & set(pred_list)\n","    hit = len(hit_list) / len(true_list)\n","    return hit\n","\n","def evaluate(model, X, user_train, user_valid):\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat = model.pred.cpu()\n","    score = recon_mat * torch.from_numpy(1 - X.todense())\n","    rec_list = score.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        uv = user_valid[user]\n","        up = rec[-10:].cpu().numpy().tolist()\n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(rec_list)\n","    HIT /= len(rec_list)\n","\n","    return NDCG, HIT\n","\n","\n","def predict(model, X):\n","    user2rec = {}\n","\n","    recon_mat = model.pred.cpu()\n","    score = recon_mat * torch.from_numpy(1 - X.todense())\n","    rec_list = score.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        up = rec[-10:].cpu().numpy().tolist()\n","        user2rec[user] = up\n","    \n","    return user2rec"]},{"cell_type":"markdown","metadata":{"id":"gupkaJHMslCi"},"source":["# 5. 학습"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"HFOr6Wmbq9pW"},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n","X = make_matrix_data_set.make_sparse_matrix()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"mzhvIGPhrYov"},"outputs":[],"source":["model = EASE(X = X, reg = config.reg)\n","model.fit()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["candidate = make_matrix_data_set.make_candidate_item(train = True)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["new_X = make_matrix_data_set.m_s_m(candidate)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1103,"status":"ok","timestamp":1648373220204,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"D1yj8M7bsp6X","outputId":"20892967-6ca0-41b3-fa29-56ab76c92c0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.69471| HIT@10: 0.17233\n"]}],"source":["ndcg, hit = evaluate(model = model, X = new_X, user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.69426| HIT@10: 0.17225\n"]}],"source":["ndcg, hit = evaluate(model = model, X = X, user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["# 6. 예측"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["X_test = make_matrix_data_set.make_sparse_matrix(test = True)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["model = EASE(X = X_test, reg = config.reg)\n","model.fit()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["user2rec_list = predict(\n","    model = model, \n","    X = X_test,\n","    )\n","\n","submision = []\n","users = [i for i in range(0, make_matrix_data_set.num_user)]\n","for user in users:\n","    rec_item_list = user2rec_list[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>5010</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>3081</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>3996</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>32587</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>4886</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>313595</th>\n","      <td>138493</td>\n","      <td>1704</td>\n","    </tr>\n","    <tr>\n","      <th>313596</th>\n","      <td>138493</td>\n","      <td>1270</td>\n","    </tr>\n","    <tr>\n","      <th>313597</th>\n","      <td>138493</td>\n","      <td>8970</td>\n","    </tr>\n","    <tr>\n","      <th>313598</th>\n","      <td>138493</td>\n","      <td>110</td>\n","    </tr>\n","    <tr>\n","      <th>313599</th>\n","      <td>138493</td>\n","      <td>2628</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>313600 rows × 2 columns</p>\n","</div>"],"text/plain":["          user   item\n","0           11   5010\n","1           11   3081\n","2           11   3996\n","3           11  32587\n","4           11   4886\n","...        ...    ...\n","313595  138493   1704\n","313596  138493   1270\n","313597  138493   8970\n","313598  138493    110\n","313599  138493   2628\n","\n","[313600 rows x 2 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["submision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMB0K8DmOwclQIFyyBerAFJ","collapsed_sections":[],"mount_file_id":"1C1AHkN-z-DCxUIAjFfd7K56P-8-YrAJO","name":"EASE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
