{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ug-br-pPu9vZ"},"outputs":[],"source":["import math\n","import numpy as np\n","import scipy.sparse as sp\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import defaultdict\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from box import Box\n","\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","torch.set_printoptions(sci_mode=True)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class GMF(nn.Module):\n","    def __init__(self, num_user, num_item, num_factor):\n","        super(GMF, self).__init__()\n","        self.user_emb = nn.Embedding(num_user, num_factor)\n","        self.item_emb = nn.Embedding(num_item, num_factor)\n","        \n","        self.predict_layer = nn.Sequential(\n","            nn.Linear(num_factor, 1, bias = False)\n","        )\n","\n","        self._init_weight_()\n","    \n","    def _init_weight_(self):\n","        nn.init.normal_(self.user_emb.weight, std=0.01)\n","        nn.init.normal_(self.item_emb.weight, std=0.01)\n","        for m in self.predict_layer:\n","            if isinstance(m, nn.Linear):\n","                nn.init.kaiming_uniform_(m.weight, a=1)\n","    \n","    def forward(self, user, item):\n","        user_emb = self.user_emb(user)\n","        item_emb = self.item_emb(item)\n","\n","        output = self.predict_layer(user_emb * item_emb)\n","\n","        return output.view(-1)"]},{"cell_type":"markdown","metadata":{"id":"pbRKDSg4u9vc"},"source":["# 1. 학습 설정"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"MEhK_fLIu9vd"},"outputs":[],"source":["config = {\n","    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n","    'model_path' : \"../model\",\n","    \n","    'submission_path' : \"../submission\",\n","    'submission_name' : 'EASE_v3_submission.csv',\n","\n","    'candidate_item_num' : 5,\n","    'valid_samples' : 10, # 검증에 사용할 sample 수\n","    'seed' : 22,\n","    'reg' : 1000,\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","config = Box(config)"]},{"cell_type":"markdown","metadata":{"id":"wjDxy0fJu9vf"},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"W64BYWl0u9vg"},"outputs":[],"source":["class MakeMatrixDataSet():\n","    \"\"\"\n","    MatrixDataSet 생성\n","    \"\"\"\n","    def __init__(self, config):\n","        self.config = config\n","        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n","        \n","        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n","        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n","        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n","\n","        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n","        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n","\n","        self.user_train, self.user_valid = self.generate_sequence_data()\n","\n","    def generate_encoder_decoder(self, col : str) -> dict:\n","        \"\"\"\n","        encoder, decoder 생성\n","\n","        Args:\n","            col (str): 생성할 columns 명\n","        Returns:\n","            dict: 생성된 user encoder, decoder\n","        \"\"\"\n","\n","        encoder = {}\n","        decoder = {}\n","        ids = self.df[col].unique()\n","\n","        for idx, _id in enumerate(ids):\n","            encoder[_id] = idx\n","            decoder[idx] = _id\n","\n","        return encoder, decoder\n","    \n","    def generate_sequence_data(self) -> dict:\n","        \"\"\"\n","        sequence_data 생성\n","\n","        Returns:\n","            dict: train user sequence / valid user sequence\n","        \"\"\"\n","        users = defaultdict(list)\n","        user_train = {}\n","        user_valid = {}\n","        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n","            users[user].append(item)\n","        \n","        for user in users:\n","            np.random.seed(self.config.seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            user_train[user] = train\n","            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n","\n","        return user_train, user_valid\n","    \n","    def get_train_valid_data(self):\n","        return self.user_train, self.user_valid\n","\n","    def make_matrix(self, user_list, train = True):\n","        \"\"\"\n","        user_item_dict를 바탕으로 행렬 생성\n","        \"\"\"\n","        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n","        for idx, user in enumerate(user_list):\n","            if train:\n","                mat[idx, self.user_train[user.item()]] = 1\n","            else:\n","                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n","        return mat\n","\n","    def make_sparse_matrix(self, test = False):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        \n","        for user in self.user_train.keys():\n","            item_list = self.user_train[user]\n","            X[user, item_list] = 1.0\n","        \n","        if test:\n","            for user in self.user_valid.keys():\n","                item_list = self.user_valid[user]\n","                X[user, item_list] = 1.0\n","\n","        return X.tocsr()\n","    \n","\n","    def make_year_candidate_item(self, train = True):\n","        user_pro_df = pd.read_csv(os.path.join(self.config.data_path, 'user_pro.csv'))\n","        item_pro_df = pd.read_csv(os.path.join(self.config.data_path, 'item_pro.csv'))\n","\n","        item_pro_df['item'] = item_pro_df['item'].apply(lambda x : self.item_encoder[x])\n","        item_pro_df['year'] = item_pro_df['year'].astype(int)\n","\n","        user_pro_df['user'] = user_pro_df['user'].apply(lambda x : self.user_encoder[x])\n","        user_pro_df['max_year'] = user_pro_df['max_year'].astype(int)\n","        \n","        year2item_list = {}\n","        year_list = user_pro_df['max_year'].unique().tolist()\n","        for year in year_list:\n","            item_list = item_pro_df[item_pro_df['year'] <= year + 1]['item'].tolist()\n","            year2item_list[year + 1] = item_list\n","\n","        all_item_list = [i for i in range(self.num_item)]\n","        group_df = user_pro_df.groupby('user')\n","        candidate = {}\n","        if train:\n","            for user, df in group_df:\n","                max_year = df['max_year'].values[0]\n","                candidate_item_list = year2item_list[max_year + 1]\n","                candidate_item_list = set(all_item_list) - set(candidate_item_list)\n","                candidate_item_list = list(candidate_item_list | set(self.user_train[user]))\n","                candidate[user] = candidate_item_list\n","        else:\n","            for user, df in group_df:\n","                max_year = df['max_year'].values[0]\n","                candidate_item_list = year2item_list[max_year + 1]\n","                candidate_item_list = set(all_item_list) - set(candidate_item_list)\n","                candidate_item_list = candidate_item_list | set(self.user_train[user])\n","                candidate_item_list = list(candidate_item_list | set(self.user_valid[user]))\n","                candidate[user] = candidate_item_list\n","\n","        return candidate\n","\n","    def make_cos_candidate_item(self, candidate_item_num, train = True):\n","        gmf = GMF(\n","            num_user = self.num_user, \n","            num_item = self.num_item, \n","            num_factor = 512).to(device)\n","\n","        gmf.load_state_dict(torch.load(os.path.join(self.config.model_path, 'GMF_v1.pt')))\n","        movie_emb = gmf.item_emb.weight.data.cpu()\n","        \n","        cos_mm = torch.nn.CosineSimilarity(dim=1)\n","        cos_sim_list = []\n","        for target_item in range(len(movie_emb)):\n","            cos_sim_score = cos_mm(movie_emb[target_item], movie_emb)\n","            cos_sim_index = cos_sim_score.argsort()\n","            cos_sim_list.append(cos_sim_index.numpy()[::-1][:candidate_item_num + 1].tolist())\n","        \n","        cos_sim_list = np.array(cos_sim_list)\n","\n","        candidate = {}\n","        if train:\n","            for user in self.user_train.keys():\n","                candidate_item_list = set(cos_sim_list[self.user_train[user], :].reshape(-1).tolist())\n","                candidate_item_list = list(candidate_item_list - set(self.user_train[user]))\n","                candidate[user] = candidate_item_list\n","        else:\n","            for user in self.user_train.keys():\n","                candidate_item_list = set(cos_sim_list[self.user_train[user] + self.user_valid[user], :].reshape(-1).tolist())\n","                candidate_item_list = candidate_item_list - set(self.user_train[user])\n","                candidate_item_list = list(candidate_item_list - set(self.user_valid[user]))\n","                candidate[user] = candidate_item_list\n","        \n","        return candidate\n","\n","    def m_s_m(self, candidate):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        for user in candidate.keys():\n","            item_list = candidate[user]\n","            X[user, item_list] = 1.0\n","\n","        return X.tocsr()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"IldCGmY8u9vh"},"outputs":[],"source":["class AEDataSet(Dataset):\n","    def __init__(self, num_user):\n","        self.num_user = num_user\n","        self.users = [i for i in range(num_user)]\n","\n","    def __len__(self):\n","        return self.num_user\n","\n","    def __getitem__(self, idx): \n","        user = self.users[idx]\n","        return torch.LongTensor([user])"]},{"cell_type":"markdown","metadata":{"id":"ysia457Su9vi"},"source":["# 3. 모델"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"TVXWUTLpSh8_"},"outputs":[],"source":["class EASE():\n","    def __init__(self, X, reg):\n","        self.X = self._convert_sp_mat_to_sp_tensor(X)\n","        self.reg = reg\n","    \n","    def _convert_sp_mat_to_sp_tensor(self, X):\n","        \"\"\"\n","        Convert scipy sparse matrix to PyTorch sparse matrix\n","\n","        Arguments:\n","        ----------\n","        X = Adjacency matrix, scipy sparse matrix\n","        \"\"\"\n","        coo = X.tocoo().astype(np.float32)\n","        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n","        v = torch.FloatTensor(coo.data)\n","        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n","        return res\n","    \n","    def fit(self):\n","        '''\n","\n","        진짜 정말 간단한 식으로 모델을 만듬\n","\n","        '''\n","        G = self.X.to_dense().t() @ self.X.to_dense()\n","        diagIndices = torch.eye(G.shape[0]) == 1\n","        G[diagIndices] += self.reg\n","\n","        P = G.inverse()\n","        B = P / (-1 * P.diag())\n","        B[diagIndices] = 0\n","\n","        self.pred = self.X.to_dense() @ B"]},{"cell_type":"markdown","metadata":{"id":"GwSexh43u9vk"},"source":["# 4. 학습 함수"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"nws4JO2_rgQP"},"outputs":[],"source":["def get_ndcg(pred_list, true_list):\n","    ndcg = 0\n","    for rank, pred in enumerate(pred_list):\n","        if pred in true_list:\n","            ndcg += 1 / np.log2(rank + 2)\n","    return ndcg\n","\n","# hit == recall == precision\n","def get_hit(pred_list, true_list):\n","    hit_list = set(true_list) & set(pred_list)\n","    hit = len(hit_list) / len(true_list)\n","    return hit\n","\n","def evaluate(model, X, user_train, user_valid):\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat = model.pred.cpu()\n","    score = recon_mat * torch.from_numpy(1 - X)\n","    rec_list = score.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        uv = user_valid[user]\n","        up = rec[-10:].cpu().numpy().tolist()\n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(rec_list)\n","    HIT /= len(rec_list)\n","\n","    return NDCG, HIT\n","\n","\n","def predict(model, X):\n","    user2rec = {}\n","\n","    recon_mat = model.pred.cpu()\n","    score = recon_mat * torch.from_numpy(1 - X)\n","    rec_list = score.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        up = rec[-10:].cpu().numpy().tolist()\n","        user2rec[user] = up\n","    \n","    return user2rec"]},{"cell_type":"markdown","metadata":{"id":"gupkaJHMslCi"},"source":["# 5. 학습"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"HFOr6Wmbq9pW"},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n","X = make_matrix_data_set.make_sparse_matrix()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"mzhvIGPhrYov"},"outputs":[],"source":["model = EASE(X = X, reg = config.reg)\n","model.fit()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["candidate = make_matrix_data_set.make_cos_candidate_item(candidate_item_num = config.candidate_item_num, train = True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["new_X = make_matrix_data_set.m_s_m(candidate)\n","new_X = 1 - new_X.todense()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1103,"status":"ok","timestamp":1648373220204,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"D1yj8M7bsp6X","outputId":"20892967-6ca0-41b3-fa29-56ab76c92c0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.70355| HIT@10: 0.17417\n"]}],"source":["ndcg, hit = evaluate(model = model, X = new_X, user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.69426| HIT@10: 0.17225\n"]}],"source":["ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for candidate_item_num in range(1, 20):\n","    candidate = make_matrix_data_set.make_cos_candidate_item(candidate_item_num = candidate_item_num, train = True)\n","    new_X = make_matrix_data_set.m_s_m(candidate)\n","    new_X = 1 - new_X.todense()\n","\n","    ndcg, hit = evaluate(model = model, X = new_X, user_train = user_train, user_valid = user_valid)\n","    print(f'candidate_item_num: {candidate_item_num}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["```\n","candidate_item_num: 1| NDCG@10: 0.58045| HIT@10: 0.14915\n","candidate_item_num: 2| NDCG@10: 0.67349| HIT@10: 0.16913\n","candidate_item_num: 3| NDCG@10: 0.69687| HIT@10: 0.17347\n","candidate_item_num: 4| NDCG@10: 0.70453| HIT@10: 0.17469\n","candidate_item_num: 5| NDCG@10: 0.70501| HIT@10: 0.17461\n","candidate_item_num: 6| NDCG@10: 0.70404| HIT@10: 0.17441\n","candidate_item_num: 7| NDCG@10: 0.70468| HIT@10: 0.17448\n","candidate_item_num: 8| NDCG@10: 0.70447| HIT@10: 0.17434\n","\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["candidate = make_matrix_data_set.make_cos_candidate_item(candidate_item_num = 4, train = True)\n","new_X = make_matrix_data_set.m_s_m(candidate)\n","new_X = 1 - new_X.todense()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for reg in [1000000, 100000, 10000, 1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n","    model = EASE(X = X, reg = reg)\n","    model.fit()\n","    ndcg, hit = evaluate(model = model, X = new_X, user_train = user_train, user_valid = user_valid)\n","    print(f'reg: {reg}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["```\n","reg: 1000000| NDCG@10: 0.46015| HIT@10: 0.11131\n","reg: 100000| NDCG@10: 0.57234| HIT@10: 0.14224\n","reg: 10000| NDCG@10: 0.72272| HIT@10: 0.18252\n","reg: 1000| NDCG@10: 0.79034| HIT@10: 0.19934\n","reg: 100| NDCG@10: 0.77785| HIT@10: 0.19445\n","reg: 10| NDCG@10: 0.73045| HIT@10: 0.18189\n","reg: 1| NDCG@10: 0.70640| HIT@10: 0.17564\n","reg: 0.1| NDCG@10: 0.70441| HIT@10: 0.17476\n","reg: 0.01| NDCG@10: 0.70451| HIT@10: 0.17470\n","reg: 0.001| NDCG@10: 0.70453| HIT@10: 0.17469\n","reg: 0.0001| NDCG@10: 0.70453| HIT@10: 0.17469\n","reg: 1e-05| NDCG@10: 0.70453| HIT@10: 0.17469\n","\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 6. 예측"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["X_test = make_matrix_data_set.make_sparse_matrix(test = True)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["model = EASE(X = X_test, reg = 1000)\n","model.fit()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["candidate = make_matrix_data_set.make_cos_candidate_item(candidate_item_num = 5, train = False)\n","new_X = make_matrix_data_set.m_s_m(candidate)\n","new_X = 1 - new_X.todense()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["user2rec_list = predict(\n","    model = model, \n","    X = new_X,\n","    )\n","\n","submision = []\n","users = [i for i in range(0, make_matrix_data_set.num_user)]\n","for user in users:\n","    rec_item_list = user2rec_list[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>2987</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>2174</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>7438</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>7373</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>313595</th>\n","      <td>138493</td>\n","      <td>1270</td>\n","    </tr>\n","    <tr>\n","      <th>313596</th>\n","      <td>138493</td>\n","      <td>5349</td>\n","    </tr>\n","    <tr>\n","      <th>313597</th>\n","      <td>138493</td>\n","      <td>8961</td>\n","    </tr>\n","    <tr>\n","      <th>313598</th>\n","      <td>138493</td>\n","      <td>2628</td>\n","    </tr>\n","    <tr>\n","      <th>313599</th>\n","      <td>138493</td>\n","      <td>551</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>313600 rows × 2 columns</p>\n","</div>"],"text/plain":["          user  item\n","0           11  2987\n","1           11  2174\n","2           11  7438\n","3           11     2\n","4           11  7373\n","...        ...   ...\n","313595  138493  1270\n","313596  138493  5349\n","313597  138493  8961\n","313598  138493  2628\n","313599  138493   551\n","\n","[313600 rows x 2 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["submision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMB0K8DmOwclQIFyyBerAFJ","collapsed_sections":[],"mount_file_id":"1C1AHkN-z-DCxUIAjFfd7K56P-8-YrAJO","name":"EASE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
