{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ug-br-pPu9vZ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from box import Box\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbRKDSg4u9vc"
   },
   "source": [
    "# 1. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MEhK_fLIu9vd"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n",
    "    'model_path' : \"../model\",\n",
    "\n",
    "\n",
    "    'submission_path' : \"../submission\",\n",
    "    'submission_name' : 'Ensembel_v4_submission.csv',\n",
    "\n",
    "    'candidate_item_num' : 50,\n",
    "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
    "    'seed' : 22,\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjDxy0fJu9vf"
   },
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W64BYWl0u9vg"
   },
   "outputs": [],
   "source": [
    "class MakeMatrixDataSet():\n",
    "    \"\"\"\n",
    "    MatrixDataSet 생성\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n",
    "        \n",
    "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n",
    "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n",
    "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
    "\n",
    "        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n",
    "        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n",
    "\n",
    "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
    "\n",
    "    def generate_encoder_decoder(self, col : str) -> dict:\n",
    "        \"\"\"\n",
    "        encoder, decoder 생성\n",
    "\n",
    "        Args:\n",
    "            col (str): 생성할 columns 명\n",
    "        Returns:\n",
    "            dict: 생성된 user encoder, decoder\n",
    "        \"\"\"\n",
    "\n",
    "        encoder = {}\n",
    "        decoder = {}\n",
    "        ids = self.df[col].unique()\n",
    "\n",
    "        for idx, _id in enumerate(ids):\n",
    "            encoder[_id] = idx\n",
    "            decoder[idx] = _id\n",
    "\n",
    "        return encoder, decoder\n",
    "    \n",
    "    def generate_sequence_data(self) -> dict:\n",
    "        \"\"\"\n",
    "        sequence_data 생성\n",
    "\n",
    "        Returns:\n",
    "            dict: train user sequence / valid user sequence\n",
    "        \"\"\"\n",
    "        users = defaultdict(list)\n",
    "        user_train = {}\n",
    "        user_valid = {}\n",
    "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n",
    "            users[user].append(item)\n",
    "        \n",
    "        for user in users:\n",
    "            np.random.seed(self.config.seed)\n",
    "\n",
    "            user_total = users[user]\n",
    "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
    "            train = list(set(user_total) - set(valid))\n",
    "\n",
    "            user_train[user] = train\n",
    "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
    "\n",
    "        return user_train, user_valid\n",
    "    \n",
    "    def get_train_valid_data(self):\n",
    "        return self.user_train, self.user_valid\n",
    "\n",
    "    def make_matrix(self, user_list, train = True):\n",
    "        \"\"\"\n",
    "        user_item_dict를 바탕으로 행렬 생성\n",
    "        \"\"\"\n",
    "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
    "        for idx, user in enumerate(user_list):\n",
    "            if train:\n",
    "                mat[idx, self.user_train[user.item()]] = 1\n",
    "            else:\n",
    "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
    "        return mat\n",
    "\n",
    "    def make_sparse_matrix(self, test = False):\n",
    "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
    "        \n",
    "        for user in self.user_train.keys():\n",
    "            item_list = self.user_train[user]\n",
    "            X[user, item_list] = 1.0\n",
    "        \n",
    "        if test:\n",
    "            for user in self.user_valid.keys():\n",
    "                item_list = self.user_valid[user]\n",
    "                X[user, item_list] = 1.0\n",
    "\n",
    "        return X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IldCGmY8u9vh"
   },
   "outputs": [],
   "source": [
    "class AEDataSet(Dataset):\n",
    "    def __init__(self, num_user):\n",
    "        self.num_user = num_user\n",
    "        self.users = [i for i in range(num_user)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_user\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        user = self.users[idx]\n",
    "        return torch.LongTensor([user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysia457Su9vi"
   },
   "source": [
    "# 3. 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, dropout_rate = 0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "\n",
    "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
    "\n",
    "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
    "\n",
    "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
    "\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.encode(input)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def encode(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                mu = h[:, :self.q_dims[-1]]\n",
    "                logvar = h[:, self.q_dims[-1]:]\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.q_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.p_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, dropout_rate = 0.5):\n",
    "        super(MultiDAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num, num_factor):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num, num_factor),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_factor, num_factor // 2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_factor // 2, num_factor),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_factor, num),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, mat):\n",
    "        latent = self.encoder(mat)\n",
    "        recont_mat = self.decoder(latent)\n",
    "\n",
    "        return recont_mat\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.encoder:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                size = layer.weight.size()\n",
    "                fan_out = size[0]\n",
    "                fan_in = size[1]\n",
    "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "                layer.weight.data.normal_(0.0, std)\n",
    "                layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.decoder:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                size = layer.weight.size()\n",
    "                fan_out = size[0]\n",
    "                fan_in = size[1]\n",
    "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "                layer.weight.data.normal_(0.0, std)\n",
    "                layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE():\n",
    "    def __init__(self, X, reg):\n",
    "        self.X = self._convert_sp_mat_to_sp_tensor(X)\n",
    "        self.reg = reg\n",
    "    \n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        \"\"\"\n",
    "        Convert scipy sparse matrix to PyTorch sparse matrix\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        X = Adjacency matrix, scipy sparse matrix\n",
    "        \"\"\"\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "        v = torch.FloatTensor(coo.data)\n",
    "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "        return res\n",
    "    \n",
    "    def fit(self):\n",
    "        '''\n",
    "\n",
    "        진짜 정말 간단한 식으로 모델을 만듬\n",
    "\n",
    "        '''\n",
    "        G = self.X.to_dense().t() @ self.X.to_dense()\n",
    "        diagIndices = torch.eye(G.shape[0]) == 1\n",
    "        G[diagIndices] += self.reg\n",
    "\n",
    "        P = G.inverse()\n",
    "        B = P / (-1 * P.diag())\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.pred = self.X.to_dense() @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x.mul(torch.sigmoid(x))\n",
    "\n",
    "def log_norm_pdf(x, mu, logvar):\n",
    "    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n",
    "\n",
    "class CompositePrior(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n",
    "        super(CompositePrior, self).__init__()\n",
    "        \n",
    "        self.mixture_weights = mixture_weights\n",
    "        \n",
    "        self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.mu_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_uniform_prior.data.fill_(10)\n",
    "        \n",
    "        self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.encoder_old.requires_grad_(False)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "\n",
    "        post_mu, post_logvar = self.encoder_old(x, dropout_rate = 0)\n",
    "\n",
    "        stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n",
    "        post_prior = log_norm_pdf(z, post_mu, post_logvar)\n",
    "        unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n",
    "        \n",
    "        gaussians = [stnd_prior, post_prior, unif_prior]\n",
    "        gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n",
    "\n",
    "        density_per_gaussian = torch.stack(gaussians, dim=-1)\n",
    "\n",
    "        return torch.logsumexp(density_per_gaussian, dim=-1)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x, dropout_rate):\n",
    "        norm = x.pow(2).sum(dim=-1).sqrt()\n",
    "        x = x / norm[:, None]\n",
    "    \n",
    "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "        \n",
    "        h1 = self.ln1(swish(self.fc1(x)))\n",
    "        h2 = self.ln2(swish(self.fc2(h1) + h1))\n",
    "        h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n",
    "        h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n",
    "        h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n",
    "        return self.fc_mu(h5), self.fc_logvar(h5)\n",
    "\n",
    "\n",
    "class RecVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 600, latent_dim = 200):\n",
    "        super(RecVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n",
    "        self.decoder = nn.Linear(latent_dim, input_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, user_ratings, beta=None, gamma=0.0005, dropout_rate=0.7, calculate_loss=True):\n",
    "        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)    \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_pred = self.decoder(z)\n",
    "\n",
    "        if calculate_loss:\n",
    "            if gamma:\n",
    "                norm = user_ratings.sum(dim=-1)\n",
    "                kl_weight = gamma * norm\n",
    "            elif beta:\n",
    "                kl_weight = beta\n",
    "\n",
    "            mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n",
    "            kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n",
    "            negative_elbo = -(mll - kld)\n",
    "            \n",
    "            return (mll, kld), negative_elbo\n",
    "            \n",
    "        else:\n",
    "            return x_pred\n",
    "\n",
    "    def update_prior(self):\n",
    "        self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwSexh43u9vk"
   },
   "source": [
    "# 4. 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nws4JO2_rgQP"
   },
   "outputs": [],
   "source": [
    "def get_ndcg(pred_list, true_list):\n",
    "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
    "    dcg = 0\n",
    "    for rank, pred in enumerate(pred_list):\n",
    "        if pred in true_list:\n",
    "            dcg += 1 / np.log2(rank + 2)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "# hit == recall == precision\n",
    "def get_hit(pred_list, true_list):\n",
    "    hit_list = set(true_list) & set(pred_list)\n",
    "    hit = len(hit_list) / len(true_list)\n",
    "    return hit\n",
    "\n",
    "\n",
    "def evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "    AutoRec.eval()\n",
    "    MultiDAE.eval()\n",
    "    MultiVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    NDCG = 0.0 # NDCG@10\n",
    "    HIT = 0.0 # HIT@10\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "    recon_mat6 = recon_mat6.cpu().detach()\n",
    "    recon_mat6[mat == 1] = -np.inf\n",
    "    rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li\n",
    "        movie_df.loc[rec4, 'rec5_score'] = score_li\n",
    "        movie_df.loc[rec4, 'rec6_score'] = score_li\n",
    "        movie_df = movie_df.fillna(min(score_li))\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score'] + movie_df['rec6_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT\n",
    "\n",
    "# def predict(model1, model2, RecVAE, X, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "\n",
    "#     user2rec = {}\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "#     for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "#         # ranking\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3))\n",
    "\n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[rec1, 'rec1_score'] = score_li\n",
    "#         movie_df.loc[rec2, 'rec2_score'] = score_li\n",
    "#         movie_df.loc[rec3, 'rec3_score'] = score_li\n",
    "#         movie_df = movie_df.fillna(min(score_li))\n",
    "#         movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score']\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         user2rec[user] = up\n",
    "\n",
    "#     return user2rec\n",
    "\n",
    "\n",
    "def total_evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "    AutoRec.eval()\n",
    "    MultiDAE.eval()\n",
    "    MultiVAE.eval()\n",
    "\n",
    "    df = []\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "    recon_mat6 = recon_mat6.cpu().detach()\n",
    "    recon_mat6[mat == 1] = -np.inf\n",
    "    rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        rec123456 = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "        df.append(\n",
    "            {\n",
    "               'user' : user,\n",
    "\n",
    "               'rec1' : get_hit(pred_list = rec1, true_list = uv),\n",
    "               'rec2' : get_hit(pred_list = rec2, true_list = uv),\n",
    "               'rec3' : get_hit(pred_list = rec3, true_list = uv),\n",
    "               'rec4' : get_hit(pred_list = rec4, true_list = uv),\n",
    "               'rec5' : get_hit(pred_list = rec5, true_list = uv),\n",
    "               'rec6' : get_hit(pred_list = rec6, true_list = uv),\n",
    "\n",
    "               'rec123456' : get_hit(pred_list = rec123456, true_list = uv),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def predict(model1, model2, RecVAE, X, candidate_cnt, df):\n",
    "    RecVAE.eval()\n",
    "\n",
    "    user2rec = {}\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    for user, (rec1, rec2, rec3, total_name) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, df['total_name']))):\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        \n",
    "        if total_name == 'rec1': user2rec[user] = rec1\n",
    "        elif total_name == 'rec2': user2rec[user] = rec2\n",
    "        elif total_name == 'rec3':user2rec[user] = rec3\n",
    "\n",
    "    return user2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# def evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X_df, y_df, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     NDCG = 0.0 # NDCG@10\n",
    "#     HIT = 0.0 # HIT@10\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     copy_recon_mat1 = deepcopy(recon_mat1.sigmoid())\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     copy_recon_mat2 = deepcopy(recon_mat2.sigmoid())\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     copy_recon_mat3 = deepcopy(recon_mat3.sigmoid())\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     copy_recon_mat4 = deepcopy(recon_mat4.sigmoid())\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     copy_recon_mat5 = deepcopy(recon_mat5.sigmoid())\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     copy_recon_mat6 = deepcopy(recon_mat6.sigmoid())\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "\n",
    "#         cif = LogisticRegression(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "#         score_li = np.array([[copy_recon_mat1.numpy()[user][item], copy_recon_mat2.numpy()[user][item], copy_recon_mat3.numpy()[user][item] , copy_recon_mat4.numpy()[user][item] , copy_recon_mat5.numpy()[user][item] , copy_recon_mat6.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "#         HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "#     NDCG /= len(user_train)\n",
    "#     HIT /= len(user_train)\n",
    "\n",
    "#     return NDCG, HIT\n",
    "\n",
    "\n",
    "# def predict(model1, model2, RecVAE, X_df, y_df, X, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "\n",
    "#     user2rec = {}\n",
    "\n",
    "#     neg = torch.from_numpy(1 - X)\n",
    "#     pos = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     score1 = recon_mat1 * neg\n",
    "#     rec_list1 = score1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     score2 = recon_mat2 * neg\n",
    "#     rec_list2 = score2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(pos.to(device), calculate_loss = False).cpu().detach()\n",
    "#     score3 = recon_mat3 * neg\n",
    "#     rec_list3 = score3.argsort(dim = 1)\n",
    "\n",
    "#     for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "\n",
    "#         cif = LogisticRegression(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3))\n",
    "#         score_li = np.array([[recon_mat1.numpy()[user][item], recon_mat2.numpy()[user][item], recon_mat3.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "        \n",
    "#         user2rec[user] = up\n",
    "\n",
    "#     return user2rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gupkaJHMslCi"
   },
   "source": [
    "# 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "model4.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = MultiDAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = MultiVAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model6.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [00:01, 18826.74it/s]\n"
     ]
    }
   ],
   "source": [
    "df = total_evaluate(\n",
    "    model1 = model1,\n",
    "    model2 = model2,\n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4,\n",
    "    MultiDAE = model5,\n",
    "    MultiVAE = model6,\n",
    "    X = X.todense(),\n",
    "    user_train = user_train,\n",
    "    user_valid = user_valid,\n",
    "    candidate_cnt = 10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec6</th>\n",
       "      <th>rec123456</th>\n",
       "      <th>total_val</th>\n",
       "      <th>total_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>31355</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>31356</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>31357</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>31358</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>31359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  rec1  rec2  rec3  rec4  rec5  rec6  rec123456  total_val  \\\n",
       "0          0   0.3   0.3   0.2   0.2   0.2   0.2        0.5        0.3   \n",
       "1          1   0.1   0.1   0.2   0.1   0.1   0.1        0.2        0.2   \n",
       "2          2   0.3   0.3   0.3   0.3   0.2   0.1        0.3        0.3   \n",
       "3          3   0.3   0.3   0.2   0.2   0.2   0.2        0.4        0.3   \n",
       "4          4   0.4   0.3   0.4   0.3   0.5   0.4        0.5        0.5   \n",
       "...      ...   ...   ...   ...   ...   ...   ...        ...        ...   \n",
       "31355  31355   0.2   0.4   0.2   0.2   0.2   0.2        0.4        0.4   \n",
       "31356  31356   0.3   0.3   0.3   0.2   0.5   0.0        0.5        0.5   \n",
       "31357  31357   0.2   0.3   0.2   0.1   0.1   0.1        0.3        0.3   \n",
       "31358  31358   0.1   0.1   0.0   0.0   0.0   0.0        0.1        0.1   \n",
       "31359  31359   0.0   0.2   0.1   0.0   0.1   0.0        0.2        0.2   \n",
       "\n",
       "      total_name  \n",
       "0           rec1  \n",
       "1           rec3  \n",
       "2           rec1  \n",
       "3           rec1  \n",
       "4           rec5  \n",
       "...          ...  \n",
       "31355       rec2  \n",
       "31356       rec5  \n",
       "31357       rec2  \n",
       "31358       rec1  \n",
       "31359       rec2  \n",
       "\n",
       "[31360 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저들 마다 rec1 or rec2 or rec3 or ranking 등 맞는 방법에 따라사 추천을 해주는 것도 좋은 방법이 될 수 있음\n",
    "\n",
    "new_df = pd.DataFrame(df)\n",
    "\n",
    "def get_total_name(x):\n",
    "    val_list = [x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5'] , x['rec6']]\n",
    "    max_val = max(val_list)\n",
    "    val_idx = val_list.index(max_val)\n",
    "    if val_idx == 0 : return 'rec1'\n",
    "    elif val_idx == 1 : return 'rec2'\n",
    "    elif val_idx == 2 : return 'rec3'\n",
    "    elif val_idx == 3 : return 'rec4'\n",
    "    elif val_idx == 4 : return 'rec5'\n",
    "    elif val_idx == 5 : return 'rec6'\n",
    "\n",
    "new_df['total_val'] = new_df.apply(lambda x: max(x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5'] , x['rec6']), axis = 1)\n",
    "new_df['total_name'] = new_df.apply(lambda x: get_total_name(x), axis = 1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.boxplot(data = new_df[[\"rec1\", \"rec2\", \"rec3\", \"rec4\", \"rec5\", \"rec6\", 'rec123456', 'total_val']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec1    16391\n",
       "rec3     4737\n",
       "rec2     3913\n",
       "rec5     2433\n",
       "rec4     2162\n",
       "rec6     1724\n",
       "Name: total_name, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['total_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         15679.500000\n",
       "rec1             0.203839\n",
       "rec2             0.200207\n",
       "rec3             0.192140\n",
       "rec4             0.174758\n",
       "rec5             0.172388\n",
       "rec6             0.174767\n",
       "rec123456        0.313935\n",
       "total_val        0.263115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "rec1 | NDCG@10: 0.31055| HIT@10: 0.20384\n",
    "rec2 | NDCG@10: 0.30428| HIT@10: 0.20021\n",
    "rec3 | NDCG@10: 0.28574| HIT@10: 0.19214\n",
    "rec12 | NDCG@10: 0.23462| HIT@10: 0.22666\n",
    "rec13 | NDCG@10: 0.21648| HIT@10: 0.24872\n",
    "rec23 | NDCG@10: 0.21378| HIT@10: 0.24704\n",
    "rec123 | NDCG@10: 0.20457| HIT@10: 0.26235\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = np.concatenate([np.repeat(i, 6807) for i in range(31360)])\n",
    "\n",
    "model1_score = model1.pred.sigmoid().cpu().numpy().reshape(-1)\n",
    "\n",
    "model2_score = model2.pred.T.sigmoid().cpu().numpy().reshape(-1)\n",
    "\n",
    "model3_score = model3(torch.from_numpy(X.todense()).to(device), calculate_loss = False).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "model4_score = model4(torch.from_numpy(X.todense()).to(device)).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "model5_score = model5(torch.from_numpy(X.todense()).to(device)).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "model6_score, _, _ = model6(torch.from_numpy(X.todense()).to(device))\n",
    "model6_score = model6_score.sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "X_df = np.concatenate([\n",
    "    users.reshape(-1, 1), \n",
    "    model1_score.reshape(-1, 1), \n",
    "    model2_score.reshape(-1, 1), \n",
    "    model3_score.reshape(-1, 1), \n",
    "    model4_score.reshape(-1, 1), \n",
    "    model5_score.reshape(-1, 1),\n",
    "    model6_score.reshape(-1, 1)], axis = 1)\n",
    "\n",
    "y_df = X.toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [15:57, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.31142| HIT@10: 0.20458\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 10\n",
    "\n",
    "ndcg, hit = evaluate(\n",
    "            model1 = model1, \n",
    "            model2 = model2, \n",
    "            RecVAE = model3,\n",
    "            AutoRec = model4,\n",
    "            MultiDAE = model5,\n",
    "            MultiVAE = model6,\n",
    "            X_df = X_df, \n",
    "            y_df = y_df,\n",
    "            X = X.todense(),\n",
    "            user_train = user_train, \n",
    "            user_valid = user_valid, \n",
    "            candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre = pd.read_csv(os.path.join(config.data_path, 'genres.tsv'), sep='\\t')\n",
    "# genre['genres'] = 1\n",
    "# genre['item_idx'] = genre['item'].apply(lambda x : make_matrix_data_set.item_encoder[x])\n",
    "# genre = pd.pivot_table(genre, values='genres', index=['item_idx'], columns=['genre'], aggfunc=np.sum, fill_value=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:58, 175.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.27091| HIT@10: 0.18457\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 10\n",
    "\n",
    "ndcg, hit = evaluate(\n",
    "            model1 = model1, \n",
    "            model2 = model2, \n",
    "            RecVAE = model3,\n",
    "            AutoRec = model4,\n",
    "            MultiDAE = model5,\n",
    "            MultiVAE = model6,\n",
    "            X = X.todense(),\n",
    "            user_train = user_train, \n",
    "            user_valid = user_valid, \n",
    "            candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:07, 246.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.31054| HIT@10: 0.20327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:10, 240.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 15| NDCG@10: 0.31195| HIT@10: 0.20454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:08, 244.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 20| NDCG@10: 0.31247| HIT@10: 0.20504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:13, 234.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 25| NDCG@10: 0.31270| HIT@10: 0.20521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3140it [00:13, 227.02it/s]"
     ]
    }
   ],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "                model1 = model1, \n",
    "                model2 = model2, \n",
    "                RecVAE = model3,\n",
    "                AutoRec = model4,\n",
    "                X = X.todense(),\n",
    "                user_train = user_train, \n",
    "                user_valid = user_valid, \n",
    "                candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RecVAE-v3\n",
    "candidate_cnt: 10| NDCG@10: 0.31412| HIT@10: 0.20595\n",
    "candidate_cnt: 15| NDCG@10: 0.31573| HIT@10: 0.20745\n",
    "candidate_cnt: 20| NDCG@10: 0.31644| HIT@10: 0.20807\n",
    "candidate_cnt: 25| NDCG@10: 0.31687| HIT@10: 0.20851\n",
    "candidate_cnt: 30| NDCG@10: 0.31696| HIT@10: 0.20863\n",
    "candidate_cnt: 35| NDCG@10: 0.31708| HIT@10: 0.20872\n",
    "candidate_cnt: 40| NDCG@10: 0.31712| HIT@10: 0.20878\n",
    "candidate_cnt: 45| NDCG@10: 0.31717| HIT@10: 0.20882\n",
    "candidate_cnt: 50| NDCG@10: 0.31723| HIT@10: 0.20886\n",
    "candidate_cnt: 55| NDCG@10: 0.31723| HIT@10: 0.20884\n",
    "candidate_cnt: 60| NDCG@10: 0.31726| HIT@10: 0.20887\n",
    "candidate_cnt: 65| NDCG@10: 0.31729| HIT@10: 0.20888\n",
    "candidate_cnt: 70| NDCG@10: 0.31727| HIT@10: 0.20887\n",
    "candidate_cnt: 75| NDCG@10: 0.31730| HIT@10: 0.20889\n",
    "candidate_cnt: 80| NDCG@10: 0.31730| HIT@10: 0.20890\n",
    "candidate_cnt: 85| NDCG@10: 0.31733| HIT@10: 0.20888\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RecVAE-v5\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "candidate_cnt: 15| NDCG@10: 0.31518| HIT@10: 0.20735\n",
    "candidate_cnt: 20| NDCG@10: 0.31569| HIT@10: 0.20779\n",
    "candidate_cnt: 25| NDCG@10: 0.31605| HIT@10: 0.20812\n",
    "candidate_cnt: 30| NDCG@10: 0.31616| HIT@10: 0.20822\n",
    "candidate_cnt: 35| NDCG@10: 0.31627| HIT@10: 0.20833\n",
    "candidate_cnt: 40| NDCG@10: 0.31636| HIT@10: 0.20843\n",
    "candidate_cnt: 45| NDCG@10: 0.31643| HIT@10: 0.20846\n",
    "candidate_cnt: 50| NDCG@10: 0.31644| HIT@10: 0.20848\n",
    "candidate_cnt: 55| NDCG@10: 0.31653| HIT@10: 0.20854\n",
    "candidate_cnt: 60| NDCG@10: 0.31657| HIT@10: 0.20857\n",
    "candidate_cnt: 65| NDCG@10: 0.31652| HIT@10: 0.20856\n",
    "candidate_cnt: 70| NDCG@10: 0.31653| HIT@10: 0.20856\n",
    "candidate_cnt: 75| NDCG@10: 0.31651| HIT@10: 0.20855\n",
    "candidate_cnt: 80| NDCG@10: 0.31658| HIT@10: 0.20858\n",
    "candidate_cnt: 85| NDCG@10: 0.31660| HIT@10: 0.20859\n",
    "candidate_cnt: 90| NDCG@10: 0.31658| HIT@10: 0.20860\n",
    "candidate_cnt: 95| NDCG@10: 0.31662| HIT@10: 0.20862\n",
    "candidate_cnt: 100| NDCG@10: 0.31658| HIT@10: 0.20861\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "none + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31411| HIT@10: 0.20686\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31568| HIT@10: 0.20702\n",
    "```\n",
    "\n",
    "```\n",
    "softmax + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.28598| HIT@10: 0.19227\n",
    "```\n",
    "\n",
    "```\n",
    "none + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31381| HIT@10: 0.20633\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31469| HIT@10: 0.20636\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[147, 197, 188, 313, 228, 273, 189, 114, 42, 242]\n",
    "\n",
    "```\n",
    "non softmax\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.902873     0.411256     1.314129\n",
    "42    0.815624     0.411256     1.226880\n",
    "933   0.981398     0.172427     1.153824\n",
    "718   0.671753     0.402721     1.074474\n",
    "484   0.923667     0.149443     1.073110\n",
    "376   0.883676     0.173539     1.057215\n",
    "667   0.919388     0.097644     1.017032\n",
    "650   0.855481     0.151946     1.007427\n",
    "2200  0.878635     0.125442     1.004077\n",
    "714   0.719053     0.210817     0.929870\n",
    "1844  0.698690     0.226953     0.925643\n",
    "273   0.810516     0.097710     0.908226\n",
    "760   0.763495     0.036601     0.800096\n",
    "313   0.766302     0.027069     0.793371\n",
    "777   0.641927     0.142652     0.784579\n",
    "228   0.733693     0.044058     0.777750\n",
    "734   0.738835     0.031143     0.769978\n",
    "1354  0.438386     0.122450     0.560836\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "softmax\n",
    "\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.053804     0.411256     0.465060\n",
    "42    0.053799     0.411256     0.465055\n",
    "718   0.053844     0.402721     0.456565\n",
    "1844  0.053790     0.226953     0.280743\n",
    "714   0.053817     0.210817     0.264634\n",
    "376   0.053824     0.173539     0.227363\n",
    "933   0.053912     0.172427     0.226339\n",
    "650   0.053820     0.151946     0.205766\n",
    "484   0.053827     0.149443     0.203270\n",
    "777   0.053828     0.142652     0.196481\n",
    "2200  0.053810     0.125442     0.179252\n",
    "1354  0.053825     0.122450     0.176275\n",
    "273   0.053800     0.097710     0.151510\n",
    "667   0.053807     0.097644     0.151450\n",
    "228   0.053814     0.044058     0.097871\n",
    "760   0.053811     0.036601     0.090412\n",
    "734   0.053804     0.031143     0.084947\n",
    "313   0.053817     0.027069     0.080885\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(3, 21)]:\n",
    "    ndcg, hit = evaluate(\n",
    "            model1 = model1, \n",
    "            model2 = model2, \n",
    "            RecVAE = model3,\n",
    "            X_df = X_df,\n",
    "            y_df = y_df,\n",
    "            X = X.todense(),\n",
    "            user_train = user_train, \n",
    "            user_valid = user_valid, \n",
    "            candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Logistic + 'l2'\n",
    "\n",
    "candidate_cnt: 5| NDCG@10: 0.35450| HIT@10: 0.18291\n",
    "candidate_cnt: 10| NDCG@10: 0.31411| HIT@10: 0.20686\n",
    "candidate_cnt: 15| NDCG@10: 0.31367| HIT@10: 0.20634\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "log2(rank + 1)\n",
    "\n",
    "candidate_cnt: 5| NDCG@10: 0.35405| HIT@10: 0.18237\n",
    "candidate_cnt: 10| NDCG@10: 0.31403| HIT@10: 0.20607\n",
    "candidate_cnt: 15| NDCG@10: 0.31528| HIT@10: 0.20717\n",
    "candidate_cnt: 20| NDCG@10: 0.31590| HIT@10: 0.20775\n",
    "candidate_cnt: 25| NDCG@10: 0.31634| HIT@10: 0.20822\n",
    "candidate_cnt: 30| NDCG@10: 0.31650| HIT@10: 0.20833\n",
    "candidate_cnt: 35| NDCG@10: 0.31657| HIT@10: 0.20840\n",
    "candidate_cnt: 40| NDCG@10: 0.31667| HIT@10: 0.20850\n",
    "candidate_cnt: 45| NDCG@10: 0.31669| HIT@10: 0.20852\n",
    "candidate_cnt: 50| NDCG@10: 0.31672| HIT@10: 0.20852\n",
    "candidate_cnt: 55| NDCG@10: 0.31676| HIT@10: 0.20859\n",
    "candidate_cnt: 60| NDCG@10: 0.31678| HIT@10: 0.20856\n",
    "candidate_cnt: 65| NDCG@10: 0.31674| HIT@10: 0.20855\n",
    "candidate_cnt: 70| NDCG@10: 0.31675| HIT@10: 0.20855\n",
    "candidate_cnt: 75| NDCG@10: 0.31673| HIT@10: 0.20856\n",
    "candidate_cnt: 80| NDCG@10: 0.31677| HIT@10: 0.20855\n",
    "candidate_cnt: 85| NDCG@10: 0.31676| HIT@10: 0.20856\n",
    "candidate_cnt: 90| NDCG@10: 0.31679| HIT@10: 0.20856\n",
    "candidate_cnt: 95| NDCG@10: 0.31678| HIT@10: 0.20857\n",
    "candidate_cnt: 100| NDCG@10: 0.31677| HIT@10: 0.20856\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X_test, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X_test.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = np.concatenate([np.repeat(i, 6807) for i in range(31360)])\n",
    "\n",
    "# model1_score = model1.pred.cpu().numpy().reshape(-1)\n",
    "# model2_score = model2.pred.T.cpu().numpy().reshape(-1)\n",
    "# model3_score = model3(torch.from_numpy(X_test.todense()).to(device), calculate_loss = False).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# X_df = np.concatenate([users.reshape(-1, 1), model1_score.reshape(-1, 1), model2_score.reshape(-1, 1), model3_score.reshape(-1, 1)], axis = 1)\n",
    "# y_df = X_test.toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [00:00, 64933.20it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    RecVAE = model3,\n",
    "    X = X_test.todense(),\n",
    "    candidate_cnt = 10,\n",
    "    df = new_df,)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>32587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>53125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11   4886\n",
       "2           11  40815\n",
       "3           11   8961\n",
       "4           11  32587\n",
       "...        ...    ...\n",
       "313595  138493   5349\n",
       "313596  138493   1907\n",
       "313597  138493   8961\n",
       "313598  138493   1270\n",
       "313599  138493  53125\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
