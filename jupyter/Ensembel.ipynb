{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ug-br-pPu9vZ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from box import Box\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbRKDSg4u9vc"
   },
   "source": [
    "# 1. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MEhK_fLIu9vd"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n",
    "    'model_path' : \"../model\",\n",
    "\n",
    "\n",
    "    'submission_path' : \"../submission\",\n",
    "    'submission_name' : 'Ensembel_v5_submission.csv',\n",
    "\n",
    "    'candidate_item_num' : 50,\n",
    "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
    "    'seed' : 22,\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjDxy0fJu9vf"
   },
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "W64BYWl0u9vg"
   },
   "outputs": [],
   "source": [
    "class MakeMatrixDataSet():\n",
    "    \"\"\"\n",
    "    MatrixDataSet 생성\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n",
    "        \n",
    "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n",
    "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n",
    "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
    "\n",
    "        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n",
    "        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n",
    "\n",
    "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
    "\n",
    "    def generate_encoder_decoder(self, col : str) -> dict:\n",
    "        \"\"\"\n",
    "        encoder, decoder 생성\n",
    "\n",
    "        Args:\n",
    "            col (str): 생성할 columns 명\n",
    "        Returns:\n",
    "            dict: 생성된 user encoder, decoder\n",
    "        \"\"\"\n",
    "\n",
    "        encoder = {}\n",
    "        decoder = {}\n",
    "        ids = self.df[col].unique()\n",
    "\n",
    "        for idx, _id in enumerate(ids):\n",
    "            encoder[_id] = idx\n",
    "            decoder[idx] = _id\n",
    "\n",
    "        return encoder, decoder\n",
    "    \n",
    "    def generate_sequence_data(self) -> dict:\n",
    "        \"\"\"\n",
    "        sequence_data 생성\n",
    "\n",
    "        Returns:\n",
    "            dict: train user sequence / valid user sequence\n",
    "        \"\"\"\n",
    "        users = defaultdict(list)\n",
    "        user_train = {}\n",
    "        user_valid = {}\n",
    "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n",
    "            users[user].append(item)\n",
    "        \n",
    "        for user in users:\n",
    "            np.random.seed(self.config.seed)\n",
    "\n",
    "            user_total = users[user]\n",
    "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
    "            train = list(set(user_total) - set(valid))\n",
    "\n",
    "            user_train[user] = train\n",
    "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
    "\n",
    "        return user_train, user_valid\n",
    "    \n",
    "    def get_train_valid_data(self):\n",
    "        return self.user_train, self.user_valid\n",
    "\n",
    "    def make_matrix(self, user_list, train = True):\n",
    "        \"\"\"\n",
    "        user_item_dict를 바탕으로 행렬 생성\n",
    "        \"\"\"\n",
    "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
    "        for idx, user in enumerate(user_list):\n",
    "            if train:\n",
    "                mat[idx, self.user_train[user.item()]] = 1\n",
    "            else:\n",
    "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
    "        return mat\n",
    "\n",
    "    def make_sparse_matrix(self, test = False):\n",
    "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
    "        \n",
    "        for user in self.user_train.keys():\n",
    "            item_list = self.user_train[user]\n",
    "            X[user, item_list] = 1.0\n",
    "        \n",
    "        if test:\n",
    "            for user in self.user_valid.keys():\n",
    "                item_list = self.user_valid[user]\n",
    "                X[user, item_list] = 1.0\n",
    "\n",
    "        return X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IldCGmY8u9vh"
   },
   "outputs": [],
   "source": [
    "class AEDataSet(Dataset):\n",
    "    def __init__(self, num_user):\n",
    "        self.num_user = num_user\n",
    "        self.users = [i for i in range(num_user)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_user\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        user = self.users[idx]\n",
    "        return torch.LongTensor([user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysia457Su9vi"
   },
   "source": [
    "# 3. 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, dropout_rate = 0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "\n",
    "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
    "\n",
    "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
    "\n",
    "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
    "\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.encode(input)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def encode(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                mu = h[:, :self.q_dims[-1]]\n",
    "                logvar = h[:, self.q_dims[-1]:]\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.q_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.p_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, dropout_rate = 0.5):\n",
    "        super(MultiDAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num, num_factor):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num, num_factor),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_factor, num_factor // 2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_factor // 2, num_factor),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_factor, num),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, mat):\n",
    "        latent = self.encoder(mat)\n",
    "        recont_mat = self.decoder(latent)\n",
    "\n",
    "        return recont_mat\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.encoder:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                size = layer.weight.size()\n",
    "                fan_out = size[0]\n",
    "                fan_in = size[1]\n",
    "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "                layer.weight.data.normal_(0.0, std)\n",
    "                layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.decoder:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                size = layer.weight.size()\n",
    "                fan_out = size[0]\n",
    "                fan_in = size[1]\n",
    "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "                layer.weight.data.normal_(0.0, std)\n",
    "                layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE():\n",
    "    def __init__(self, X, reg):\n",
    "        self.X = self._convert_sp_mat_to_sp_tensor(X)\n",
    "        self.reg = reg\n",
    "    \n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        \"\"\"\n",
    "        Convert scipy sparse matrix to PyTorch sparse matrix\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        X = Adjacency matrix, scipy sparse matrix\n",
    "        \"\"\"\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "        v = torch.FloatTensor(coo.data)\n",
    "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "        return res\n",
    "    \n",
    "    def fit(self):\n",
    "        '''\n",
    "\n",
    "        진짜 정말 간단한 식으로 모델을 만듬\n",
    "\n",
    "        '''\n",
    "        G = self.X.to_dense().t() @ self.X.to_dense()\n",
    "        diagIndices = torch.eye(G.shape[0]) == 1\n",
    "        G[diagIndices] += self.reg\n",
    "\n",
    "        P = G.inverse()\n",
    "        B = P / (-1 * P.diag())\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.pred = self.X.to_dense() @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x.mul(torch.sigmoid(x))\n",
    "\n",
    "def log_norm_pdf(x, mu, logvar):\n",
    "    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n",
    "\n",
    "class CompositePrior(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n",
    "        super(CompositePrior, self).__init__()\n",
    "        \n",
    "        self.mixture_weights = mixture_weights\n",
    "        \n",
    "        self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.mu_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_uniform_prior.data.fill_(10)\n",
    "        \n",
    "        self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.encoder_old.requires_grad_(False)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "\n",
    "        post_mu, post_logvar = self.encoder_old(x, dropout_rate = 0)\n",
    "\n",
    "        stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n",
    "        post_prior = log_norm_pdf(z, post_mu, post_logvar)\n",
    "        unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n",
    "        \n",
    "        gaussians = [stnd_prior, post_prior, unif_prior]\n",
    "        gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n",
    "\n",
    "        density_per_gaussian = torch.stack(gaussians, dim=-1)\n",
    "\n",
    "        return torch.logsumexp(density_per_gaussian, dim=-1)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x, dropout_rate):\n",
    "        norm = x.pow(2).sum(dim=-1).sqrt()\n",
    "        x = x / norm[:, None]\n",
    "    \n",
    "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "        \n",
    "        h1 = self.ln1(swish(self.fc1(x)))\n",
    "        h2 = self.ln2(swish(self.fc2(h1) + h1))\n",
    "        h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n",
    "        h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n",
    "        h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n",
    "        return self.fc_mu(h5), self.fc_logvar(h5)\n",
    "\n",
    "\n",
    "class RecVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 600, latent_dim = 200):\n",
    "        super(RecVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n",
    "        self.decoder = nn.Linear(latent_dim, input_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, user_ratings, beta=None, gamma=0.0005, dropout_rate=0.7, calculate_loss=True):\n",
    "        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)    \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_pred = self.decoder(z)\n",
    "\n",
    "        if calculate_loss:\n",
    "            if gamma:\n",
    "                norm = user_ratings.sum(dim=-1)\n",
    "                kl_weight = gamma * norm\n",
    "            elif beta:\n",
    "                kl_weight = beta\n",
    "\n",
    "            mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n",
    "            kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n",
    "            negative_elbo = -(mll - kld)\n",
    "            \n",
    "            return (mll, kld), negative_elbo\n",
    "            \n",
    "        else:\n",
    "            return x_pred\n",
    "\n",
    "    def update_prior(self):\n",
    "        self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwSexh43u9vk"
   },
   "source": [
    "# 4. 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nws4JO2_rgQP"
   },
   "outputs": [],
   "source": [
    "def get_ndcg(pred_list, true_list):\n",
    "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
    "    dcg = 0\n",
    "    for rank, pred in enumerate(pred_list):\n",
    "        if pred in true_list:\n",
    "            dcg += 1 / np.log2(rank + 2)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "# hit == recall == precision\n",
    "def get_hit(pred_list, true_list):\n",
    "    hit_list = set(true_list) & set(pred_list)\n",
    "    hit = len(hit_list) / len(true_list)\n",
    "    return hit\n",
    "\n",
    "\n",
    "def evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "    AutoRec.eval()\n",
    "    MultiDAE.eval()\n",
    "    MultiVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    NDCG = 0.0 # NDCG@10\n",
    "    HIT = 0.0 # HIT@10\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "    recon_mat6 = recon_mat6.cpu().detach()\n",
    "    recon_mat6[mat == 1] = -np.inf\n",
    "    rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li * 0.25\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li * 0.25\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li * 0.2\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li * 0.1\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li * 0.1\n",
    "        movie_df.loc[rec6, 'rec6_score'] = score_li * 0.1\n",
    "        movie_df = movie_df.fillna(min(score_li) * 0.1)\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score'] + movie_df['rec6_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT\n",
    "\n",
    "def predict(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, candidate_cnt):\n",
    "    user2rec = {}\n",
    "\n",
    "    RecVAE.eval()\n",
    "    AutoRec.eval()\n",
    "    MultiDAE.eval()\n",
    "    MultiVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "    recon_mat6 = recon_mat6.cpu().detach()\n",
    "    recon_mat6[mat == 1] = -np.inf\n",
    "    rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "        \n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li * 0.25\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li * 0.25\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li * 0.2\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li * 0.1\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li * 0.1\n",
    "        movie_df.loc[rec6, 'rec6_score'] = score_li * 0.1\n",
    "        movie_df = movie_df.fillna(min(score_li) * 0.1)\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score'] + movie_df['rec6_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        user2rec[user] = up\n",
    "\n",
    "    return user2rec\n",
    "\n",
    "\n",
    "def total_evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "    AutoRec.eval()\n",
    "    MultiDAE.eval()\n",
    "    MultiVAE.eval()\n",
    "\n",
    "    df = []\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "    recon_mat6 = recon_mat6.cpu().detach()\n",
    "    recon_mat6[mat == 1] = -np.inf\n",
    "    rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        rec123456 = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "        df.append(\n",
    "            {\n",
    "               'user' : user,\n",
    "               'len' : len(rec123456),\n",
    "\n",
    "               'rec1' : get_hit(pred_list = rec1, true_list = uv),\n",
    "               'rec2' : get_hit(pred_list = rec2, true_list = uv),\n",
    "               'rec3' : get_hit(pred_list = rec3, true_list = uv),\n",
    "               'rec4' : get_hit(pred_list = rec4, true_list = uv),\n",
    "               'rec5' : get_hit(pred_list = rec5, true_list = uv),\n",
    "               'rec6' : get_hit(pred_list = rec6, true_list = uv),\n",
    "\n",
    "               'rec123456' : get_hit(pred_list = rec123456, true_list = uv),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# def evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X_df, y_df, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     NDCG = 0.0 # NDCG@10\n",
    "#     HIT = 0.0 # HIT@10\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     copy_recon_mat1 = deepcopy(recon_mat1.sigmoid())\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     copy_recon_mat2 = deepcopy(recon_mat2.sigmoid())\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     copy_recon_mat3 = deepcopy(recon_mat3.sigmoid())\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     copy_recon_mat4 = deepcopy(recon_mat4.sigmoid())\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     copy_recon_mat5 = deepcopy(recon_mat5.sigmoid())\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     copy_recon_mat6 = deepcopy(recon_mat6.sigmoid())\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "\n",
    "#         cif = DecisionTreeClassifier(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "#         score_li = np.array([[copy_recon_mat1.numpy()[user][item], copy_recon_mat2.numpy()[user][item], copy_recon_mat3.numpy()[user][item] , copy_recon_mat4.numpy()[user][item] , copy_recon_mat5.numpy()[user][item] , copy_recon_mat6.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "#         HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "#     NDCG /= len(user_train)\n",
    "#     HIT /= len(user_train)\n",
    "\n",
    "#     return NDCG, HIT\n",
    "\n",
    "\n",
    "# def predict(model1, model2, RecVAE, X_df, y_df, X, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "\n",
    "#     user2rec = {}\n",
    "\n",
    "#     neg = torch.from_numpy(1 - X)\n",
    "#     pos = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     score1 = recon_mat1 * neg\n",
    "#     rec_list1 = score1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     score2 = recon_mat2 * neg\n",
    "#     rec_list2 = score2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(pos.to(device), calculate_loss = False).cpu().detach()\n",
    "#     score3 = recon_mat3 * neg\n",
    "#     rec_list3 = score3.argsort(dim = 1)\n",
    "\n",
    "#     for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "\n",
    "#         cif = LogisticRegression(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3))\n",
    "#         score_li = np.array([[recon_mat1.numpy()[user][item], recon_mat2.numpy()[user][item], recon_mat3.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "        \n",
    "#         user2rec[user] = up\n",
    "\n",
    "#     return user2rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gupkaJHMslCi"
   },
   "source": [
    "# 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "model4.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = MultiDAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = MultiVAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model6.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [00:01, 19314.52it/s]\n"
     ]
    }
   ],
   "source": [
    "df = total_evaluate(\n",
    "    model1 = model1,\n",
    "    model2 = model2,\n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4,\n",
    "    MultiDAE = model5,\n",
    "    MultiVAE = model6,\n",
    "    X = X.todense(),\n",
    "    user_train = user_train,\n",
    "    user_valid = user_valid,\n",
    "    candidate_cnt = 10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>len</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec6</th>\n",
       "      <th>rec123456</th>\n",
       "      <th>total_val</th>\n",
       "      <th>total_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>31355</td>\n",
       "      <td>17</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>31356</td>\n",
       "      <td>26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>31357</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>31358</td>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>31359</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  len  rec1  rec2  rec3  rec4  rec5  rec6  rec123456  total_val  \\\n",
       "0          0   27   0.3   0.3   0.2   0.2   0.2   0.2        0.5        0.3   \n",
       "1          1   23   0.1   0.1   0.2   0.1   0.1   0.1        0.2        0.2   \n",
       "2          2   22   0.3   0.3   0.3   0.3   0.2   0.1        0.3        0.3   \n",
       "3          3   19   0.3   0.3   0.2   0.2   0.2   0.2        0.4        0.3   \n",
       "4          4   23   0.4   0.3   0.4   0.3   0.5   0.4        0.5        0.5   \n",
       "...      ...  ...   ...   ...   ...   ...   ...   ...        ...        ...   \n",
       "31355  31355   17   0.2   0.4   0.2   0.2   0.2   0.2        0.4        0.4   \n",
       "31356  31356   26   0.3   0.3   0.3   0.2   0.5   0.0        0.5        0.5   \n",
       "31357  31357   21   0.2   0.3   0.2   0.1   0.1   0.1        0.3        0.3   \n",
       "31358  31358   23   0.1   0.1   0.0   0.0   0.0   0.0        0.1        0.1   \n",
       "31359  31359   35   0.0   0.2   0.1   0.0   0.1   0.0        0.2        0.2   \n",
       "\n",
       "      total_name  \n",
       "0           rec1  \n",
       "1           rec3  \n",
       "2           rec1  \n",
       "3           rec1  \n",
       "4           rec5  \n",
       "...          ...  \n",
       "31355       rec2  \n",
       "31356       rec5  \n",
       "31357       rec2  \n",
       "31358       rec1  \n",
       "31359       rec2  \n",
       "\n",
       "[31360 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저들 마다 rec1 or rec2 or rec3 or ranking 등 맞는 방법에 따라사 추천을 해주는 것도 좋은 방법이 될 수 있음\n",
    "\n",
    "new_df = pd.DataFrame(df)\n",
    "\n",
    "def get_total_name(x):\n",
    "    val_list = [x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5'] , x['rec6']]\n",
    "    max_val = max(val_list)\n",
    "    val_idx = val_list.index(max_val)\n",
    "    if val_idx == 0 : return 'rec1'\n",
    "    elif val_idx == 1 : return 'rec2'\n",
    "    elif val_idx == 2 : return 'rec3'\n",
    "    elif val_idx == 3 : return 'rec4'\n",
    "    elif val_idx == 4 : return 'rec5'\n",
    "    elif val_idx == 5 : return 'rec6'\n",
    "\n",
    "new_df['total_val'] = new_df.apply(lambda x: max(x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5'] , x['rec6']), axis = 1)\n",
    "new_df['total_name'] = new_df.apply(lambda x: get_total_name(x), axis = 1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.histplot(data = new_df[[\"rec1\", \"rec2\", \"rec3\", \"rec4\", \"rec5\", \"rec6\", 'rec123456', 'total_val']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec1    16391\n",
       "rec3     4737\n",
       "rec2     3913\n",
       "rec5     2433\n",
       "rec4     2162\n",
       "rec6     1724\n",
       "Name: total_name, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['total_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         15679.500000\n",
       "len             24.823884\n",
       "rec1             0.203839\n",
       "rec2             0.200207\n",
       "rec3             0.192140\n",
       "rec4             0.174758\n",
       "rec5             0.172388\n",
       "rec6             0.174767\n",
       "rec123456        0.313935\n",
       "total_val        0.263115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = np.concatenate([np.repeat(i, 6807) for i in range(31360)])\n",
    "\n",
    "# model1_score = model1.pred.sigmoid().cpu().numpy().reshape(-1)\n",
    "\n",
    "# model2_score = model2.pred.T.sigmoid().cpu().numpy().reshape(-1)\n",
    "\n",
    "# model3_score = model3(torch.from_numpy(X.todense()).to(device), calculate_loss = False).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model4_score = model4(torch.from_numpy(X.todense()).to(device)).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model5_score = model5(torch.from_numpy(X.todense()).to(device)).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model6_score, _, _ = model6(torch.from_numpy(X.todense()).to(device))\n",
    "# model6_score = model6_score.sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# X_df = np.concatenate([\n",
    "#     users.reshape(-1, 1), \n",
    "#     model1_score.reshape(-1, 1), \n",
    "#     model2_score.reshape(-1, 1), \n",
    "#     model3_score.reshape(-1, 1), \n",
    "#     model4_score.reshape(-1, 1), \n",
    "#     model5_score.reshape(-1, 1),\n",
    "#     model6_score.reshape(-1, 1)], axis = 1)\n",
    "\n",
    "# y_df = X.toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre = pd.read_csv(os.path.join(config.data_path, 'genres.tsv'), sep='\\t')\n",
    "# genre['genres'] = 1\n",
    "# genre['item_idx'] = genre['item'].apply(lambda x : make_matrix_data_set.item_encoder[x])\n",
    "# genre = pd.pivot_table(genre, values='genres', index=['item_idx'], columns=['genre'], aggfunc=np.sum, fill_value=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [16:22, 31.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.17573| HIT@10: 0.13605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# candidate_cnt = 10\n",
    "\n",
    "# ndcg, hit = evaluate(\n",
    "#             model1 = model1, \n",
    "#             model2 = model2, \n",
    "#             RecVAE = model3,\n",
    "#             AutoRec = model4,\n",
    "#             MultiDAE = model5,\n",
    "#             MultiVAE = model6,\n",
    "#             X_df = X_df, \n",
    "#             y_df = y_df,\n",
    "#             X = X.todense(),\n",
    "#             user_train = user_train, \n",
    "#             user_valid = user_valid, \n",
    "#             candidate_cnt = candidate_cnt)\n",
    "\n",
    "# print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for candidate_cnt in [5 * i for i in range(3, 21)]:\n",
    "#     ndcg, hit = evaluate(\n",
    "#             model1 = model1, \n",
    "#             model2 = model2, \n",
    "#             RecVAE = model3,\n",
    "#             X_df = X_df,\n",
    "#             y_df = y_df,\n",
    "#             X = X.todense(),\n",
    "#             user_train = user_train, \n",
    "#             user_valid = user_valid, \n",
    "#             candidate_cnt = candidate_cnt)\n",
    "\n",
    "#     print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [04:17, 121.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.29828| HIT@10: 0.19009\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 30\n",
    "\n",
    "ndcg, hit = evaluate(\n",
    "            model1 = model1, \n",
    "            model2 = model2, \n",
    "            RecVAE = model3,\n",
    "            AutoRec = model4,\n",
    "            MultiDAE = model5,\n",
    "            MultiVAE = model6,\n",
    "            X = X.todense(),\n",
    "            user_train = user_train, \n",
    "            user_valid = user_valid, \n",
    "            candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "                model1 = model1,\n",
    "                model2 = model2, \n",
    "                RecVAE = model3,\n",
    "                AutoRec = model4,\n",
    "                MultiDAE = model5,\n",
    "                MultiVAE = model6,\n",
    "                X = X.todense(),\n",
    "                user_train = user_train, \n",
    "                user_valid = user_valid, \n",
    "                candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weighted Ensemble 조합 찾는 코드 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델+ log2(rank + 1) + weighted Ensemble (0.25, 0.25, 0.2, 0.1, 0.1, 0.1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31753| HIT@10: 0.20782\n",
    "candidate_cnt: 15| NDCG@10: 0.31839| HIT@10: 0.20871\n",
    "candidate_cnt: 20| NDCG@10: 0.31884| HIT@10: 0.20924\n",
    "candidate_cnt: 25| NDCG@10: 0.31889| HIT@10: 0.20930\n",
    "candidate_cnt: 30| NDCG@10: 0.31911| HIT@10: 0.20956\n",
    "candidate_cnt: 35| NDCG@10: 0.31907| HIT@10: 0.20955\n",
    "candidate_cnt: 40| NDCG@10: 0.31901| HIT@10: 0.20949\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델 + voting\n",
    "candidate_cnt: 10| NDCG@10: 0.29867| HIT@10: 0.20497\n",
    "candidate_cnt: 15| NDCG@10: 0.28563| HIT@10: 0.20339\n",
    "candidate_cnt: 20| NDCG@10: 0.27253| HIT@10: 0.19996\n",
    "candidate_cnt: 25| NDCG@10: 0.25738| HIT@10: 0.19344\n",
    "candidate_cnt: 30| NDCG@10: 0.24171| HIT@10: 0.18377\n",
    "candidate_cnt: 35| NDCG@10: 0.22492| HIT@10: 0.17286\n",
    "candidate_cnt: 40| NDCG@10: 0.20953| HIT@10: 0.16214\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델 + log2(rank + 1)\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.30926| HIT@10: 0.20194\n",
    "candidate_cnt: 15| NDCG@10: 0.31167| HIT@10: 0.20401\n",
    "candidate_cnt: 20| NDCG@10: 0.31282| HIT@10: 0.20501\n",
    "candidate_cnt: 25| NDCG@10: 0.31330| HIT@10: 0.20542\n",
    "candidate_cnt: 30| NDCG@10: 0.31366| HIT@10: 0.20572\n",
    "candidate_cnt: 35| NDCG@10: 0.31382| HIT@10: 0.20584\n",
    "candidate_cnt: 40| NDCG@10: 0.31397| HIT@10: 0.20594\n",
    "candidate_cnt: 45| NDCG@10: 0.31408| HIT@10: 0.20603\n",
    "candidate_cnt: 50| NDCG@10: 0.31416| HIT@10: 0.20611\n",
    "candidate_cnt: 55| NDCG@10: 0.31422| HIT@10: 0.20613\n",
    "candidate_cnt: 60| NDCG@10: 0.31427| HIT@10: 0.20618\n",
    "candidate_cnt: 65| NDCG@10: 0.31430| HIT@10: 0.20620\n",
    "candidate_cnt: 70| NDCG@10: 0.31435| HIT@10: 0.20623\n",
    "candidate_cnt: 75| NDCG@10: 0.31435| HIT@10: 0.20624\n",
    "candidate_cnt: 80| NDCG@10: 0.31438| HIT@10: 0.20627\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "EASE2개 + RecVAE-v3 + log2(rank + 1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31412| HIT@10: 0.20595\n",
    "candidate_cnt: 15| NDCG@10: 0.31573| HIT@10: 0.20745\n",
    "candidate_cnt: 20| NDCG@10: 0.31644| HIT@10: 0.20807\n",
    "candidate_cnt: 25| NDCG@10: 0.31687| HIT@10: 0.20851\n",
    "candidate_cnt: 30| NDCG@10: 0.31696| HIT@10: 0.20863\n",
    "candidate_cnt: 35| NDCG@10: 0.31708| HIT@10: 0.20872\n",
    "candidate_cnt: 40| NDCG@10: 0.31712| HIT@10: 0.20878\n",
    "candidate_cnt: 45| NDCG@10: 0.31717| HIT@10: 0.20882\n",
    "candidate_cnt: 50| NDCG@10: 0.31723| HIT@10: 0.20886\n",
    "candidate_cnt: 55| NDCG@10: 0.31723| HIT@10: 0.20884\n",
    "candidate_cnt: 60| NDCG@10: 0.31726| HIT@10: 0.20887\n",
    "candidate_cnt: 65| NDCG@10: 0.31729| HIT@10: 0.20888\n",
    "candidate_cnt: 70| NDCG@10: 0.31727| HIT@10: 0.20887\n",
    "candidate_cnt: 75| NDCG@10: 0.31730| HIT@10: 0.20889\n",
    "candidate_cnt: 80| NDCG@10: 0.31730| HIT@10: 0.20890\n",
    "candidate_cnt: 85| NDCG@10: 0.31733| HIT@10: 0.20888\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "EASE2개 + RecVAE-v5 + log2(rank + 1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "candidate_cnt: 15| NDCG@10: 0.31518| HIT@10: 0.20735\n",
    "candidate_cnt: 20| NDCG@10: 0.31569| HIT@10: 0.20779\n",
    "candidate_cnt: 25| NDCG@10: 0.31605| HIT@10: 0.20812\n",
    "candidate_cnt: 30| NDCG@10: 0.31616| HIT@10: 0.20822\n",
    "candidate_cnt: 35| NDCG@10: 0.31627| HIT@10: 0.20833\n",
    "candidate_cnt: 40| NDCG@10: 0.31636| HIT@10: 0.20843\n",
    "candidate_cnt: 45| NDCG@10: 0.31643| HIT@10: 0.20846\n",
    "candidate_cnt: 50| NDCG@10: 0.31644| HIT@10: 0.20848\n",
    "candidate_cnt: 55| NDCG@10: 0.31653| HIT@10: 0.20854\n",
    "candidate_cnt: 60| NDCG@10: 0.31657| HIT@10: 0.20857\n",
    "candidate_cnt: 65| NDCG@10: 0.31652| HIT@10: 0.20856\n",
    "candidate_cnt: 70| NDCG@10: 0.31653| HIT@10: 0.20856\n",
    "candidate_cnt: 75| NDCG@10: 0.31651| HIT@10: 0.20855\n",
    "candidate_cnt: 80| NDCG@10: 0.31658| HIT@10: 0.20858\n",
    "candidate_cnt: 85| NDCG@10: 0.31660| HIT@10: 0.20859\n",
    "candidate_cnt: 90| NDCG@10: 0.31658| HIT@10: 0.20860\n",
    "candidate_cnt: 95| NDCG@10: 0.31662| HIT@10: 0.20862\n",
    "candidate_cnt: 100| NDCG@10: 0.31658| HIT@10: 0.20861\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "none + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31411| HIT@10: 0.20686\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31568| HIT@10: 0.20702\n",
    "```\n",
    "\n",
    "```\n",
    "softmax + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.28598| HIT@10: 0.19227\n",
    "```\n",
    "\n",
    "```\n",
    "none + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31381| HIT@10: 0.20633\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31469| HIT@10: 0.20636\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[147, 197, 188, 313, 228, 273, 189, 114, 42, 242]\n",
    "\n",
    "```\n",
    "non softmax\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.902873     0.411256     1.314129\n",
    "42    0.815624     0.411256     1.226880\n",
    "933   0.981398     0.172427     1.153824\n",
    "718   0.671753     0.402721     1.074474\n",
    "484   0.923667     0.149443     1.073110\n",
    "376   0.883676     0.173539     1.057215\n",
    "667   0.919388     0.097644     1.017032\n",
    "650   0.855481     0.151946     1.007427\n",
    "2200  0.878635     0.125442     1.004077\n",
    "714   0.719053     0.210817     0.929870\n",
    "1844  0.698690     0.226953     0.925643\n",
    "273   0.810516     0.097710     0.908226\n",
    "760   0.763495     0.036601     0.800096\n",
    "313   0.766302     0.027069     0.793371\n",
    "777   0.641927     0.142652     0.784579\n",
    "228   0.733693     0.044058     0.777750\n",
    "734   0.738835     0.031143     0.769978\n",
    "1354  0.438386     0.122450     0.560836\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "softmax\n",
    "\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.053804     0.411256     0.465060\n",
    "42    0.053799     0.411256     0.465055\n",
    "718   0.053844     0.402721     0.456565\n",
    "1844  0.053790     0.226953     0.280743\n",
    "714   0.053817     0.210817     0.264634\n",
    "376   0.053824     0.173539     0.227363\n",
    "933   0.053912     0.172427     0.226339\n",
    "650   0.053820     0.151946     0.205766\n",
    "484   0.053827     0.149443     0.203270\n",
    "777   0.053828     0.142652     0.196481\n",
    "2200  0.053810     0.125442     0.179252\n",
    "1354  0.053825     0.122450     0.176275\n",
    "273   0.053800     0.097710     0.151510\n",
    "667   0.053807     0.097644     0.151450\n",
    "228   0.053814     0.044058     0.097871\n",
    "760   0.053811     0.036601     0.090412\n",
    "734   0.053804     0.031143     0.084947\n",
    "313   0.053817     0.027069     0.080885\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X_test, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X_test.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "model4.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = MultiDAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = MultiVAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model6.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:57, 176.98it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4, \n",
    "    MultiDAE = model5, \n",
    "    MultiVAE = model6,\n",
    "    X = X_test.todense(),\n",
    "    candidate_cnt = 30,)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>27660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11   4886\n",
       "2           11  40815\n",
       "3           11   7373\n",
       "4           11      2\n",
       "...        ...    ...\n",
       "313595  138493    589\n",
       "313596  138493  27660\n",
       "313597  138493   8961\n",
       "313598  138493   5349\n",
       "313599  138493   1022\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
