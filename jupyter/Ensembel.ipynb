{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ug-br-pPu9vZ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from box import Box\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbRKDSg4u9vc"
   },
   "source": [
    "# 1. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MEhK_fLIu9vd"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n",
    "    'model_path' : \"../model\",\n",
    "\n",
    "\n",
    "    'submission_path' : \"../submission\",\n",
    "    'submission_name' : 'Ensembel_v3_submission.csv',\n",
    "\n",
    "    'candidate_item_num' : 50,\n",
    "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
    "    'seed' : 22,\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjDxy0fJu9vf"
   },
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W64BYWl0u9vg"
   },
   "outputs": [],
   "source": [
    "class MakeMatrixDataSet():\n",
    "    \"\"\"\n",
    "    MatrixDataSet 생성\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n",
    "        \n",
    "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n",
    "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n",
    "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
    "\n",
    "        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n",
    "        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n",
    "\n",
    "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
    "\n",
    "    def generate_encoder_decoder(self, col : str) -> dict:\n",
    "        \"\"\"\n",
    "        encoder, decoder 생성\n",
    "\n",
    "        Args:\n",
    "            col (str): 생성할 columns 명\n",
    "        Returns:\n",
    "            dict: 생성된 user encoder, decoder\n",
    "        \"\"\"\n",
    "\n",
    "        encoder = {}\n",
    "        decoder = {}\n",
    "        ids = self.df[col].unique()\n",
    "\n",
    "        for idx, _id in enumerate(ids):\n",
    "            encoder[_id] = idx\n",
    "            decoder[idx] = _id\n",
    "\n",
    "        return encoder, decoder\n",
    "    \n",
    "    def generate_sequence_data(self) -> dict:\n",
    "        \"\"\"\n",
    "        sequence_data 생성\n",
    "\n",
    "        Returns:\n",
    "            dict: train user sequence / valid user sequence\n",
    "        \"\"\"\n",
    "        users = defaultdict(list)\n",
    "        user_train = {}\n",
    "        user_valid = {}\n",
    "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n",
    "            users[user].append(item)\n",
    "        \n",
    "        for user in users:\n",
    "            np.random.seed(self.config.seed)\n",
    "\n",
    "            user_total = users[user]\n",
    "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
    "            train = list(set(user_total) - set(valid))\n",
    "\n",
    "            user_train[user] = train\n",
    "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
    "\n",
    "        return user_train, user_valid\n",
    "    \n",
    "    def get_train_valid_data(self):\n",
    "        return self.user_train, self.user_valid\n",
    "\n",
    "    def make_matrix(self, user_list, train = True):\n",
    "        \"\"\"\n",
    "        user_item_dict를 바탕으로 행렬 생성\n",
    "        \"\"\"\n",
    "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
    "        for idx, user in enumerate(user_list):\n",
    "            if train:\n",
    "                mat[idx, self.user_train[user.item()]] = 1\n",
    "            else:\n",
    "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
    "        return mat\n",
    "\n",
    "    def make_sparse_matrix(self, test = False):\n",
    "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
    "        \n",
    "        for user in self.user_train.keys():\n",
    "            item_list = self.user_train[user]\n",
    "            X[user, item_list] = 1.0\n",
    "        \n",
    "        if test:\n",
    "            for user in self.user_valid.keys():\n",
    "                item_list = self.user_valid[user]\n",
    "                X[user, item_list] = 1.0\n",
    "\n",
    "        return X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IldCGmY8u9vh"
   },
   "outputs": [],
   "source": [
    "class AEDataSet(Dataset):\n",
    "    def __init__(self, num_user):\n",
    "        self.num_user = num_user\n",
    "        self.users = [i for i in range(num_user)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_user\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        user = self.users[idx]\n",
    "        return torch.LongTensor([user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysia457Su9vi"
   },
   "source": [
    "# 3. 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE():\n",
    "    def __init__(self, X, reg):\n",
    "        self.X = self._convert_sp_mat_to_sp_tensor(X)\n",
    "        self.reg = reg\n",
    "    \n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        \"\"\"\n",
    "        Convert scipy sparse matrix to PyTorch sparse matrix\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        X = Adjacency matrix, scipy sparse matrix\n",
    "        \"\"\"\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "        v = torch.FloatTensor(coo.data)\n",
    "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "        return res\n",
    "    \n",
    "    def fit(self):\n",
    "        '''\n",
    "\n",
    "        진짜 정말 간단한 식으로 모델을 만듬\n",
    "\n",
    "        '''\n",
    "        G = self.X.to_dense().t() @ self.X.to_dense()\n",
    "        diagIndices = torch.eye(G.shape[0]) == 1\n",
    "        G[diagIndices] += self.reg\n",
    "\n",
    "        P = G.inverse()\n",
    "        B = P / (-1 * P.diag())\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.pred = self.X.to_dense() @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x.mul(torch.sigmoid(x))\n",
    "\n",
    "def log_norm_pdf(x, mu, logvar):\n",
    "    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n",
    "\n",
    "class CompositePrior(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n",
    "        super(CompositePrior, self).__init__()\n",
    "        \n",
    "        self.mixture_weights = mixture_weights\n",
    "        \n",
    "        self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.mu_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_uniform_prior.data.fill_(10)\n",
    "        \n",
    "        self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.encoder_old.requires_grad_(False)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "\n",
    "        post_mu, post_logvar = self.encoder_old(x, dropout_rate = 0)\n",
    "\n",
    "        stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n",
    "        post_prior = log_norm_pdf(z, post_mu, post_logvar)\n",
    "        unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n",
    "        \n",
    "        gaussians = [stnd_prior, post_prior, unif_prior]\n",
    "        gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n",
    "\n",
    "        density_per_gaussian = torch.stack(gaussians, dim=-1)\n",
    "\n",
    "        return torch.logsumexp(density_per_gaussian, dim=-1)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x, dropout_rate):\n",
    "        norm = x.pow(2).sum(dim=-1).sqrt()\n",
    "        x = x / norm[:, None]\n",
    "    \n",
    "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "        \n",
    "        h1 = self.ln1(swish(self.fc1(x)))\n",
    "        h2 = self.ln2(swish(self.fc2(h1) + h1))\n",
    "        h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n",
    "        h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n",
    "        h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n",
    "        return self.fc_mu(h5), self.fc_logvar(h5)\n",
    "\n",
    "\n",
    "class RecVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 600, latent_dim = 200):\n",
    "        super(RecVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n",
    "        self.decoder = nn.Linear(latent_dim, input_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, user_ratings, beta=None, gamma=0.0005, dropout_rate=0.7, calculate_loss=True):\n",
    "        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)    \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_pred = self.decoder(z)\n",
    "\n",
    "        if calculate_loss:\n",
    "            if gamma:\n",
    "                norm = user_ratings.sum(dim=-1)\n",
    "                kl_weight = gamma * norm\n",
    "            elif beta:\n",
    "                kl_weight = beta\n",
    "\n",
    "            mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n",
    "            kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n",
    "            negative_elbo = -(mll - kld)\n",
    "            \n",
    "            return (mll, kld), negative_elbo\n",
    "            \n",
    "        else:\n",
    "            return x_pred\n",
    "\n",
    "    def update_prior(self):\n",
    "        self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwSexh43u9vk"
   },
   "source": [
    "# 4. 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nws4JO2_rgQP"
   },
   "outputs": [],
   "source": [
    "def get_ndcg(pred_list, true_list):\n",
    "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
    "    dcg = 0\n",
    "    for rank, pred in enumerate(pred_list):\n",
    "        if pred in true_list:\n",
    "            dcg += 1 / np.log2(rank + 2)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "# hit == recall == precision\n",
    "def get_hit(pred_list, true_list):\n",
    "    hit_list = set(true_list) & set(pred_list)\n",
    "    hit = len(hit_list) / len(true_list)\n",
    "    return hit\n",
    "\n",
    "\n",
    "def evaluate(model1, model2, RecVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    NDCG = 0.0 # NDCG@10\n",
    "    HIT = 0.0 # HIT@10\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li\n",
    "        movie_df = movie_df.fillna(min(score_li))\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT\n",
    "\n",
    "def predict(model1, model2, RecVAE, X, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "\n",
    "    user2rec = {}\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li\n",
    "        movie_df = movie_df.fillna(min(score_li))\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        user2rec[user] = up\n",
    "\n",
    "    return user2rec\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# def evaluate(model1, model2, RecVAE, X_df, y_df, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     NDCG = 0.0 # NDCG@10\n",
    "#     HIT = 0.0 # HIT@10\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     copy_recon_mat1 = deepcopy(recon_mat1)\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     copy_recon_mat2 = deepcopy(recon_mat2)\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     copy_recon_mat3 = deepcopy(recon_mat3.tanh())\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "\n",
    "#         cif = LogisticRegression(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3))\n",
    "#         score_li = np.array([[copy_recon_mat1.numpy()[user][item], copy_recon_mat2.numpy()[user][item], copy_recon_mat3.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "#         HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "#     NDCG /= len(user_train)\n",
    "#     HIT /= len(user_train)\n",
    "\n",
    "#     return NDCG, HIT\n",
    "\n",
    "\n",
    "# def predict(model1, model2, RecVAE, X_df, y_df, X, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "\n",
    "#     user2rec = {}\n",
    "\n",
    "#     neg = torch.from_numpy(1 - X)\n",
    "#     pos = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     score1 = recon_mat1 * neg\n",
    "#     rec_list1 = score1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     score2 = recon_mat2 * neg\n",
    "#     rec_list2 = score2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(pos.to(device), calculate_loss = False).cpu().detach()\n",
    "#     score3 = recon_mat3 * neg\n",
    "#     rec_list3 = score3.argsort(dim = 1)\n",
    "\n",
    "#     for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "\n",
    "#         cif = LogisticRegression(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3))\n",
    "#         score_li = np.array([[recon_mat1.numpy()[user][item], recon_mat2.numpy()[user][item], recon_mat3.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "        \n",
    "#         user2rec[user] = up\n",
    "\n",
    "#     return user2rec\n",
    "\n",
    "\n",
    "def total_evaluate(model1, model2, RecVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "    \n",
    "    rec1_NDCG = 0.0 # NDCG@10\n",
    "    rec1_HIT = 0.0 # HIT@10\n",
    "\n",
    "    rec2_NDCG = 0.0 # NDCG@10\n",
    "    rec2_HIT = 0.0 # HIT@10\n",
    "\n",
    "    rec3_NDCG = 0.0 # NDCG@10\n",
    "    rec3_HIT = 0.0 # HIT@10\n",
    "\n",
    "    rec12_NDCG = 0.0 # NDCG@10\n",
    "    rec12_HIT = 0.0 # HIT@10\n",
    "\n",
    "    rec13_NDCG = 0.0 # NDCG@10\n",
    "    rec13_HIT = 0.0 # HIT@10\n",
    "\n",
    "    rec23_NDCG = 0.0 # NDCG@10\n",
    "    rec23_HIT = 0.0 # HIT@10\n",
    "\n",
    "    rec123_NDCG = 0.0 # NDCG@10\n",
    "    rec123_HIT = 0.0 # HIT@10\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "    \n",
    "    for user, (rec1, rec2, rec3) in enumerate(zip(rec_list1, rec_list2, rec_list3)):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        \n",
    "        rec12 = list(set(rec1 + rec2))\n",
    "        rec13 = list(set(rec1 + rec3))\n",
    "        rec23 = list(set(rec2 + rec3))\n",
    "\n",
    "        rec123 = list(set(rec1 + rec2 + rec3))\n",
    "\n",
    "        rec1_NDCG += get_ndcg(pred_list = rec1, true_list = uv)\n",
    "        rec1_HIT += get_hit(pred_list = rec1, true_list = uv)\n",
    "\n",
    "        rec2_NDCG += get_ndcg(pred_list = rec2, true_list = uv)\n",
    "        rec2_HIT += get_hit(pred_list = rec2, true_list = uv)\n",
    "\n",
    "        rec3_NDCG += get_ndcg(pred_list = rec3, true_list = uv)\n",
    "        rec3_HIT += get_hit(pred_list = rec3, true_list = uv)\n",
    "\n",
    "\n",
    "        rec12_NDCG += get_ndcg(pred_list = rec12, true_list = uv)\n",
    "        rec12_HIT += get_hit(pred_list = rec12, true_list = uv)\n",
    "\n",
    "        rec13_NDCG += get_ndcg(pred_list = rec13, true_list = uv)\n",
    "        rec13_HIT += get_hit(pred_list = rec13, true_list = uv)\n",
    "\n",
    "        rec23_NDCG += get_ndcg(pred_list = rec23, true_list = uv)\n",
    "        rec23_HIT += get_hit(pred_list = rec23, true_list = uv)\n",
    "\n",
    "\n",
    "        rec123_NDCG += get_ndcg(pred_list = rec123, true_list = uv)\n",
    "        rec123_HIT += get_hit(pred_list = rec123, true_list = uv)\n",
    "\n",
    "    print(f'rec1 | NDCG@10: {rec1_NDCG / len(user_train):.5f}| HIT@10: {rec1_HIT / len(user_train):.5f}')\n",
    "    print(f'rec2 | NDCG@10: {rec2_NDCG / len(user_train):.5f}| HIT@10: {rec2_HIT / len(user_train):.5f}')\n",
    "    print(f'rec3 | NDCG@10: {rec3_NDCG / len(user_train):.5f}| HIT@10: {rec3_HIT / len(user_train):.5f}')\n",
    "\n",
    "    print(f'rec12 | NDCG@10: {rec12_NDCG / len(user_train):.5f}| HIT@10: {rec12_HIT / len(user_train):.5f}')\n",
    "    print(f'rec13 | NDCG@10: {rec13_NDCG / len(user_train):.5f}| HIT@10: {rec13_HIT / len(user_train):.5f}')\n",
    "    print(f'rec23 | NDCG@10: {rec23_NDCG / len(user_train):.5f}| HIT@10: {rec23_HIT / len(user_train):.5f}')\n",
    "\n",
    "    print(f'rec123 | NDCG@10: {rec123_NDCG / len(user_train):.5f}| HIT@10: {rec123_HIT / len(user_train):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gupkaJHMslCi"
   },
   "source": [
    "# 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec1 | NDCG@10: 0.31055| HIT@10: 0.20384\n",
      "rec2 | NDCG@10: 0.30428| HIT@10: 0.20021\n",
      "rec3 | NDCG@10: 0.28574| HIT@10: 0.19214\n",
      "rec12 | NDCG@10: 0.23462| HIT@10: 0.22666\n",
      "rec13 | NDCG@10: 0.21648| HIT@10: 0.24872\n",
      "rec23 | NDCG@10: 0.21378| HIT@10: 0.24704\n",
      "rec123 | NDCG@10: 0.20457| HIT@10: 0.26235\n"
     ]
    }
   ],
   "source": [
    "total_evaluate(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    RecVAE = model3,\n",
    "    X = X.todense(),\n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid, \n",
    "    candidate_cnt = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = np.concatenate([np.repeat(i, 6807) for i in range(31360)])\n",
    "\n",
    "model1_score = model1.pred.sigmoid().cpu().numpy().reshape(-1)\n",
    "model2_score = model2.pred.T.sigmoid().cpu().numpy().reshape(-1)\n",
    "model3_score = model3(torch.from_numpy(X.todense()).to(device), calculate_loss = False).tanh().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "X_df = np.concatenate([users.reshape(-1, 1), model1_score.reshape(-1, 1), model2_score.reshape(-1, 1), model3_score.reshape(-1, 1)], axis = 1)\n",
    "y_df = X.toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre = pd.read_csv(os.path.join(config.data_path, 'genres.tsv'), sep='\\t')\n",
    "# genre['genres'] = 1\n",
    "# genre['item_idx'] = genre['item'].apply(lambda x : make_matrix_data_set.item_encoder[x])\n",
    "# genre = pd.pivot_table(genre, values='genres', index=['item_idx'], columns=['genre'], aggfunc=np.sum, fill_value=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [12:50, 40.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.31253| HIT@10: 0.20492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 10\n",
    "\n",
    "ndcg, hit = evaluate(\n",
    "                model1 = model1, \n",
    "                model2 = model2, \n",
    "                RecVAE = model3,\n",
    "                X_df = X_df, \n",
    "                y_df = y_df,\n",
    "                X = X.todense(),\n",
    "                user_train = user_train, \n",
    "                user_valid = user_valid, \n",
    "                candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "                model1 = model1, \n",
    "                model2 = model2, \n",
    "                RecVAE = model3,\n",
    "                X = X.todense(),\n",
    "                user_train = user_train, \n",
    "                user_valid = user_valid, \n",
    "                candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RecVAE-v3\n",
    "candidate_cnt: 10| NDCG@10: 0.31412| HIT@10: 0.20595\n",
    "candidate_cnt: 15| NDCG@10: 0.31573| HIT@10: 0.20745\n",
    "candidate_cnt: 20| NDCG@10: 0.31644| HIT@10: 0.20807\n",
    "candidate_cnt: 25| NDCG@10: 0.31687| HIT@10: 0.20851\n",
    "candidate_cnt: 30| NDCG@10: 0.31696| HIT@10: 0.20863\n",
    "candidate_cnt: 35| NDCG@10: 0.31708| HIT@10: 0.20872\n",
    "candidate_cnt: 40| NDCG@10: 0.31712| HIT@10: 0.20878\n",
    "candidate_cnt: 45| NDCG@10: 0.31717| HIT@10: 0.20882\n",
    "candidate_cnt: 50| NDCG@10: 0.31723| HIT@10: 0.20886\n",
    "candidate_cnt: 55| NDCG@10: 0.31723| HIT@10: 0.20884\n",
    "candidate_cnt: 60| NDCG@10: 0.31726| HIT@10: 0.20887\n",
    "candidate_cnt: 65| NDCG@10: 0.31729| HIT@10: 0.20888\n",
    "candidate_cnt: 70| NDCG@10: 0.31727| HIT@10: 0.20887\n",
    "candidate_cnt: 75| NDCG@10: 0.31730| HIT@10: 0.20889\n",
    "candidate_cnt: 80| NDCG@10: 0.31730| HIT@10: 0.20890\n",
    "candidate_cnt: 85| NDCG@10: 0.31733| HIT@10: 0.20888\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RecVAE-v5\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "candidate_cnt: 15| NDCG@10: 0.31518| HIT@10: 0.20735\n",
    "candidate_cnt: 20| NDCG@10: 0.31569| HIT@10: 0.20779\n",
    "candidate_cnt: 25| NDCG@10: 0.31605| HIT@10: 0.20812\n",
    "candidate_cnt: 30| NDCG@10: 0.31616| HIT@10: 0.20822\n",
    "candidate_cnt: 35| NDCG@10: 0.31627| HIT@10: 0.20833\n",
    "candidate_cnt: 40| NDCG@10: 0.31636| HIT@10: 0.20843\n",
    "candidate_cnt: 45| NDCG@10: 0.31643| HIT@10: 0.20846\n",
    "candidate_cnt: 50| NDCG@10: 0.31644| HIT@10: 0.20848\n",
    "candidate_cnt: 55| NDCG@10: 0.31653| HIT@10: 0.20854\n",
    "candidate_cnt: 60| NDCG@10: 0.31657| HIT@10: 0.20857\n",
    "candidate_cnt: 65| NDCG@10: 0.31652| HIT@10: 0.20856\n",
    "candidate_cnt: 70| NDCG@10: 0.31653| HIT@10: 0.20856\n",
    "candidate_cnt: 75| NDCG@10: 0.31651| HIT@10: 0.20855\n",
    "candidate_cnt: 80| NDCG@10: 0.31658| HIT@10: 0.20858\n",
    "candidate_cnt: 85| NDCG@10: 0.31660| HIT@10: 0.20859\n",
    "candidate_cnt: 90| NDCG@10: 0.31658| HIT@10: 0.20860\n",
    "candidate_cnt: 95| NDCG@10: 0.31662| HIT@10: 0.20862\n",
    "candidate_cnt: 100| NDCG@10: 0.31658| HIT@10: 0.20861\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "none + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31411| HIT@10: 0.20686\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31568| HIT@10: 0.20702\n",
    "```\n",
    "\n",
    "```\n",
    "softmax + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.28598| HIT@10: 0.19227\n",
    "```\n",
    "\n",
    "```\n",
    "none + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31381| HIT@10: 0.20633\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31469| HIT@10: 0.20636\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[147, 197, 188, 313, 228, 273, 189, 114, 42, 242]\n",
    "\n",
    "```\n",
    "non softmax\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.902873     0.411256     1.314129\n",
    "42    0.815624     0.411256     1.226880\n",
    "933   0.981398     0.172427     1.153824\n",
    "718   0.671753     0.402721     1.074474\n",
    "484   0.923667     0.149443     1.073110\n",
    "376   0.883676     0.173539     1.057215\n",
    "667   0.919388     0.097644     1.017032\n",
    "650   0.855481     0.151946     1.007427\n",
    "2200  0.878635     0.125442     1.004077\n",
    "714   0.719053     0.210817     0.929870\n",
    "1844  0.698690     0.226953     0.925643\n",
    "273   0.810516     0.097710     0.908226\n",
    "760   0.763495     0.036601     0.800096\n",
    "313   0.766302     0.027069     0.793371\n",
    "777   0.641927     0.142652     0.784579\n",
    "228   0.733693     0.044058     0.777750\n",
    "734   0.738835     0.031143     0.769978\n",
    "1354  0.438386     0.122450     0.560836\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "softmax\n",
    "\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.053804     0.411256     0.465060\n",
    "42    0.053799     0.411256     0.465055\n",
    "718   0.053844     0.402721     0.456565\n",
    "1844  0.053790     0.226953     0.280743\n",
    "714   0.053817     0.210817     0.264634\n",
    "376   0.053824     0.173539     0.227363\n",
    "933   0.053912     0.172427     0.226339\n",
    "650   0.053820     0.151946     0.205766\n",
    "484   0.053827     0.149443     0.203270\n",
    "777   0.053828     0.142652     0.196481\n",
    "2200  0.053810     0.125442     0.179252\n",
    "1354  0.053825     0.122450     0.176275\n",
    "273   0.053800     0.097710     0.151510\n",
    "667   0.053807     0.097644     0.151450\n",
    "228   0.053814     0.044058     0.097871\n",
    "760   0.053811     0.036601     0.090412\n",
    "734   0.053804     0.031143     0.084947\n",
    "313   0.053817     0.027069     0.080885\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(3, 21)]:\n",
    "    ndcg, hit = evaluate(\n",
    "            model1 = model1, \n",
    "            model2 = model2, \n",
    "            RecVAE = model3,\n",
    "            X_df = X_df,\n",
    "            y_df = y_df,\n",
    "            X = X.todense(),\n",
    "            user_train = user_train, \n",
    "            user_valid = user_valid, \n",
    "            candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([1, 2, 3, -np.inf]).argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Logistic + 'l2'\n",
    "\n",
    "candidate_cnt: 5| NDCG@10: 0.35450| HIT@10: 0.18291\n",
    "candidate_cnt: 10| NDCG@10: 0.31411| HIT@10: 0.20686\n",
    "candidate_cnt: 15| NDCG@10: 0.31367| HIT@10: 0.20634\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "log2(rank + 1)\n",
    "\n",
    "candidate_cnt: 5| NDCG@10: 0.35405| HIT@10: 0.18237\n",
    "candidate_cnt: 10| NDCG@10: 0.31403| HIT@10: 0.20607\n",
    "candidate_cnt: 15| NDCG@10: 0.31528| HIT@10: 0.20717\n",
    "candidate_cnt: 20| NDCG@10: 0.31590| HIT@10: 0.20775\n",
    "candidate_cnt: 25| NDCG@10: 0.31634| HIT@10: 0.20822\n",
    "candidate_cnt: 30| NDCG@10: 0.31650| HIT@10: 0.20833\n",
    "candidate_cnt: 35| NDCG@10: 0.31657| HIT@10: 0.20840\n",
    "candidate_cnt: 40| NDCG@10: 0.31667| HIT@10: 0.20850\n",
    "candidate_cnt: 45| NDCG@10: 0.31669| HIT@10: 0.20852\n",
    "candidate_cnt: 50| NDCG@10: 0.31672| HIT@10: 0.20852\n",
    "candidate_cnt: 55| NDCG@10: 0.31676| HIT@10: 0.20859\n",
    "candidate_cnt: 60| NDCG@10: 0.31678| HIT@10: 0.20856\n",
    "candidate_cnt: 65| NDCG@10: 0.31674| HIT@10: 0.20855\n",
    "candidate_cnt: 70| NDCG@10: 0.31675| HIT@10: 0.20855\n",
    "candidate_cnt: 75| NDCG@10: 0.31673| HIT@10: 0.20856\n",
    "candidate_cnt: 80| NDCG@10: 0.31677| HIT@10: 0.20855\n",
    "candidate_cnt: 85| NDCG@10: 0.31676| HIT@10: 0.20856\n",
    "candidate_cnt: 90| NDCG@10: 0.31679| HIT@10: 0.20856\n",
    "candidate_cnt: 95| NDCG@10: 0.31678| HIT@10: 0.20857\n",
    "candidate_cnt: 100| NDCG@10: 0.31677| HIT@10: 0.20856\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X_test, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X_test.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = np.concatenate([np.repeat(i, 6807) for i in range(31360)])\n",
    "\n",
    "# model1_score = model1.pred.cpu().numpy().reshape(-1)\n",
    "# model2_score = model2.pred.T.cpu().numpy().reshape(-1)\n",
    "# model3_score = model3(torch.from_numpy(X_test.todense()).to(device), calculate_loss = False).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# X_df = np.concatenate([users.reshape(-1, 1), model1_score.reshape(-1, 1), model2_score.reshape(-1, 1), model3_score.reshape(-1, 1)], axis = 1)\n",
    "# y_df = X_test.toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [01:46, 294.11it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    RecVAE = model3,\n",
    "    X = X_test.todense(),\n",
    "    candidate_cnt = 50)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11   4886\n",
       "2           11  40815\n",
       "3           11   7373\n",
       "4           11   8961\n",
       "...        ...    ...\n",
       "313595  138493   8961\n",
       "313596  138493    110\n",
       "313597  138493   5349\n",
       "313598  138493   1022\n",
       "313599  138493   8970\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
