{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ug-br-pPu9vZ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from box import Box\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbRKDSg4u9vc"
   },
   "source": [
    "# 1. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MEhK_fLIu9vd"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n",
    "    'model_path' : \"../model\",\n",
    "\n",
    "\n",
    "    'submission_path' : \"../submission\",\n",
    "    'submission_name' : 'Ensembel_v11_submission.csv',\n",
    "\n",
    "    'candidate_item_num' : 50,\n",
    "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
    "    'seed' : 22,\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjDxy0fJu9vf"
   },
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W64BYWl0u9vg"
   },
   "outputs": [],
   "source": [
    "class MakeMatrixDataSet():\n",
    "    \"\"\"\n",
    "    MatrixDataSet 생성\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n",
    "        \n",
    "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n",
    "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n",
    "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
    "\n",
    "        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n",
    "        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n",
    "\n",
    "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
    "\n",
    "    def generate_encoder_decoder(self, col : str) -> dict:\n",
    "        \"\"\"\n",
    "        encoder, decoder 생성\n",
    "\n",
    "        Args:\n",
    "            col (str): 생성할 columns 명\n",
    "        Returns:\n",
    "            dict: 생성된 user encoder, decoder\n",
    "        \"\"\"\n",
    "\n",
    "        encoder = {}\n",
    "        decoder = {}\n",
    "        ids = self.df[col].unique()\n",
    "\n",
    "        for idx, _id in enumerate(ids):\n",
    "            encoder[_id] = idx\n",
    "            decoder[idx] = _id\n",
    "\n",
    "        return encoder, decoder\n",
    "    \n",
    "    def generate_sequence_data(self) -> dict:\n",
    "        \"\"\"\n",
    "        sequence_data 생성\n",
    "\n",
    "        Returns:\n",
    "            dict: train user sequence / valid user sequence\n",
    "        \"\"\"\n",
    "        users = defaultdict(list)\n",
    "        user_train = {}\n",
    "        user_valid = {}\n",
    "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n",
    "            users[user].append(item)\n",
    "        \n",
    "        for user in users:\n",
    "            np.random.seed(self.config.seed)\n",
    "\n",
    "            user_total = users[user]\n",
    "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
    "            train = list(set(user_total) - set(valid))\n",
    "\n",
    "            user_train[user] = train\n",
    "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
    "\n",
    "        return user_train, user_valid\n",
    "    \n",
    "    def get_train_valid_data(self):\n",
    "        return self.user_train, self.user_valid\n",
    "\n",
    "    def make_matrix(self, user_list, train = True):\n",
    "        \"\"\"\n",
    "        user_item_dict를 바탕으로 행렬 생성\n",
    "        \"\"\"\n",
    "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
    "        for idx, user in enumerate(user_list):\n",
    "            if train:\n",
    "                mat[idx, self.user_train[user.item()]] = 1\n",
    "            else:\n",
    "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
    "        return mat\n",
    "\n",
    "    def make_sparse_matrix(self, test = False):\n",
    "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
    "        \n",
    "        for user in self.user_train.keys():\n",
    "            item_list = self.user_train[user]\n",
    "            X[user, item_list] = 1.0\n",
    "        \n",
    "        if test:\n",
    "            for user in self.user_valid.keys():\n",
    "                item_list = self.user_valid[user]\n",
    "                X[user, item_list] = 1.0\n",
    "\n",
    "        return X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IldCGmY8u9vh"
   },
   "outputs": [],
   "source": [
    "class AEDataSet(Dataset):\n",
    "    def __init__(self, num_user):\n",
    "        self.num_user = num_user\n",
    "        self.users = [i for i in range(num_user)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_user\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        user = self.users[idx]\n",
    "        return torch.LongTensor([user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysia457Su9vi"
   },
   "source": [
    "# 3. 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOSLIM():\n",
    "    def __init__(self, threshold = 3500, lambdaBB = 500, lambdaCC = 5000, rho = 100000, epochs = 40):\n",
    "        self.threshold = threshold\n",
    "        self.lambdaBB = lambdaBB\n",
    "        self.lambdaCC = lambdaCC\n",
    "        self.rho = rho\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def create_list_feature_pairs(self, XtX):\n",
    "        AA = np.triu(np.abs(XtX))\n",
    "        AA[ np.diag_indices(AA.shape[0]) ]=0.0\n",
    "        ii_pairs = np.where((AA > self.threshold) == True)\n",
    "        return ii_pairs\n",
    "    \n",
    "    def create_matrix_Z(self, ii_pairs, X):\n",
    "        MM = np.zeros( (len(ii_pairs[0]), X.shape[1]),    dtype=np.float)\n",
    "        MM[np.arange(MM.shape[0]) , ii_pairs[0]   ]=1.0\n",
    "        MM[np.arange(MM.shape[0]) , ii_pairs[1]   ]=1.0\n",
    "        CCmask = 1.0-MM\n",
    "        MM = MM.T\n",
    "        Z=  X.dot(MM)\n",
    "        Z= (Z == 2.0 )\n",
    "        Z=Z*1.0\n",
    "        return Z, CCmask\n",
    "\n",
    "    def train_higher(self, XtX, XtXdiag, ZtZ, ZtZdiag, CCmask, ZtX):\n",
    "        ii_diag=np.diag_indices(XtX.shape[0])\n",
    "        XtX[ii_diag] = XtXdiag + self.lambdaBB\n",
    "        PP = np.linalg.inv(XtX)\n",
    "        ii_diag_ZZ=np.diag_indices(ZtZ.shape[0])\n",
    "        ZtZ[ii_diag_ZZ] = ZtZdiag + self.lambdaCC + self.rho\n",
    "        QQ=np.linalg.inv(ZtZ)\n",
    "        CC = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float )\n",
    "        DD = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float )\n",
    "        UU = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float )\n",
    "\n",
    "        for iter in range(self.epochs):\n",
    "            # learn BB\n",
    "            XtX[ii_diag] = XtXdiag\n",
    "            BB= PP.dot(XtX-ZtX.T.dot(CC))\n",
    "            gamma = np.diag(BB) / np.diag(PP)\n",
    "            BB-= PP * gamma\n",
    "            # learn CC\n",
    "            CC= QQ.dot(ZtX-ZtX.dot(BB) + self.rho * (DD-UU))\n",
    "            # learn DD\n",
    "            DD=  CC  * CCmask \n",
    "            #DD= np.maximum(0.0, DD) # if you want to enforce non-negative parameters\n",
    "            # learn UU (is Gamma in paper)\n",
    "            UU+= CC-DD\n",
    "        \n",
    "        return BB, DD\n",
    "\n",
    "    def fit(self, X):\n",
    "        XtX = X.T.dot(X)\n",
    "        XtXdiag = deepcopy(np.diag(XtX))\n",
    "        ii_pairs = self.create_list_feature_pairs(XtX)\n",
    "        Z, CCmask = self.create_matrix_Z(ii_pairs, X)\n",
    "\n",
    "        ZtZ = Z.T.dot(Z)\n",
    "        ZtZdiag = deepcopy(np.diag(ZtZ))\n",
    "\n",
    "        ZtX = Z.T.dot(X)\n",
    "\n",
    "        BB, CC = self.train_higher(XtX, XtXdiag, ZtZ, ZtZdiag, CCmask, ZtX)\n",
    "\n",
    "        self.pred = torch.from_numpy(X.dot(BB) + Z.dot(CC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdmmSlim():\n",
    "    def __init__(self, lambda_1=1, lambda_2=500, rho=10000, positive=True, n_iter=50, eps_rel=1e-4, eps_abs=1e-3, verbose=False):\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.rho = rho\n",
    "        self.positive = positive\n",
    "        self.n_iter = n_iter\n",
    "        self.eps_rel = eps_rel\n",
    "        self.eps_abs = eps_abs\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def soft_thresholding(self, B, Gamma):\n",
    "        if self.lambda_1 == 0:\n",
    "            if self.positive:\n",
    "                return np.abs(B)\n",
    "            else:\n",
    "                return B\n",
    "        else:\n",
    "            x = B + Gamma / self.rho\n",
    "            threshold = self.lambda_1 / self.rho\n",
    "            if self.positive:\n",
    "                return np.where(threshold < x, x - threshold, 0)\n",
    "            else:\n",
    "                return np.where(threshold < x, x - threshold,\n",
    "                                np.where(x < - threshold, x + threshold, 0))\n",
    "\n",
    "    def is_converged(self, B, C, C_old, Gamma):\n",
    "        B_norm = np.linalg.norm(B)\n",
    "        C_norm = np.linalg.norm(C)\n",
    "        Gamma_norm = np.linalg.norm(Gamma)\n",
    "\n",
    "        eps_primal = self.eps_abs * B.shape[0] - self.eps_rel * np.max([B_norm, C_norm])\n",
    "        eps_dual = self.eps_abs * B.shape[0] - self.eps_rel * Gamma_norm\n",
    "\n",
    "        R_primal_norm = np.linalg.norm(B - C)\n",
    "        R_dual_norm = np.linalg.norm(C  - C_old) * self.rho\n",
    "\n",
    "        converged = R_primal_norm < eps_primal and R_dual_norm < eps_dual\n",
    "        return converged\n",
    "\n",
    "    def fit(self, X):\n",
    "        XtX = X.T.dot(X)\n",
    "        if sp.issparse(XtX):\n",
    "            XtX = XtX.todense().A\n",
    "\n",
    "        if self.verbose:\n",
    "            print(' --- init')\n",
    "        identity_mat = np.identity(XtX.shape[0])\n",
    "        diags = identity_mat * (self.lambda_2 + self.rho)\n",
    "        P = np.linalg.inv(XtX + diags).astype(np.float32)\n",
    "        B_aux = P.dot(XtX)\n",
    "\n",
    "        Gamma = np.zeros_like(XtX, dtype=np.float32)\n",
    "        C = np.zeros_like(XtX, dtype=np.float32)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(' --- iteration start.')\n",
    "        for iter in range(self.n_iter):\n",
    "            if self.verbose:\n",
    "                print(f' --- iteration {iter+1}/{self.n_iter}')\n",
    "            C_old = C.copy()\n",
    "            B_tilde = B_aux + P.dot(self.rho * C - Gamma)\n",
    "            gamma = np.diag(B_tilde) / (np.diag(P) + 1e-8)\n",
    "            B = B_tilde - P * gamma\n",
    "            C = self.soft_thresholding(B, Gamma)\n",
    "            Gamma = Gamma + self.rho * (B - C)\n",
    "            if self.is_converged(B, C, C_old, Gamma):\n",
    "                if self.verbose:\n",
    "                    print(f' --- Converged. Stopped iteration.')\n",
    "                break\n",
    "\n",
    "        coef = C\n",
    "\n",
    "        self.pred = torch.from_numpy(X.dot(coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, dropout_rate = 0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "\n",
    "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
    "\n",
    "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
    "\n",
    "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
    "\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.encode(input)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def encode(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                mu = h[:, :self.q_dims[-1]]\n",
    "                logvar = h[:, self.q_dims[-1]:]\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.q_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.p_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, dropout_rate = 0.5):\n",
    "        super(MultiDAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num, num_factor):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num, num_factor),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_factor, num_factor // 2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_factor // 2, num_factor),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_factor, num),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, mat):\n",
    "        latent = self.encoder(mat)\n",
    "        recont_mat = self.decoder(latent)\n",
    "\n",
    "        return recont_mat\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.encoder:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                size = layer.weight.size()\n",
    "                fan_out = size[0]\n",
    "                fan_in = size[1]\n",
    "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "                layer.weight.data.normal_(0.0, std)\n",
    "                layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.decoder:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                size = layer.weight.size()\n",
    "                fan_out = size[0]\n",
    "                fan_in = size[1]\n",
    "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "                layer.weight.data.normal_(0.0, std)\n",
    "                layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE():\n",
    "    def __init__(self, X, reg):\n",
    "        self.X = self._convert_sp_mat_to_sp_tensor(X)\n",
    "        self.reg = reg\n",
    "    \n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        \"\"\"\n",
    "        Convert scipy sparse matrix to PyTorch sparse matrix\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        X = Adjacency matrix, scipy sparse matrix\n",
    "        \"\"\"\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "        v = torch.FloatTensor(coo.data)\n",
    "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "        return res\n",
    "    \n",
    "    def fit(self):\n",
    "        '''\n",
    "\n",
    "        진짜 정말 간단한 식으로 모델을 만듬\n",
    "\n",
    "        '''\n",
    "        G = self.X.to_dense().t() @ self.X.to_dense()\n",
    "        diagIndices = torch.eye(G.shape[0]) == 1\n",
    "        G[diagIndices] += self.reg\n",
    "\n",
    "        P = G.inverse()\n",
    "        B = P / (-1 * P.diag())\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.pred = self.X.to_dense() @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x.mul(torch.sigmoid(x))\n",
    "\n",
    "def log_norm_pdf(x, mu, logvar):\n",
    "    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n",
    "\n",
    "class CompositePrior(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n",
    "        super(CompositePrior, self).__init__()\n",
    "        \n",
    "        self.mixture_weights = mixture_weights\n",
    "        \n",
    "        self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.mu_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_uniform_prior.data.fill_(10)\n",
    "        \n",
    "        self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.encoder_old.requires_grad_(False)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "\n",
    "        post_mu, post_logvar = self.encoder_old(x, dropout_rate = 0)\n",
    "\n",
    "        stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n",
    "        post_prior = log_norm_pdf(z, post_mu, post_logvar)\n",
    "        unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n",
    "        \n",
    "        gaussians = [stnd_prior, post_prior, unif_prior]\n",
    "        gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n",
    "\n",
    "        density_per_gaussian = torch.stack(gaussians, dim=-1)\n",
    "\n",
    "        return torch.logsumexp(density_per_gaussian, dim=-1)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x, dropout_rate):\n",
    "        norm = x.pow(2).sum(dim=-1).sqrt()\n",
    "        x = x / norm[:, None]\n",
    "    \n",
    "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "        \n",
    "        h1 = self.ln1(swish(self.fc1(x)))\n",
    "        h2 = self.ln2(swish(self.fc2(h1) + h1))\n",
    "        h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n",
    "        h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n",
    "        h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n",
    "        return self.fc_mu(h5), self.fc_logvar(h5)\n",
    "\n",
    "\n",
    "class RecVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 600, latent_dim = 200):\n",
    "        super(RecVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n",
    "        self.decoder = nn.Linear(latent_dim, input_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, user_ratings, beta=None, gamma=0.0005, dropout_rate=0.7, calculate_loss=True):\n",
    "        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)    \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_pred = self.decoder(z)\n",
    "\n",
    "        if calculate_loss:\n",
    "            if gamma:\n",
    "                norm = user_ratings.sum(dim=-1)\n",
    "                kl_weight = gamma * norm\n",
    "            elif beta:\n",
    "                kl_weight = beta\n",
    "\n",
    "            mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n",
    "            kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n",
    "            negative_elbo = -(mll - kld)\n",
    "            \n",
    "            return (mll, kld), negative_elbo\n",
    "            \n",
    "        else:\n",
    "            return x_pred\n",
    "\n",
    "    def update_prior(self):\n",
    "        self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwSexh43u9vk"
   },
   "source": [
    "# 4. 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg(pred_list, true_list):\n",
    "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
    "    dcg = 0\n",
    "    for rank, pred in enumerate(pred_list):\n",
    "        if pred in true_list:\n",
    "            dcg += 1 / np.log2(rank + 2)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "# hit == recall == precision\n",
    "def get_hit(pred_list, true_list):\n",
    "    hit_list = set(true_list) & set(pred_list)\n",
    "    hit = len(hit_list) / len(true_list)\n",
    "    return hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(AdmmSlim, HOSLIM, RecVAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    NDCG = 0\n",
    "    HIT = 0\n",
    "    \n",
    "    RecVAE.eval()\n",
    "    MultiVAE.eval()\n",
    "    # MultiDAE.eval()\n",
    "    # AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    # User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    # Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    # MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    # MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    # AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    # AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (HOSLIM_rec, AdmmSlim_rec, RecVAE_rec, MultiVAE_rec) in tqdm(enumerate(zip(HOSLIM_rec_list, AdmmSlim_rec_list, RecVAE_rec_list, MultiVAE_rec_list))):\n",
    "        \n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(HOSLIM_rec + AdmmSlim_rec + RecVAE_rec + MultiVAE_rec))\n",
    "\n",
    "        rec_df = pd.DataFrame(index = all_rec)\n",
    "        rec_df.loc[HOSLIM_rec, 'HOSLIM_rec_score'] = score_li * 1.0\n",
    "        # rec_df.loc[User_EASE_rec, 'User_EASE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[Item_EASE_rec, 'Item_EASE_rec_score'] = score_li * 0.3\n",
    "        rec_df.loc[AdmmSlim_rec, 'AdmmSlim_rec_score'] = score_li * 0.6\n",
    "        rec_df.loc[RecVAE_rec, 'RecVAE_rec_score'] = score_li * 0.8\n",
    "        rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[MultiDAE_rec, 'MultiDAE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[AutoRec_rec, 'AutoRec_rec_score'] = score_li\n",
    "        rec_df = rec_df.fillna(rec_df.min().min())\n",
    "\n",
    "        rec_df['total_rec_score'] = rec_df.sum(axis = 1)\n",
    "        rec_df = rec_df.sort_values('total_rec_score', ascending = False)\n",
    "        up = rec_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_evaluate_df(User_EASE, Item_EASE, AdmmSlim, HOSLIM, RecVAE, MultiVAE, MultiDAE, AutoRec, X, user_train, user_valid, candidate_cnt):\n",
    "    total_evaluate_df = []\n",
    "\n",
    "    RecVAE.eval()\n",
    "    MultiVAE.eval()\n",
    "    MultiDAE.eval()\n",
    "    AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "    \n",
    "    User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    for user, (User_EASE_rec, Item_EASE_rec, AdmmSlim_rec, HOSLIM_rec, RecVAE_rec, AutoRec_rec, MultiDAE_rec, MultiVAE_rec) in tqdm(enumerate(zip(User_EASE_rec_list, Item_EASE_rec_list, AdmmSlim_rec_list, HOSLIM_rec_list, RecVAE_rec_list, AutoRec_rec_list, MultiDAE_rec_list, MultiVAE_rec_list))):\n",
    "        \n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(User_EASE_rec + Item_EASE_rec + AdmmSlim_rec + HOSLIM_rec + RecVAE_rec + AutoRec_rec + MultiDAE_rec + MultiVAE_rec))\n",
    "\n",
    "        total_evaluate_df.append(\n",
    "            {\n",
    "               'user' : user,\n",
    "               'len' : len(all_rec),\n",
    "\n",
    "               'User_EASE_rec_score' : get_hit(pred_list = User_EASE_rec, true_list = uv),\n",
    "               'Item_EASE_rec_score' : get_hit(pred_list = Item_EASE_rec, true_list = uv),\n",
    "               'AdmmSlim_rec_score' : get_hit(pred_list = AdmmSlim_rec, true_list = uv),\n",
    "               'HOSLIM_rec_score' : get_hit(pred_list = HOSLIM_rec, true_list = uv),\n",
    "               'RecVAE_rec_score' : get_hit(pred_list = RecVAE_rec, true_list = uv),\n",
    "               'AutoRec_rec_score' : get_hit(pred_list = AutoRec_rec, true_list = uv),\n",
    "               'MultiDAE_rec_score' : get_hit(pred_list = MultiDAE_rec, true_list = uv),\n",
    "               'MultiVAE_rec_score' : get_hit(pred_list = MultiVAE_rec, true_list = uv),\n",
    "\n",
    "               'all_rec_score' : get_hit(pred_list = all_rec, true_list = uv),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return total_evaluate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_ensemble_df(User_EASE, Item_EASE, AdmmSlim, HOSLIM, RecVAE, MultiVAE, MultiDAE, AutoRec, X, candidate_cnt):\n",
    "    \n",
    "    weighted_ensemble_df = {}\n",
    "\n",
    "    RecVAE.eval()\n",
    "    MultiVAE.eval()\n",
    "    MultiDAE.eval()\n",
    "    AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "    \n",
    "    User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (User_EASE_rec, Item_EASE_rec, AdmmSlim_rec, HOSLIM_rec, RecVAE_rec, AutoRec_rec, MultiDAE_rec, MultiVAE_rec) in tqdm(enumerate(zip(User_EASE_rec_list, Item_EASE_rec_list, AdmmSlim_rec_list, HOSLIM_rec_list, RecVAE_rec_list, AutoRec_rec_list, MultiDAE_rec_list, MultiVAE_rec_list))):\n",
    "\n",
    "        # ranking\n",
    "        User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(User_EASE_rec + Item_EASE_rec + AdmmSlim_rec + HOSLIM_rec + RecVAE_rec + AutoRec_rec + MultiDAE_rec + MultiVAE_rec))\n",
    "\n",
    "        rec_df = pd.DataFrame(index = all_rec)\n",
    "        rec_df.loc[User_EASE_rec, 'User_EASE_rec_score'] = score_li\n",
    "        rec_df.loc[Item_EASE_rec, 'Item_EASE_rec_score'] = score_li\n",
    "        rec_df.loc[AdmmSlim_rec, 'AdmmSlim_rec_score'] = score_li\n",
    "        rec_df.loc[HOSLIM_rec, 'HOSLIM_rec_score'] = score_li\n",
    "        rec_df.loc[RecVAE_rec, 'RecVAE_rec_score'] = score_li\n",
    "        rec_df.loc[AutoRec_rec, 'AutoRec_rec_score'] = score_li\n",
    "        rec_df.loc[MultiDAE_rec, 'MultiDAE_rec_score'] = score_li\n",
    "        rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li\n",
    "\n",
    "        weighted_ensemble_df[user] = rec_df\n",
    "\n",
    "    return weighted_ensemble_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gupkaJHMslCi"
   },
   "source": [
    "# 5. 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 모델 init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hoslim = HOSLIM(threshold = 3500, lambdaBB = 500, lambdaCC = 10000, rho = 50000)\n",
    "# hoslim.fit(X = X.toarray())\n",
    "\n",
    "hoslim = HOSLIM(threshold = 3500, lambdaBB = 500, lambdaCC = 15000, rho = 10000)\n",
    "hoslim.fit(X = X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "threshold = 3500, lambdaBB = 500, lambdaCC = 15000, rho = 10000 | NDCG@10: 0.31118| HIT@10: 0.20455\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admm_slim = AdmmSlim(lambda_2 = 1, rho = 1000)\n",
    "# admm_slim.fit(X = X.toarray())\n",
    "\n",
    "admm_slim = AdmmSlim(lambda_1 = 10, lambda_2 = 5, rho = 1000)\n",
    "admm_slim.fit(X = X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "lambda_1 = 10, lambda_2 = 5, rho = 1000 | NDCG@10: 0.30627| HIT@10: 0.20035\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ease = EASE(X = X, reg = 750)\n",
    "# user_ease.fit()\n",
    "\n",
    "user_ease = EASE(X = X, reg = 680)\n",
    "user_ease.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "reg: 680| NDCG@10: 0.23002| HIT@10: 0.20400\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ease = EASE(X = X.T, reg = 4400)\n",
    "item_ease.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_vae = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "rec_vae.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v7.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RecVAE_v3 | 0.192140\n",
    "\n",
    "Multi-DAE_v2 | 0.179330\n",
    "\n",
    "Multi-VAE_v2 | 0.179959\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_rec = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "auto_rec.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dae = MultiDAE(\n",
    "    p_dims = [200, 600] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "multi_dae.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_vae = MultiVAE(\n",
    "    p_dims = [200, 600] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.7).to(device)\n",
    "\n",
    "multi_vae.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v4.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. total_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_evaluate_df = get_total_evaluate_df(\n",
    "    User_EASE = user_ease, \n",
    "    Item_EASE = item_ease, \n",
    "    AdmmSlim = admm_slim, \n",
    "    HOSLIM = hoslim, \n",
    "    RecVAE = rec_vae, \n",
    "    MultiVAE = multi_vae, \n",
    "    MultiDAE = multi_dae, \n",
    "    AutoRec = auto_rec,\n",
    "    X = X.todense(), \n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid, \n",
    "    candidate_cnt = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>len</th>\n",
       "      <th>User_EASE_rec_score</th>\n",
       "      <th>Item_EASE_rec_score</th>\n",
       "      <th>AdmmSlim_rec_score</th>\n",
       "      <th>HOSLIM_rec_score</th>\n",
       "      <th>RecVAE_rec_score</th>\n",
       "      <th>AutoRec_rec_score</th>\n",
       "      <th>MultiDAE_rec_score</th>\n",
       "      <th>MultiVAE_rec_score</th>\n",
       "      <th>all_rec_score</th>\n",
       "      <th>total_best_rec_score</th>\n",
       "      <th>total_best_rec_score_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>User_EASE_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RecVAE_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>User_EASE_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>AdmmSlim_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>AdmmSlim_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>31355</td>\n",
       "      <td>18</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Item_EASE_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>31356</td>\n",
       "      <td>26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>User_EASE_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>31357</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Item_EASE_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>31358</td>\n",
       "      <td>21</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>User_EASE_rec_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>31359</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>RecVAE_rec_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  len  User_EASE_rec_score  Item_EASE_rec_score  \\\n",
       "0          0   27                  0.3                  0.3   \n",
       "1          1   26                  0.1                  0.1   \n",
       "2          2   24                  0.3                  0.3   \n",
       "3          3   20                  0.3                  0.3   \n",
       "4          4   25                  0.4                  0.3   \n",
       "...      ...  ...                  ...                  ...   \n",
       "31355  31355   18                  0.2                  0.4   \n",
       "31356  31356   26                  0.3                  0.3   \n",
       "31357  31357   21                  0.2                  0.3   \n",
       "31358  31358   21                  0.1                  0.1   \n",
       "31359  31359   34                  0.0                  0.2   \n",
       "\n",
       "       AdmmSlim_rec_score  HOSLIM_rec_score  RecVAE_rec_score  \\\n",
       "0                     0.3               0.3               0.1   \n",
       "1                     0.1               0.1               0.2   \n",
       "2                     0.3               0.3               0.2   \n",
       "3                     0.4               0.3               0.2   \n",
       "4                     0.5               0.3               0.4   \n",
       "...                   ...               ...               ...   \n",
       "31355                 0.3               0.2               0.2   \n",
       "31356                 0.2               0.3               0.2   \n",
       "31357                 0.1               0.2               0.3   \n",
       "31358                 0.1               0.1               0.0   \n",
       "31359                 0.0               0.1               0.3   \n",
       "\n",
       "       AutoRec_rec_score  MultiDAE_rec_score  MultiVAE_rec_score  \\\n",
       "0                    0.2                 0.2                 0.2   \n",
       "1                    0.1                 0.1                 0.1   \n",
       "2                    0.3                 0.2                 0.3   \n",
       "3                    0.2                 0.2                 0.2   \n",
       "4                    0.3                 0.4                 0.3   \n",
       "...                  ...                 ...                 ...   \n",
       "31355                0.2                 0.2                 0.2   \n",
       "31356                0.2                 0.2                 0.2   \n",
       "31357                0.1                 0.2                 0.1   \n",
       "31358                0.0                 0.1                 0.0   \n",
       "31359                0.0                 0.2                 0.1   \n",
       "\n",
       "       all_rec_score  total_best_rec_score total_best_rec_score_name  \n",
       "0                0.5                   0.3       User_EASE_rec_score  \n",
       "1                0.2                   0.2          RecVAE_rec_score  \n",
       "2                0.4                   0.3       User_EASE_rec_score  \n",
       "3                0.4                   0.4        AdmmSlim_rec_score  \n",
       "4                0.6                   0.5        AdmmSlim_rec_score  \n",
       "...              ...                   ...                       ...  \n",
       "31355            0.4                   0.4       Item_EASE_rec_score  \n",
       "31356            0.4                   0.3       User_EASE_rec_score  \n",
       "31357            0.4                   0.3       Item_EASE_rec_score  \n",
       "31358            0.1                   0.1       User_EASE_rec_score  \n",
       "31359            0.3                   0.3          RecVAE_rec_score  \n",
       "\n",
       "[31360 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_evaluate_df = pd.DataFrame(total_evaluate_df)\n",
    "\n",
    "def get_total_name(x):\n",
    "    val_list = [x['User_EASE_rec_score'], x['Item_EASE_rec_score'], x['AdmmSlim_rec_score'], x['HOSLIM_rec_score'], x['RecVAE_rec_score'], x['AutoRec_rec_score'], x['MultiDAE_rec_score'], x['MultiVAE_rec_score']]\n",
    "    max_val = max(val_list)\n",
    "    val_idx = val_list.index(max_val)\n",
    "    if val_idx == 0 : return 'User_EASE_rec_score'\n",
    "    elif val_idx == 1 : return 'Item_EASE_rec_score'\n",
    "    elif val_idx == 2 : return 'AdmmSlim_rec_score'\n",
    "    elif val_idx == 3 : return 'HOSLIM_rec_score'\n",
    "    elif val_idx == 4 : return 'RecVAE_rec_score'\n",
    "    elif val_idx == 5 : return 'AutoRec_rec_score'\n",
    "    elif val_idx == 6 : return 'MultiDAE_rec_score'\n",
    "    elif val_idx == 7 : return 'MultiVAE_rec_score'\n",
    "\n",
    "total_evaluate_df['total_best_rec_score'] = total_evaluate_df.apply(lambda x: max(x['User_EASE_rec_score'], x['Item_EASE_rec_score'], x['AdmmSlim_rec_score'], x['HOSLIM_rec_score'], x['RecVAE_rec_score'], x['AutoRec_rec_score'], x['MultiDAE_rec_score'], x['MultiVAE_rec_score']), axis = 1)\n",
    "total_evaluate_df['total_best_rec_score_name'] = total_evaluate_df.apply(lambda x: get_total_name(x), axis = 1)\n",
    "total_evaluate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJgAAAEvCAYAAAAJo3vaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABc3UlEQVR4nO3deVxV5dr/8c8t4IgTQz2WE/WoR5kVHDJFJYeG43hwyMyhk5mWQx3Tk5VWVnqycsij+XtScggJPWllOaCSOSYYirOZOFcqieIMrN8f4D4SqJtxI37fr9d+yb7Wve51rQ0r7eIejGVZiIiIiIiIiIiI5FUpRycgIiIiIiIiIiJ3NhWYREREREREREQkX1RgEhERERERERGRfFGBSURERERERERE8kUFJhERERERERERyRcVmEREREREREREJF+cHZ1AYfDw8LBq167t6DREREREREREREqMuLi405ZleeZ0rEQWmGrXrk1sbKyj0xARERERERERKTGMMYdvdkxT5EREREREREREJF9UYBIRERERERERkXxRgUlERERERERERPKlRK7BJCIiIiIiIiIZrl27xrFjx7h8+bKjU5E7RNmyZalevTouLi52n6MCk4iIiIiIiEgJduzYMSpWrEjt2rUxxjg6HSnmLMvizJkzHDt2DC8vL7vP0xQ5ERERERERkRLs8uXLuLu7q7gkdjHG4O7unusRbyowiYiIiIiIiJRwKi5JbuTl50UFJhERERERERERyRcVmERERERERETuIjVq1sIYU2CvGjVr3faaiYmJ+Pj4ZImNGzeOSZMmFfj9JSYmUq5cOQICAmyvuXPn2o7Hx8djjGH58uVZznvnnXfw9vbGz8+PgIAAtmzZAkCrVq2oV6+era+//e1vBZ5zSaBFvkVERERERETuIseOHuHDlfsKrL+X2tUrsL5yIzU1FWfnnMsaDz74IPHx8Tkei4iI4OGHHyYiIoIOHToAsGnTJr755hu2bdtGmTJlOH36NFevXrWds2DBAoKCggosP0cpzJw0gklEREREREREHGbq1Kk0aNAAPz8/evbsCcCFCxcYMGAAjRs3JjAwkKVLlwIQHh5Ox44dadOmDaGhobm+lmVZREVFER4ezqpVq2wLWZ88eRIPDw/KlCkDgIeHB/fdd1+u++/Xrx+DBg2iSZMmvPLKKxw8eJAOHTrQqFEjWrRowd69ewH47bff6NKlC/7+/vj7+7Nx48Yc+7tw4QKPP/44/v7++Pj4EBkZCcDWrVt56KGH8Pf3p3Hjxpw/f57Lly/Tv39/fH19CQwMZO3atTl+Zjf7bPOreJXSRO4QLzw/iLNnzmSJVXF35+MZMx2UkYiIiIiIyJ1pwoQJHDp0iDJlynD27FkgY7pamzZtmD17NmfPnqVx48Y88sgjAGzbto0dO3bg5uZ20z4PHjxIQECA7f20adNo0aIFGzduxMvLiwcffJBWrVqxbNkyunXrRrt27XjrrbeoW7cujzzyCD169CAkJMR2fu/evSlXrhwAbdu25f3337/ptY8dO8bGjRtxcnIiNDSUmTNnUqdOHbZs2cLgwYNZs2YNQ4cOJSQkhC+//JK0tDRSUlJy7Gv58uXcd999LFu2DIDk5GSuXr1Kjx49iIyMJDg4mHPnzlGuXDmmTJmCMYaEhAT27t1Lu3bt2L9/f7bP7NVXX83xs61QocLtv1m3oAKTSB6cPXOGwWGds8T+HbXEIbmIiIiIiIgUdzfblcwYg5+fH71796Zz58507twZgJUrV/LVV1/Z1mi6fPkyR44cATIKPLcqLsHNp8hFRETYRkn17NmTuXPn0q1bN1xdXYmLi+OHH35g7dq19OjRgwkTJtCvXz8gd1PkwsLCcHJyIiUlhY0bNxIWFmY7duXKFQDWrFljWxfKycmJypUr59iXr68vL7/8MqNGjeKJJ56gRYsWJCQkUK1aNYKDgwGoVKkSAOvXr+fFF18E4C9/+Qu1atWyFZhu/Mxu9tnWr1/frvu7GRWYRERERERERKRQubu788cff2SJJSUl4eXlxbJly1i3bh1ff/0177zzDgkJCViWxeLFi6lXL+v6Tlu2bMnzSJu0tDQWL17M0qVLeeedd7AsizNnznD+/HkqVqyIk5MTrVq1olWrVvj6+vLZZ5/ZCky5cT2/9PR0qlSpctO1oOxRt25dtm3bxrfffstrr71GaGgoXbp0yXNOwE0/2/zSGkwiIiIiIiIiUqhcXV2pVq0aa9asATKKS8uXL+fhhx/m6NGjtG7dmokTJ5KcnExKSgrt27dn2rRpWJYFwE8//ZTvHFavXo2fnx9Hjx4lMTGRw4cP061bN7788kv27dvHgQMHbG3j4+OpVev2u+PdSqVKlfDy8iIqKgrIKOxs374dgNDQUGbMmAFkFL6Sk5Nz7OPEiROUL1+ep556ipEjR7Jt2zbq1avHyZMn2bp1KwDnz58nNTWVFi1asGDBAgD279/PkSNHciwiFcZnCxrBJCIiIiIiInJXqV6jZoHu/Fa9Rk272s2dO5chQ4bw0ksvATB27Fhq1qxJ69atSU5OxrIshg4dSpUqVXj99dcZPnw4fn5+pKen4+XlxTfffGN3Tn9eg2nAgAH89NNP2Ub/dOvWjRkzZuDt7c2LL77I2bNncXZ25n//93+ZNWuWrd2NazB5eHgQHR1tVx4LFizg+eefZ/z48Vy7do2ePXvi7+/PlClTGDhwIJ9++ilOTk7MmDGDZs2aZTs/ISGBkSNHUqpUKVxcXJgxYwalS5cmMjKSF198kUuXLlGuXDmio6MZPHgwzz//PL6+vjg7OxMeHm5btPxG+f1sb8Zcr1iVJEFBQVZsbKyj05AS7KnuYTmuwTT/iyjHJCQiIiIiInITe/bsyff6OnL3yennxhgTZ1lWjotRaYqciIiIiIiIiIjki6bIieTBroSdfF3KZIuJiIiIiIhI0UhISKBPnz5ZYmXKlGHLli2Ffu133nnHtrbSdWFhYYwZMyZP/Z05c4bQ0NBs8dWrV+Pu7p6nPouaCkwieZB6LZW2Aa2yxL6JLZiF0UREREREROT2fH1987VDW36MGTMmz8WknLi7uzvsXgqKCkwieXDu3Hn27NmdLSYiIiIiIiJyN1KBSSQP0q10qlW7L1tMRERERERE5G6kApOIlAjPvfgcp5JPZYt7Vvbkk2mfOCAjERERERGRu4cKTCJSIpxKPsUjLz2SLR79YbQDshEREREREbm7lHJ0AiIiIiIiIiJSdGrXrI4xpsBetWtWv+01XV1dAUhMTOTzzz8v1PsbN24c999/PwEBAbbX2bNnbceHDx/O/fffT3r6f5c5+e2333jiiSfw9/enQYMGPPbYY7Z8y5Url6WvuXPnFmr+dyqNYBKREmHX9h1ciDyTLZ64/bgDshERERERKb4OHz2OtebdAuvPtHnV7rbXC0xPPvlkgV0/JyNGjOAf//hHtnh6ejpffvklNWrU4Pvvv6d169YAvPHGG7Rt25Zhw4YBsGPHDts5Dz74YJ52eEtLS8PJySlvN1BIUlNTcXYunFKQRjCJSInw68lznFiXnO3168lzjk5NREREREQyjR49mh9++IGAgAA++ugj0tLSGDlyJMHBwfj5+fHJJxnrp8bExBASEkKnTp144IEHGD16NAsWLKBx48b4+vpy8ODBPF0/JiYGb29vnn/+eSIiImzxkydPUr36f0di+fn55al/V1dXXn75Zfz9/dm0aRPz58+ncePGBAQE8Nxzz5GWlgbA8uXLadiwIf7+/oSGht60v++//942ciowMJDz5zN2L584cSK+vr74+/szevRoAOLj42natCl+fn506dKFP/74A4BWrVoxfPhwgoKCmDJlCnFxcYSEhNCoUSPat2/PyZMn83Svf6YRTCJSIlilXPjLX7P/FuTw5CkOyEZERERERHIyYcIEJk2axDfffAPArFmzqFy5Mlu3buXKlSs0b96cdu3aAbB9+3b27NmDm5sbDzzwAH//+9/58ccfmTJlCtOmTWPy5Mk3vc5HH33E/PnzAahatSpr164FICIigl69etGpUydeffVVrl27houLC0OGDKFHjx58/PHHPPLII/Tv35/77svYOfzgwYMEBATY+p42bRotWrTI8boXLlygSZMmfPDBB+zZs4eJEyeyYcMGXFxcGDx4MAsWLODRRx/l2WefZd26dXh5eZGUlHTT+5g0aRLTp0+nefPmpKSkULZsWb777juWLl3Kli1bKF++vO38p59+mmnTphESEsIbb7zBm2++afuMrl69SmxsLNeuXSMkJISlS5fi6elJZGQkY8aMYfbs2bf/5t2GCkwiUiJcS03l9OnTOcZFRERERKR4WrlyJTt27GDRokUAJCcnc+DAAUqXLk1wcDDVqlUDMqapXS88+fr62gpGN5PTFLmrV6/y7bff8uGHH1KxYkWaNGnCihUreOKJJ2jfvj2//PILy5cv57vvviMwMJCdO3farm3vFDknJye6desGwOrVq4mLiyM4OBiAS5cucc8997B582ZatmyJl5cXAG5ubjftr3nz5rz00kv07t2brl27Ur16daKjo+nfvz/ly5e3nZ+cnMzZs2cJCQkBoG/fvoSFhdn66dGjBwD79u1j586dtG3bFsiYxnf9M84vFZhEpEQwaWkkHc0+Hc5kDkEVEREREZHix7Ispk2bRvv27bPEY2JiKFOmjO19qVKlbO9LlSpFah5+kbxixQrOnj2Lr68vABcvXqRcuXI88cQTQEah5sknn+TJJ5/kiSeeYN26dTRq1ChX1yhbtqxt3SXLsujbty/vvfdeljZff/213f2NHj2axx9/nG+//ZbmzZuzYsWKXOVzXYUKFWw5eXt7s2nTpjz1cytag0lESoRSBh7yKpPtVco4OjMREREREbmuYsWKtnWEANq3b8+MGTO4du0aAPv37+fChQuFcu2IiAj+7//+j8TERBITEzl06BCrVq3i4sWLrFmzhosXLwJw/vx5Dh48SM2aNfN1vdDQUBYtWsTvv/8OQFJSEocPH6Zp06asW7eOQ4cO2eI3c/DgQXx9fRk1ahTBwcHs3buXtm3bMmfOHFu+SUlJVK5cmapVq/LDDz8AMG/ePNtophvVq1ePU6dO2QpM165dY9euXfm6z+s0gklESoxShbQbgoiIiIhISVKrxv252vnNnv7s5efnh5OTE/7+/vTr149hw4aRmJhIw4YNsSwLT09PlixZku+cblyDCeDzzz9n+fLlzJw50xarUKECDz/8MF9//TVHjhzhhRdewNnZmfT0dP7+978THBxMYmJitjWYBgwYwNChQ2+bQ4MGDRg/fjzt2rUjPT0dFxcXpk+fTtOmTZk1axZdu3YlPT2de+65h1WrVuXYx+TJk1m7di2lSpXC29ubRx99lDJlyhAfH09QUBClS5fmscce49133+Wzzz5j0KBBXLx4kQceeIA5c+Zk66906dIsWrSIoUOHkpycTGpqKsOHD8fb2zsXn27OjGVZ+e6kuAkKCrJiY2MdnYaUYB6V3Anwqp8lFn9oD6fPnXFQRuLq5sFTA7Mv8j1/1uekJGVfm0lERERE5G6xZ88e6tevf/uGIjfI6efGGBNnWVZQTu31636RPHB2KkOfVgOzxHYeGe2gbOQ6zfkVERERERFxDBWYRKTEKGVUYhIRERERuVu88847REVFZYmFhYUxZsyYQr92kyZNuHLlSpbYvHnzbAuI59acOXOYMmVKlljz5s2ZPn16nnMsaiowiYhIoXh22HBOnTufLe5ZqSL/b8rkok9IREREREqUMWPGFEkxKSdbtmwp0P769+9P//79C7TPoqYCk4iIFIpT587T/I3x2eIb3nrNAdmIiIiIiEhhUoFJREqMkrhpgYiIiIiIyJ1ABSYRKTEMxtEpiIiIiIiI3JVUYBLJi9RkvoiZki0mIiIiIiIicjcq1C2XjDEjjDG7jDE7jTERxpiyxhgvY8wWY8zPxphIY0zpzLZlMt//nHm89g39/DMzvs8Y074wcxaxRzmXdN7pUCfLq5xLuqPTEhERERERua0atWpgjCmwV41aNey67pIlSzDGsHfv3hyPt2rVitjY2IK8VQA2b95MkyZNCAgIoH79+owbNw6A8PBwXnjhBQBmzpzJ3LlzC/zad5NCG8FkjLkfGAo0sCzrkjHmC6An8BjwkWVZC40xM4FngBmZf/5hWdb/GmN6AhOBHsaYBpnneQP3AdHGmLqWZaUVVu4iIiIiIiIiJdWxI8eY/tP0AutvSOAQu9pFRETw8MMPExERwZtvvllg17+dvn378sUXX+Dv709aWhr79u3L1mbQoEEFek3LsrAsi1KlCnVcT66lpaXh5ORUKH0X9p06A+WMMc5AeeAk0AZYlHn8M6Bz5tedMt+TeTzUGGMy4wsty7piWdYh4GegcSHnLSIiIiIiIiIFJCUlhfXr1/Ppp5+ycOFCAC5dukTPnj2pX78+Xbp04dKlS7b2rq6ujBw5Em9vbx555BF+/PFHWrVqxQMPPMBXX30FZIxA6ty5M23btqV27dp8/PHHfPjhhwQGBtK0aVOSkpIA+P3336lWrRoATk5ONGjQIFt+48aNY9KkSUDGSKoRI0YQFBRE/fr12bp1K127dqVOnTq89trNd0ROTEykXr16PP300/j4+HD06FHef/99goOD8fPzY+zYsba2c+fOxc/PD39/f/r06XPTPqOiovDx8cHf35+WLVsCGUWif/zjH/j4+ODn58e0adMAWL16NYGBgfj6+jJgwACuXLkCQO3atRk1ahQNGzYkKiqKlStX0qxZMxo2bEhYWBgpKSm3+e7Zp9AKTJZlHQcmAUfIKCwlA3HAWcuyUjObHQPuz/z6fuBo5rmpme3db4zncI6IiIiIiIiIFHNLly6lQ4cO1K1bF3d3d+Li4pgxYwbly5dnz549vPnmm8TFxdnaX7hwgTZt2rBr1y4qVqzIa6+9xqpVq/jyyy954403bO127tzJf/7zH7Zu3cqYMWMoX748P/30E82aNbNNeRsxYgT16tWjS5cufPLJJ1y+fPm2+ZYuXZrY2FgGDRpEp06dmD59Ojt37iQ8PJwzZ87c9LwDBw4wePBgdu3axb59+zhw4AA//vgj8fHxxMXFsW7dOnbt2sX48eNZs2YN27dvZ8qUKTft76233mLFihVs377dVlibNWsWiYmJxMfHs2PHDnr37s3ly5fp168fkZGRJCQkkJqayowZM2z9uLu7s23bNh555BHGjx9PdHQ027ZtIygoiA8//PC2n4c9CnOKXFUyRh95AWeBKKBDIV5vIDAQoGbNmoV1GREATl9zYsCS9dliIiIiIiIikl1ERATDhg0DoGfPnkRERPDzzz8zdOhQAPz8/PDz87O1L126NB06ZJQQfH19KVOmDC4uLvj6+pKYmGhr17p1aypWrEjFihWpXLkyf/3rX23n7NixA4A33niD3r17s3LlSj7//HMiIiKIiYm5Zb4dO3a09ePt7W0bAfXAAw9w9OhR3N3dczyvVq1aNG3aFICVK1eycuVKAgMDgYxRXAcOHGD79u2EhYXh4eEBgJub203zaN68Of369aN79+507doVgOjoaAYNGoSzs7Pt/O3bt+Pl5UXdunWBjGmB06dPZ/jw4QD06NEDyFiPavfu3TRv3hyAq1ev0qxZs1t+FvYqzF3kHgEOWZZ1CsAY8x+gOVDFGOOcOUqpOnA8s/1xoAZwLHNKXWXgzA3x6248x8ayrFnALICgoCCrUO5IJJPlUpYm3Xtnie2f/qmDshERERERESm+kpKSWLNmDQkJCRhjSEtLwxhjK7zkxMXFhYxVc6BUqVKUKVPG9nVqaqqt3fX47do9+OCDPP/88zz77LN4enrechTSjf3e2GdO/f5ZhQoVbF9blsU///lPnnvuuSxtrk9ps8fMmTPZsmULy5Yto1GjRllGeeXG9bwsy6Jt27ZERETkqZ9bKcw1mI4ATY0x5TPXUgoFdgNrgb9ltukLLM38+qvM92QeX2NZlpUZ75m5y5wXUAf4sRDzFrFLyqXzWV4iIiIiIiKS3aJFi+jTpw+HDx8mMTGRo0eP4uXlRaNGjfj888+BjKlu10ccFbRly5aRUV7ImMLm5ORElSpVCuVaN2rfvj2zZ8+2rXF0/Phxfv/9d9q0aUNUVJStyHV9raicHDx4kCZNmvDWW2/h6enJ0aNHadu2LZ988omt0JWUlES9evVITEzk559/BmDevHmEhIRk669p06Zs2LDB1u7ChQvs37+/QO630EYwWZa1xRizCNgGpAI/kTHCaBmw0BgzPjN2fdjHp8A8Y8zPQBIZO8dhWdauzB3odmf2M0Q7yElxUNmltKNTEBERERERybXqNavbvfObvf3dSkREBKNGjcoS69atGz/99BOXLl2ifv361K9fn0aNGhVYTjeaN28eI0aMoHz58jg7O7NgwYJC20ntRu3atWPPnj22KWiurq7Mnz8fb29vxowZQ0hICE5OTgQGBhIeHp5jHyNHjuTAgQNYlkVoaCj+/v74+Piwf/9+/Pz8cHFx4dlnn+WFF15gzpw5hIWFkZqaSnBwcI4743l6ehIeHk6vXr1si4CPHz/eNrUuP8z1Kl5JEhQUZMXGxjo6DSnBXN086PfcU1li4Z/MJyXptIMyElc3D/oNfCpbPHyWvi+O0rn/MzR/Y3y2+Ia3XmPJHE0pFRERESkqe/bsoX79+o5OQ+4wOf3cGGPiLMsKyql9YU6RExERERERERGRu0BhLvItIiIiIiIiIlKinDlzhtDQ0Gzx1atX33R3udt55513iIqKyhILCwtjzJgxeerPEVRgEhERERERERGxk7u7O/Hx8QXa55gxY+6oYlJONEVORERERERERETyRQUmERERERERERHJFxWYREREREREREQkX1RgEhERERERERGRfFGBSUREREREROQuUrtGDYwxBfaqXaPGba/p6uqa5X14eDgvvPCC7f2sWbP4y1/+wl/+8hcaN27M+vXrbce++eYbAgMD8ff3p0GDBnzyyScAjBs3jkmTJt30WomJiRhjeO2112zHTp8+jYuLS5ZrS8HQLnIiIiIiIiIid5HDx47x+9RpBdbfPUNfzNf533zzDZ988gnr16/Hw8ODbdu20blzZ3788Ufc3d0ZOHAgP/74I9WrV+fKlSskJiba3beXlxfLli1j/PjxAERFReHt7W33+ampqTg7F6/SSXHMCTSCSUREREREREQcaOLEibz//vt4eHgA0LBhQ/r27cv06dM5f/48qampuLu7A1CmTBnq1atnd9/ly5enfv36xMbGAhAZGUn37t1veU6/fv0YNGgQTZo04ZVXXuHgwYN06NCBRo0a0aJFC/bu3QvAb7/9RpcuXfD398ff35+NGzfm2N+FCxd4/PHH8ff3x8fHh8jISAC2bt3KQw89hL+/P40bN+b8+fNcvnyZ/v374+vrS2BgIGvXrgUyRnx17NiRNm3aEBoayoULFxgwYACNGzcmMDCQpUuX2v2ZFJbiV/ISEZESYf9PGzgzekC2+Jl9hxyQjYiIiIg40qVLlwgICLC9T0pKomPHjgDs2rWLRo0aZWkfFBTEZ599hpubGx07dqRWrVqEhobyxBNP0KtXL0qVsn+8TM+ePVm4cCH33nsvTk5O3HfffZw4ceKW5xw7doyNGzfi5OREaGgoM2fOpE6dOmzZsoXBgwezZs0ahg4dSkhICF9++SVpaWmkpKTk2Nfy5cu57777WLZsGQDJyclcvXqVHj16EBkZSXBwMOfOnaNcuXJMmTIFYwwJCQns3buXdu3asX//fgC2bdvGjh07cHNz49VXX6VNmzbMnj2bs2fP0rhxYx555BEqVKhg9+dS0FRgEhGRQmHMFZ4b1Txb/L1n9jogGxERERFxpHLlyhEfH297Hx4ebhtVdDv/93//R0JCAtHR0UyaNIlVq1YRHh5u97U7dOjA66+/zr333kuPHj3sOicsLAwnJydSUlLYuHEjYWFhtmNXrlwBYM2aNcydOxcAJycnKleunGNfvr6+vPzyy4waNYonnniCFi1akJCQQLVq1QgODgagUqVKAKxfv54XX8yYcviXv/yFWrVq2QpMbdu2xc3NDYCVK1fy1Vdf2dagunz5MkeOHKF+/fp2fy4FTQUmEREREREREXGYBg0aEBcXR5s2bWyxuLi4LGsl+fr64uvrS58+ffDy8spVgal06dI0atSIDz74gN27d/PVV1/d9pzrI4HS09OpUqVKluJYbtWtW5dt27bx7bff8tprrxEaGkqXLl1y3c+No5Msy2Lx4sW5mi5Y2LQGk4iIiIiIiIg4zCuvvMKoUaM4c+YMAPHx8YSHhzN48GBSUlKIiYmxtY2Pj6dWrVq5vsbLL7/MxIkTbSOA7FWpUiW8vLyIiooCMgo727dvByA0NJQZM2YAkJaWRnJyco59nDhxgvLly/PUU08xcuRItm3bRr169Th58iRbt24FsK011aJFCxYsWADA/v37OXLkSI5FpPbt2zNt2jQsywLgp59+ytV9FQaNYBIRERERERG5i9SqXj3fO7/9ub/86NixI8ePH+ehhx7CGEPFihWZP38+1apV4/z58/zrX//iueeeo1y5clSoUCHL6KXx48czefJk2/tjx47leA1vb+9c7R53owULFvD8888zfvx4rl27Rs+ePfH392fKlCkMHDiQTz/9FCcnJ2bMmEGzZs2ynZ+QkMDIkSMpVaoULi4uzJgxg9KlSxMZGcmLL77IpUuXKFeuHNHR0QwePJjnn38eX19fnJ2dCQ8Pp0yZMtn6fP311xk+fDh+fn6kp6fj5eXFN998k6f7KyjmerWrJAkKCrLsncspkheubh70e+6pLLHwT+aTknTaQRmJq5sH/QY+lS0ePkvfF0fxDvTin58+ky3+3jOfsusnLfQtIiIiUlT27Nnj0LV55M6U08+NMSbOsqygnNpripyIiIiIiIiIiOSLpsiJiIiIiIiIyF3nnXfesa2tdF1YWBhjxozJU39nzpwhNDQ0W3z16tW4u7vnqc87iQpMIiIiIiIiInLXGTNmTJ6LSTlxd3fP125zdzpNkRMRERERERERkXxRgUlERERERERERPJFBSYREREREREREckXFZhERERERERERCRfVGASERERERERuYvUqlkLY0yBvWrVrHXbazo5OREQEICPjw9//etfOXv2bK7zbt26NStWrMgSmzx5Ms8//zwAp0+fxsXFhZkzZ2ZpU7t2bXx9fQkICCAgIIChQ4fm+tpye9pFTkREREREROQucuToEbZ8dbDA+mvS8cHbtilXrpxth7W+ffsyffr0XO/g1qtXLxYuXEj79u1tsYULF/Kvf/0LgKioKJo2bUpERASDBg3Kcu7atWvx8PDI1fVSU1Nxdi5eZZPimNN1GsEkIiIiIiIiIkWmWbNmHD9+HICDBw/SoUMHGjVqRIsWLdi7dy8Av/32G126dMHf3x9/f382btzI3/72N5YtW8bVq1cBSExM5MSJE7Ro0QKAiIgIPvjgA44fP86xY8fylFurVq0YPnw4QUFBTJkyhbi4OEJCQmjUqBHt27fn5MmTAPz888888sgj+Pv707BhQw4ezLlgd/LkSVq2bGkbvfXDDz8AsHz5cho2bIi/vz+hoaEAJCUl0blzZ/z8/GjatCk7duwAYNy4cfTp04fmzZvTp08fTp06Rbdu3QgODiY4OJgNGzbk6V4LWvEse4mIiIiIiIhIiZOWlsbq1at55plnABg4cCAzZ86kTp06bNmyhcGDB7NmzRqGDh1KSEgIX375JWlpaaSkpFC5cmUaN27Md999R6dOnVi4cCHdu3fHGMPRo0c5efIkjRs3pnv37kRGRvLyyy/brtu6dWucnJyAjBFUI0aMuGmOV69eJTY2lmvXrhESEsLSpUvx9PQkMjKSMWPGMHv2bHr37s3o0aPp0qULly9fJj09Pce+Pv/8c9q3b8+YMWNIS0vj4sWLnDp1imeffZZ169bh5eVFUlISAGPHjiUwMJAlS5awZs0ann76aduor927d7N+/XrKlSvHk08+yYgRI3j44Yc5cuQI7du3Z8+ePQXx7ckXFZhEREREREREpFBdunSJgIAAjh8/Tv369Wnbti0pKSls3LiRsLAwW7srV64AsGbNGubOnQtkrN9UuXJl4L/T5K4XmD799FMAIiMj6d69OwA9e/ZkwIABWQpMuZki16NHDwD27dvHzp07adu2LZBRHKtWrRrnz5/n+PHjdOnSBYCyZcvetK/g4GAGDBjAtWvX6Ny5MwEBAcTExNCyZUu8vLwAcHNzA2D9+vUsXrwYgDZt2nDmzBnOnTsHQMeOHSlXrhwA0dHR7N6923aNc+fOkZKSgqurq133V1hUYBIRERERERGRQnV9DaaLFy/Svn17pk+fTr9+/ahSpYptlI49OnXqxIgRI9i2bRsXL16kUaNGQMb0uF9//ZUFCxYAcOLECQ4cOECdOnVynWuFChUAsCwLb29vNm3alOX4+fPn7e6rZcuWrFu3jmXLltGvXz9eeuklqlatmuecANLT09m8efMtC1uOoDWYRERERERERKRIlC9fnqlTp/LBBx9Qvnx5vLy8iIqKAjIKOtu3bwcgNDSUGTNmABkjh5KTkwFwdXWldevWDBgwgF69egGwf/9+UlJSOH78OImJiSQmJvLPf/6TiIiIfOVar149Tp06ZSswXbt2jV27dlGxYkWqV6/OkiVLgIxRVxcvXsyxj8OHD3Pvvffy7LPP8ve//51t27bRtGlT1q1bx6FDhwBsU+RatGhhK5DFxMTg4eFBpUqVsvXZrl07pk2bZnufmwJdYdIIJhEREREREZG7SM0aNe3a+S03/eVGYGAgfn5+REREsGDBAp5//nnGjx/PtWvX6NmzJ/7+/kyZMoWBAwfy6aef4uTkxIwZM2jWrBmQMU2uS5cuLFy4EMgYvXR9utp13bp1o0ePHrzxxhtA1jWY/Pz8bNPvbqV06dIsWrSIoUOHkpycTGpqKsOHD8fb25t58+bx3HPP8cYbb+Di4kJUVBQPPPBAtj5iYmJ4//33cXFxwdXVlblz5+Lp6cmsWbPo2rUr6enp3HPPPaxatYpx48YxYMAA/Pz8KF++PJ999lmOeU2dOpUhQ4bg5+dHamoqLVu2ZObMmfZ/AwqJsSzL0TkUuKCgICs2NtbRaUgJ5urmQb/nnsoSC/9kPilJpx2Ukbi6edBv4FPZ4uGz9H1xFO9AL/756TPZ4u898ym7fjrkgIxERERE7k579uyhfv36jk5D7jA5/dwYY+IsywrKqb2myImIiIiIiIiISL5oipyIiIiIiIiI3FWGDBnChg0bssSGDRtG//7989RfQkICffr0yRIrU6YMW7ZsyXOOdxoVmERERERERETkrjJ9+vQC7c/X17fYLLbtKJoiJyIiIiIiIiIi+aICk4iIiIiIiIiI5IsKTCIiIiIiIiIiki8qMImIiIiIiIiISL6owCQiIiIiIiJyF6lZswbGmAJ71axZw67rLlmyBGMMe/fuvW3byZMnc/Hixdu2q127Nr6+vvj5+RESEsLhw4ftykUKnnaRExERuYsMGzaQc+dOZYtXquTJlCmzHJCRiIiIFLWjR4+x4Yv5BdZf8+5P2dUuIiKChx9+mIiICN58881btp08eTJPPfUU5cuXv22/a9euxcPDg7FjxzJ+/Hj+3//7f3blkxtpaWk4OTkVeL/5kZqairNz8SnrFJ9MRESkRDn520WmvP5tjnFxnHPnTvH6662yxd9+O6aoUxEREZG7SEpKCuvXr2ft2rX89a9/5c033yQmJoZJkybxzTffAPDCCy8QFBTEuXPnOHHiBK1bt8bDw4O1a9cSERHBu+++i2VZPP7440ycODHbNZo1a8bUqVMBOHXqFIMGDeLIkSNARsGqefPmpKSk8OKLLxIbG4sxhrFjx9KtW7ccc3Z1deW5554jOjqa6dOnk5iYyNSpU7l69SpNmjTh3//+N05OTixfvpxXX32VtLQ0PDw8WL16dY79ff/99wwbNgwAYwzr1q2jYsWKTJw4kfnz51OqVCkeffRRJkyYQHx8PIMGDeLixYs8+OCDzJ49m6pVq9KqVSsCAgJYv349vXr1olWrVrz00kukpKTg4eFBeHg41apVy/f3Ky9UYBKREsPCcnQKcoN044JPjwHZ4gfixxV9MiIiIiLiUEuXLqVDhw7UrVsXd3d34uLibtp26NChfPjhh7aRSSdOnGDUqFHExcVRtWpV2rVrx5IlS+jcuXOW85YvX26LDRs2jBEjRvDwww9z5MgR2rdvz549e3j77bepXLkyCQkJAPzxxx83zePChQs0adKEDz74gD179jBx4kQ2bNiAi4sLgwcPZsGCBTz66KM8++yzrFu3Di8vL5KSkm7a36RJk5g+fbqt0FW2bFm+++47li5dypYtWyhfvrzt/Keffppp06YREhLCG2+8wZtvvsnkyZMBuHr1KrGxsVy7do2QkBCWLl2Kp6cnkZGRjBkzhtmzZ9vxHSl4KjCJSIlhHJ2AZJF66Ro7Vu3MMS4iIiIid5eIiAjb6J2ePXsSERHBE088Yde5W7dupVWrVnh6egLQu3dv1q1bZysmtW7dmqSkJFxdXXn77bcBiI6OZvfu3bY+zp07R0pKCtHR0SxcuNAWr1q16k2v6+TkZBvdtHr1auLi4ggODgbg0qVL3HPPPWzevJmWLVvi5eUFgJub2037a968OS+99BK9e/ema9euVK9enejoaPr372+bCujm5kZycjJnz54lJCQEgL59+xIWFmbrp0ePHgDs27ePnTt30rZtWyBjGp+jRi+BCkwiIlJISmHR/H7PbPEDGmkmIiIicldJSkpizZo1JCQkYIwhLS0NYwydOnUiPT3d1u7y5ct56n/t2rVUqVKF3r17M3bsWD788EPS09PZvHkzZcuWzXPeZcuWta27ZFkWffv25b333svS5uuvv7a7v9GjR/P444/z7bff0rx5c1asWJGnvCpUqGDLydvbm02bNuWpn4KmXeREREREREREpNAsWrSIPn36cPjwYRITEzl69CheXl6kp6eze/durly5wtmzZ7OsXVSxYkXOnz8PQOPGjfn+++85ffo0aWlpRERE2Eb3XOfs7MzkyZOZO3cuSUlJtGvXjmnTptmOx8fHA9C2bVumT59ui99qityNQkNDWbRoEb///juQUTQ7fPgwTZs2Zd26dRw6dMgWv5mDBw/i6+vLqFGjCA4OZu/evbRt25Y5c+bYdsxLSkqicuXKVK1alR9++AGAefPmZbtfgHr16nHq1ClbgenatWvs2rXLrvspDBrBJCIiheKqZRHzy7Ec4yIiIiLiODVqVLd75zd7+7uViIgIRo0alSXWrVs3Fi5cSPfu3fHx8cHLy4vAwEDb8YEDB9KhQwfuu+8+1q5dy4QJE2jdurVtke9OnTplu061atXo1asX06dPZ+rUqQwZMgQ/Pz9SU1Np2bIlM2fO5LXXXmPIkCH4+Pjg5OTE2LFj6dq1623vsUGDBowfP5527dqRnp6Oi4sL06dPp2nTpsyaNYuuXbuSnp7OPffcw6pVq3LsY/Lkyaxdu5ZSpUrh7e3No48+SpkyZYiPjycoKIjSpUvz2GOP8e677/LZZ5/ZFvl+4IEHmDNnTrb+SpcuzaJFixg6dCjJycmkpqYyfPhwvL29b3s/hcFYJfAf+kFBQVZsbKyj05ASzNXNg37PZf0Pcvgn80lJOu2gjMTVzYN+A3tni4fPWqDvi4OUdfek9bCB2eJrp8zi8plTDshIAPr373LTXeTmzPmyyPMRERGRwrdnzx7q16/v6DTkDpPTz40xJs6yrKCc2hfqFDljTBVjzCJjzF5jzB5jTDNjjJsxZpUx5kDmn1Uz2xpjzFRjzM/GmB3GmIY39NM3s/0BY0zfwsxZRERERERERERyp7CnyE0BlluW9TdjTGmgPPAqsNqyrAnGmNHAaGAU8ChQJ/PVBJgBNDHGuAFjgSDAAuKMMV9ZlmXfREkREXEIk25xfPfvOcZFRERERIqLJk2acOXKlSyxefPm4evrm6f+5syZw5QpU7LEmjdvnmXtp5Ko0ApMxpjKQEugH4BlWVeBq8aYTkCrzGafATFkFJg6AXOtjDl7mzNHP1XLbLvKsqykzH5XAR2AiMLKXURE8s/JQMu65bLFf1npgGRERERERG5iy5YtBdpf//796d+/f4H2eScozClyXsApYI4x5idjzP8ZYyoA91qWdTKzza/AvZlf3w8cveH8Y5mxm8WzMMYMNMbEGmNiT53S2h4iIiIiIiIiIkWlMAtMzkBDYIZlWYHABTKmw9lkjlYqkLkSlmXNsiwryLKsIE9Pz4LoUkRERERERERE7FCYBaZjwDHLsq6PNVtERsHpt8ypb2T+eX2BjuNAjRvOr54Zu1lcRERERERERESKgUIrMFmW9Stw1BhTLzMUCuwGvgKu7wTXF1ia+fVXwNOZu8k1BZIzp9KtANoZY6pm7jjXLjMmIiIiIiIiIrlUu2YtjDEF9qpds5ajb0mKgcLeRe5FYEHmDnK/AP3JKGp9YYx5BjgMdM9s+y3wGPAzcDGzLZZlJRlj3ga2ZrZ76/qC3yIiIiIiIiKSO4ePHuHsysQC669Ku9q3bWOMoXfv3syfPx+A1NRUqlWrRpMmTfjmm29uea6rqyspKSkkJiayceNGnnzySQBiY2OZO3cuU6dOJTw8nJEjR1K9enVSUlJ44IEHGDt2LA899JCtn9OnT1OtWjWmTZvGoEGDbPHatWtTsWJFnJycAGjZsiVTp07N7cdw1yvUApNlWfFAUA6HQnNoawFDbtLPbGB2gSYnIiIiIiIiIkWiQoUK7Ny5k0uXLlGuXDlWrVrF/fdn27/rlhITE/n8889tBaagoCCCgv5bcujRowcff/wxAGvXrqVr166sXbuW+vXrAxAVFUXTpk2JiIjIUmC63t7DwyNX+aSmpuLsXNjjdnLHkTkV5hpMIiIiIiIiIiIAPPbYYyxbtgyAiIgIevXqZTs2btw4Jk2aZHvv4+NDYmJilvNHjx7NDz/8QEBAAB999BExMTE88cQTOV6rdevWDBw4kFmzZtliERERfPDBBxw/fpxjx47l6R5atWrF8OHDCQoKYsqUKcTFxRESEkKjRo1o3749J0+eBODnn3/mkUcewd/fn4YNG3Lw4MEc+zt58iQtW7YkICAAHx8ffvjhBwCWL19Ow4YN8ff3JzQ0Y4xOUlISnTt3xs/Pj6ZNm7Jjxw7bZ9enTx+aN29Onz59OHXqFN26dSM4OJjg4GA2bNiQp3vNLRWYRESk0Fy9ci3bS0RERETuTj179mThwoVcvnyZHTt20KRJk1ydP2HCBFq0aEF8fDwjRoy4bfuGDRuyd+9eAI4ePcrJkydp3Lgx3bt3JzIyMkvb1q1bExAQYCte3crVq1eJjY1l6NChvPjiiyxatIi4uDgGDBjAmDFjAOjduzdDhgxh+/btbNy4kWrVquXY1+eff0779u2Jj49n+/btBAQEcOrUKZ599lkWL17M9u3biYqKAmDs2LEEBgayY8cO3n33XZ5++mlbP7t37yY6OpqIiAiGDRvGiBEj2Lp1K4sXL+bvf//7bT+rglC8xnKJiEiJUtq5jKNTEBEREZFiws/Pj8TERCIiInjssccK/XoZK/FkiIyMpHv3jCWge/bsyYABA3j55Zdtx3MzRa5Hjx4A7Nu3j507d9K2bVsA0tLSqFatGufPn+f48eN06dIFgLJly960r+DgYAYMGMC1a9fo3LkzAQEBxMTE0LJlS7y8vABwc3MDYP369SxevBiANm3acObMGc6dOwdAx44dKVeuHADR0dHs3r3bdo1z586RkpKCq6urXfeXVyowiYiIiIiIiEiR6NixI//4xz+IiYnhzJkztrizszPp6em295cvX873tX766Sfb+ksRERH8+uuvLFiwAIATJ05w4MAB6tSpk+t+K1SoAGQUsLy9vdm0aVOW4+fPn7e7r5YtW7Ju3TqWLVtGv379eOmll6hatWqecwJIT09n8+bNtyxsFQYVmERERERERETuIrVq1LRr57fc9GevAQMGUKVKFXx9fYmJibHFa9eubdtNbtu2bRw6dCjbuRUrVrS7ePP9998za9Ys1q5dy/79+0lJSeH48eO242PHjiUiIoI33njD7tz/rF69epw6dYpNmzbRrFkzrl27xv79+/H29qZ69eosWbKEzp07c+XKFdLS0ihfvny2Pg4fPkz16tV59tlnuXLlCtu2bWPMmDEMHjyYQ4cO4eXlRVJSEm5ubrRo0YIFCxbw+uuvExMTg4eHB5UqVcrWZ7t27Zg2bRojR44EID4+noCAgDzfp720BpOIiIiIiIjIXSTxyGEsyyqwV+KRw3Zfu3r16gwdOjRbvFu3biQlJeHt7c3HH39M3bp1s7Xx8/PDyckJf3//HNdJioyMJCAggLp16/Luu++yePFi6tevT0REhG262o3Xi4iIsL2/cQ2mG9c2upXSpUuzaNEiRo0ahb+/PwEBAWzcuBGAefPmMXXqVPz8/HjooYf49ddfc+wjJiYGf39/AgMDiYyMZNiwYXh6ejJr1iy6du2Kv7+/bUreuHHjiIuLw8/Pj9GjR/PZZ5/l2OfUqVOJjY3Fz8+PBg0aMHPmTLvuJ7/MjXMSS4qgoCArNjbW0WlICebq5kG/557KEgv/ZD4pSacdlJG4unnQb2DvbPHwWQv0fXEQVzcP+j3/VLZ4+Aw9K47Uv38XXn+9Vbb422/HMGfOl0Wej4iIiBS+PXv22KaKidgrp58bY0ycZVlBObXXFLli7oXnB3H2hnmp11Vxd+fjGUVThRQRERERERERuRUVmIq5s2fOMDisc7b4v6OWFHkuIiIiIiIiIneDIUOGsGHDhiyxYcOG0b9//zz1l5CQQJ8+fbLEypQpw5YtW/KcY3GjApOIiIiIiIiIyA2mT59eoP35+voSHx9foH0WN1rkW0RERERERERE8kUjmEREpNCkpaU5OgURERERESkCKjCJiEihKVVKA2WLm+07d7JwaXIO8aMOyEZERERESgr9y19ERApNelp6tpc41pXUVGqGtMn2upKa6ujUREREpIjUrFkTY0yBvWrWrHnbaxpjeOqpp2zvU1NT8fT05Iknnrjtua6urgAkJiby+eef2+KxsbEMHTqUxMREqlevTnp61n9rBgQE2BbRnjx5MmXLliU5+b+/aIuJiaFy5coEBATYXtHR0bfNR3KmEUwiIlJonErprxkRERGR4ubo0aOsWbOmwPpr06bNbdtUqFCBnTt3cunSJcqVK8eqVau4//77c3Wd6wWmJ598EoCgoCCCgoKAjKLZDz/8QEhICAB79+7l/PnzNGnSBICIiAiCg4P5z3/+k2UnuBYtWvDNN9/kKg/LsrAsq9iN1k9LS8PJyclh17fr0zDGNLcnJgUvISGBxYsXZ3slJCQ4OjURERERERERuz322GMsW7YMyCj49OrVy3Zs3LhxTJo0yfbex8eHxMTELOePHj2aH374gYCAAD766CNiYmJsI6B69erFwoULbW0XLlxIz549ATh48CApKSmMHz+eiIiIPOWemJhIvXr1ePrpp/Hx8eHo0aO8//77BAcH4+fnx9ixY21t586di5+fH/7+/vTp0+emfUZFReHj44O/vz8tW7YEMopE//jHP/Dx8cHPz49p06YBsHr1agIDA/H19WXAgAFcuXIFgNq1azNq1CgaNmxIVFQUK1eupFmzZjRs2JCwsDBSUlLydL95YW+5bZqdMSlgV69do2HDRtleV69dc3RqIiIiIiIiInbr2bMnCxcu5PLly+zYscM2usheEyZMoEWLFsTHxzNixIgsx7p3786SJUtIzZz2HxkZaStgXS82tWjRgn379vHbb7/ZzrtesLr+Onjw4E2vf+DAAQYPHsyuXbvYt28fBw4c4McffyQ+Pp64uDjWrVvHrl27GD9+PGvWrGH79u1MmTLlpv299dZbrFixgu3bt/PVV18BMGvWLBITE4mPj2fHjh307t2by5cv069fPyIjI0lISCA1NZUZM2bY+nF3d2fbtm088sgjjB8/nujoaLZt20ZQUBAffvhhrj7j/Ljl3AVjTDPgIcDTGPPSDYcqAY4bdyUiIiIiIiIidxQ/Pz8SExOJiIjgscceK9C+7733Xnx8fFi9ejX33nsvzs7O+Pj4ABmjpb788ktKlSpFt27diIqK4oUXXgByN0WuVq1aNG3aFICVK1eycuVKAgMDAUhJSeHAgQNs376dsLAwPDw8AHBzc7tpf82bN6dfv350796drl27AhAdHc2gQYNwdna2nb99+3a8vLyoW7cuAH379mX69OkMHz4cgB49egCwefNmdu/eTfPmGRPOrl69SrNmzez7AAvA7RbHKA24ZrareEP8HPC3wkpK/ivl3Hl+XL8px7iIiIiIiIjInaRjx4784x//ICYmhjNnztjizs7OWRbpvnz5cq77vj5N7t5777WNXkpISODAgQO0bdsWyCi6eHl52QpMuVGhQgXb15Zl8c9//pPnnnsuS5vrU9rsMXPmTLZs2cKyZcto1KgRcXFxuc7pxrwsy6Jt27Z5ngaYX7ecImdZ1veWZb0JNLUs680bXh9alnWgiHK8u1kQ0uChbC8sRycmInJ7aemp2V4iIiIicvcaMGAAY8eOxdfXN0u8du3abNu2DYBt27Zx6NChbOdWrFiR8+dvPtiia9eufPvtt0RGRtrWX4qIiGDcuHEkJiaSmJjIiRMnOHHiBIcPH87XfbRv357Zs2fb1jg6fvw4v//+O23atCEqKspWPEtKSrppHwcPHqRJkya89dZbeHp6cvToUdq2bcsnn3xim+qXlJREvXr1SExM5OeffwZg3rx5tsXMb9S0aVM2bNhga3fhwgX279+fr/vMDXu39yljjJkF1L7xHMuybr9UvIiI3LWcTPHaWUNEREREoEaNGnbt/Jab/uxVvXp1hg4dmi3erVs35s6di7e3N02aNLFNB7uRn58fTk5O+Pv7069fP9v0tOuqVKlCs2bN+PXXX3nggQeAjPWXvv322yztunTpwsKFC2nSpIltDabrXnvtNf72t9tP2GrXrh179uyxTUFzdXVl/vz5eHt7M2bMGEJCQnByciIwMJDw8PAc+xg5ciQHDhzAsixCQ0Px9/fHx8eH/fv34+fnh4uLC88++ywvvPACc+bMISwsjNTUVIKDgxk0aFC2/jw9PQkPD6dXr162RcDHjx+f42dZGIxl3X4ojDFmOzATiAPSrscty8rb+K1CFhQUZMXGxjo6jQJRw/MepjwzPFt82KeTOXrq96JPSABwdfOg33NPZYmFfzKflKTTDspIXN086Dewd7Z4+KwF+r44iL4nxZN3oBf//PSZbPH3nvmUXT9l/02hiIiI3Pn27NlD/fr1HZ2G3GFy+rkxxsRZlhWUU3t7RzClWpY14/bNRO4e9hRnRURERERERO4G9haYvjbGDAa+BK5cD1qWdfPJhCIlnME4OgUREREREREpQGfOnCE0NDRbfPXq1bi7u+epz3feeYeoqKgssbCwMMaMGZOn/oorewtMfTP/HHlDzAIeKNh0REREREREREQcw93dnfj4+ALtc8yYMSWumJQTuwpMlmV5FXYiIiIiIiIiIiJyZ7KrwGSMeTqnuGVZcws2HRERERERERERudPYO0Uu+IavywKhwDZABSYRERERERERkbucvVPkXrzxvTGmCrCwMBISEREREREREZE7S6k8nncB0LpMIiIiIiIiIneYWrVqYIwpsFetWjXynEvt2rU5ffo0AK6urgV1i+IA9q7B9DUZu8YBOAH1gS8KKykRERERERERKRxHjhzj4MHJBdbfgw8OL7C+7JGamoqzs70r/hSdtLQ0nJycHJ2Gw9g7gmkS8EHm612gpWVZowstKxEREREREREpUTp37kyjRo3w9vZm1qxZuTo3JiaGFi1a0LFjRxo0aEBaWhojR44kODgYPz8/PvnkE1vbiRMn4uvri7+/P6NH37x0MXXqVBo0aICfnx89e/YEICUlhf79++Pr64ufnx+LFy8GICIiAl9fX3x8fBg1apStD1dXV15++WX8/f3ZtGkT8+fPp3HjxgQEBPDcc8+RlpaWq/u8k9m7BtP3xph7+e9i3wcKLyURERERERERKWlmz56Nm5sbly5dIjg4mG7duuXq/G3btrFz5068vLyYNWsWlStXZuvWrVy5coXmzZvTrl079u7dy9KlS9myZQvly5cnKSnppv1NmDCBQ4cOUaZMGc6ePQvA22+/TeXKlUlISADgjz/+4MSJE4waNYq4uDiqVq1Ku3btWLJkCZ07d+bChQs0adKEDz74gD179jBx4kQ2bNiAi4sLgwcPZsGCBTz99NN5/szuJPZOkesOvA/EAAaYZowZaVnWokLMTURERERERERKiKlTp/Lll18CcPToUQ4cyN3YlcaNG+PllbEc9MqVK9mxYweLFmWUJZKTkzlw4ADR0dH079+f8uXLA+Dm5nbT/vz8/OjduzedO3emc+fOAERHR7Nw4X/3NKtatSrr1q2jVatWeHp6AtC7d2/WrVtH586dcXJyshXKVq9eTVxcHMHBGWNzLl26xD333JOre7yT2TtpcQwQbFnW7wDGGE8gGlCBSURERERERERuKSYmhujoaDZt2kT58uVp1aoVly9fzlUfFSpUsH1tWRbTpk2jffv2WdqsWLHC7v6WLVvGunXr+Prrr3nnnXdso5Zyo2zZsrZ1lyzLom/fvrz33nu57qcksHcNplLXi0uZzuTiXMmHS1fS+Pd332Z7Xbpy98zjFBERERERkTtbcnIyVatWpXz58uzdu5fNmzfnq7/27dszY8YMrl27BsD+/fu5cOECbdu2Zc6cOVy8eBHgplPk0tPTOXr0KK1bt2bixIkkJyeTkpJC27ZtmT59uq3dH3/8QePGjfn+++85ffo0aWlpREREEBISkq3P0NBQFi1axO+//2679uHDh/N1n3cSe0cwLTfGrAAiMt/3AL4tnJTkRs5OZejTamC2+M4jWmNdREREREREcq9mzeoFuvNbzZrVb9umQ4cOzJw5k/r161OvXj2aNm2ar2v+/e9/JzExkYYNG2JZFp6enixZsoQOHToQHx9PUFAQpUuX5rHHHuPdd9/Ndn5aWhpPPfUUycnJWJbF0KFDqVKlCq+99hpDhgzBx8cHJycnxo4dS9euXZkwYQKtW7fGsiwef/xxOnXqlK3PBg0aMH78eNq1a0d6ejouLi5Mnz6dWrVq5ete7xS3LDAZY/4XuNeyrJHGmK7Aw5mHNgELCjs5ERERERERESlYhw8fLfJrlilThu+++y5bPDEx0fZ1SkrKTc9v1aoVrVq1sr0vVaoU7777bo7Fo9GjR99y9zgAFxcX1q9fny3u6urKZ599li3eq1cvevXqlS3+55x79OhBjx49bnntkup2I5gmA/8EsCzrP8B/AIwxvpnH/lqIuYmIiIiIiIiIyB3gdgWmey3LyrbKlWVZCcaY2oWTkoiIiIiIiIjcjRISEujTp0+WWJkyZdiyZUue+xwyZAgbNmzIEhs2bBj9+/fPc5+S3e0KTFVucaxcAeYhIiIiIiIiInc5X19f4uPjC7TPGxftlsJzu53gYo0xz/45aIz5OxBXOCmJiIiIiIiIiMid5HYjmIYDXxpjevPfglIQUBroUoh5iYiIiIiIiIjIHeKWBSbLsn4DHjLGtAZ8MsPLLMtaU+iZiYiIiIiIiIjIHeF2I5gAsCxrLbC2kHMREREREREREZE70O3WYBIRERERERGREqRGrVoYYwrsVaNWrVte7+zZs/z73/++ZZvExEQ+//zz2+aemJiIj4/PTY+Hh4fzwgsv3Laf2wkPD+fEiRP57uduYtcIJnGg1GS+iJmSY1xEREREREQkt44dOcK/fim44skrD9x3y+PXC0yDBw++aZvrBaYnn3yywPLKj/DwcHx8fLjvvlvf23VpaWk4OTkVcla5k5qairNz0ZV9Cn0EkzHGyRjzkzHmm8z3XsaYLcaYn40xkcaY0pnxMpnvf848XvuGPv6ZGd9njGlf2DkXJ+Vc0nmnQ51sr3Iu6Y5OTUREREREROS2Ro8ezcGDBwkICGDkyJGMHDkSHx8ffH19iYyMtLX54YcfCAgI4KOPPiIxMZEWLVrQsGFDGjZsyMaNG+2+3tGjR2nVqhV16tThzTfftMXnz59P48aNCQgI4LnnniMtLY20tDT69etny+ejjz5i0aJFxMbG0rt3bwICArh06VKO16lduzajRo2iYcOGREVFsXLlSpo1a0bDhg0JCwsjJSUFgK1bt/LQQw/h7+9P48aNOX/+fI797dq1y5afn58fBw4cAGDu3Ln4+fnh7+9Pnz59gIyCXJs2bfDz8yM0NJQjR44A0K9fPwYNGkSTJk145ZVXOHjwIB06dKBRo0a0aNGCvXv32v055lZRlLKGAXuASpnvJwIfWZa10BgzE3gGmJH55x+WZf2vMaZnZrsexpgGQE/AG7gPiDbG1LUsK60Icne4NFL58ciPOcZFREREREREirsJEyawc+dO4uPjWbx4MTNnzmT79u2cPn2a4OBgWrZsyYQJE5g0aRLffPMNABcvXmTVqlWULVuWAwcO0KtXL2JjY+263o8//sjOnTspX748wcHBPP7441SoUIHIyEg2bNiAi4sLgwcPZsGCBXh7e3P8+HF27twJZIy2qlKlCh9//DGTJk0iKCjoltdyd3dn27ZtnD59mq5duxIdHU2FChWYOHEiH374IaNHj6ZHjx5ERkYSHBzMuXPnKFeuXI59zZw5k2HDhtG7d2+uXr1KWloau3btYvz48WzcuBEPDw+SkpIAePHFF+nbty99+/Zl9uzZDB06lCVLlgBw7NgxNm7ciJOTE6GhocycOZM6deqwZcsWBg8ezJo1hbNvW6EWmIwx1YHHgXeAl4wxBmgDXB/z9hkwjowCU6fMrwEWAR9ntu8ELLQs6wpwyBjzM9AY2FSYuRcbpaBag//JHl91tOhzERERkQI3bNhAzp07lS1eqZInU6bMckBGIiIihWf9+vX06tULJycn7r33XkJCQti6dSuVKlXK0u7atWu88MILxMfH4+TkxP79++2+Rtu2bXF3dwega9eurF+/HmdnZ+Li4ggODgbg0qVL3HPPPfz1r3/ll19+4cUXX+Txxx+nXbt2ubqfHj16ALB582Z2795N8+bNAbh69SrNmjVj3759VKtWzXbdP9/njZo1a8Y777zDsWPH6Nq1K3Xq1GHNmjWEhYXh4eEBgJubGwCbNm3iP//5DwB9+vThlVdesfUTFhaGk5MTKSkpbNy4kbCwMNuxK1eu5Or+cqOwRzBNBl4BKma+dwfOWpZ1ffjNMeD+zK/vB44CWJaVaoxJzmx/P7D5hj5vPEdERETkjnbu3Clef71Vtvjbb8cUdSoiIiLFxkcffcS9997L9u3bSU9Pp2zZsnafmzFWJet7y7Lo27cv7733Xrb227dvZ8WKFcycOZMvvviC2bNn232tChUqAGBZFm3btiUiIiLL8YSEBLv7evLJJ2nSpAnLli3jscce45NPPrH73JxySk9Pp0qVKsTHx+epn9wqtDWYjDFPAL9blhVXWNf40/UGGmNijTGxp05l/y2giIiIiIiIiBS9ihUr2tYdatGiBZGRkaSlpXHq1CnWrVtH48aNs7QBSE5Oplq1apQqVYp58+aRlmb/KjmrVq0iKSmJS5cusWTJEpo3b05oaCiLFi3i999/ByApKYnDhw9z+vRp0tPT6datG+PHj2fbtm3ZcrZH06ZN2bBhAz///DMAFy5cYP/+/dSrV4+TJ0+ydetWAM6fP09qas5L3vzyyy888MADDB06lE6dOrFjxw7atGlDVFQUZ86cseUN8NBDD7Fw4UIAFixYQIsWLbL1V6lSJby8vIiKigIyimDbt2+3+55yqzBHMDUHOhpjHgPKkrEG0xSgijHGOXMUU3XgeGb740AN4JgxxhmoDJy5IX7djefYWJY1C5gFEBQUZBXKHYmIiIiIiIjc4arXrHnbnd9y29+tuLu707x5c3x8fHj00UdtC1YbY/jXv/7F//zP/+Du7o6TkxP+/v7069ePwYMH061bN+bOnUuHDh1so3Ls0bhxY7p168axY8d46qmnbOsojR8/nnbt2pGeno6LiwvTp0+nXLly9O/fn/T0jI20ro9wur5Ydrly5di0adNN1026ztPTk/DwcHr16mWbhjZ+/Hjq1q1LZGQkL774IpcuXaJcuXJER0fj6uqarY8vvviCefPm4eLiwv/8z//w6quv4ubmxpgxYwgJCcHJyYnAwEDCw8OZNm0a/fv35/3338fT05M5c+bkmNeCBQt4/vnnGT9+PNeuXaNnz574+/vb/VnmhrGswq/FGGNaAf+wLOsJY0wUsPiGRb53WJb1b2PMEMDXsqxBmYt8d7Usq7sxxhv4nIx1l+4DVgN1brXId1BQkGXv4l/FXcVKrtSpXSVb/EDiWc6fSyn6hAQAVzcP+g18KkssfNZ8UpJOOygjyfie9M4WD5+1QN8XB9H3pHjyDvTin58+ky3+3jOfsuunQw7ISPr373LTKXJz5nxZ5PmIiEjJs2fPHurXr+/oNOQOk9PPjTEmzrKsHFc+L4pd5P5sFLDQGDMe+An4NDP+KTAvcxHvJDJ2jsOyrF3GmC+A3UAqMORu2UEOwHIuy0OP/y1bfP8n8x2QjYiIiIiIiIhIdkVSYLIsKwaIyfz6FzJGI/25zWUg7M/xzGPvkLETnYiIiIiIiIjc5VasWMGoUaOyxLy8vPjyy4If/dulSxcOHco60nvixIm0b98+T/0VZe5FyREjmERERERERERE8qx9+/Z5LvDkVkEXfooy96JUaLvIiYiIiIiIiEjxUBTrL0vJkZefFxWYREREREREREqwsmXLcubMGRWZxC6WZXHmzBnKli2bq/M0RU5ERERERESkBKtevTrHjh3j1KlTjk5F7hBly5alevXquTpHBSYRERERERGREszFxQUvLy9HpyElnKbIiYiIiIiIiIhIvqjAJCIiIiIiIiIi+aICk4iIiIiIiIiI5IvWYBLJIwvtwCAiIiIiIiICKjCJ5JlxdAIiIiIiIiIixYSmyImIiIiIiIiISL6owCQiIiIiIiIiIvmiApOIiIiIiIiIiOSLCkwiIiIiIiIiIpIvKjCJiIiIiIiIiEi+qMAkIiIiIiIiIiL5ogKTiIiIiIiIiIjkiwpMIiIiIiIiIiKSLyowiYiIiIiIiIhIvjg7OgEREREpOueOJTFv5MIc4yIiIiIieaUCk4iIyF2kdLrFK00aZIsPjD/igGxEREREpKTQFDkREREREREREckXjWASERG5i5y+Zhj73e4c4yIiIiIieaUCk4iIyF3kaikXfq8WlD1+6FcHZCMiIiIiJYUKTCIiIncRp1LQLqhStnj4ZgckIyIiIiIlhtZgEhERERERERGRfFGBSURERERERERE8kUFJhERERERERERyRcVmEREREREREREJF9UYBIRERERERERkXzRLnIiIiJ3matXrjk6BREREREpYVRgEhERucuUdi7j6BREREREpITRFDkREREREREREckXFZhERERERERERCRfVGASEREREREREZF8UYFJRERERERERETyRQUmERERERERERHJF+0iJyIicpdJvZbm6BREREREpIRRgUlEROQu4+ykv/5FREREpGBpipyIiIiIiIiIiOSLCkwiIiIiIiIiIpIvKjCJiIiIiIiIiEi+aBEGEREREQfavnMnC5cm5xA/6oBsRERERPJGBSYRERERB7qSmkrNkDbZ43M/dUA2IiIiInmjApOIiMhdJi091dEpiIiIiEgJowKTiIjIXcbJaAlGERERESlY+hemiIiIiIiIiIjkiwpMIiIiIiIiIiKSL4VWYDLG1DDGrDXG7DbG7DLGDMuMuxljVhljDmT+WTUzbowxU40xPxtjdhhjGt7QV9/M9geMMX0LK2cREREREREREcm9whzBlAq8bFlWA6ApMMQY0wAYDay2LKsOsDrzPcCjQJ3M10BgBmQUpICxQBOgMTD2elFKREREREREREQcr9AKTJZlnbQsa1vm1+eBPcD9QCfgs8xmnwGdM7/uBMy1MmwGqhhjqgHtgVWWZSVZlvUHsAroUFh5i4iIiIiIiIhI7hTJGkzGmNpAILAFuNeyrJOZh34F7s38+n7g6A2nHcuM3Sz+52sMNMbEGmNiT506VbA3ICIiIiIiIiIiN1XoBSZjjCuwGBhuWda5G49ZlmUBVkFcx7KsWZZlBVmWFeTp6VkQXYqIiIiIiIiIiB0KtcBkjHEho7i0wLKs/2SGf8uc+kbmn79nxo8DNW44vXpm7GZxEREREREREREpBgpzFzkDfArssSzrwxsOfQVc3wmuL7D0hvjTmbvJNQWSM6fSrQDaGWOqZi7u3S4zJiIiIiIiIiIixYBzIfbdHOgDJBhj4jNjrwITgC+MMc8Ah4Humce+BR4DfgYuAv0BLMtKMsa8DWzNbPeWZVlJhZi3iIiIiIiIiIjkQqEVmCzLWg+YmxwOzaG9BQy5SV+zgdkFl52IiIiIiIiIiBSUItlFTkRERERERERESq7CnCInIiIiInJHGjZsIOfOncoWr1TJkylTZjkgIxERkeJNBSYRERERkT85d+4Ur7/eKlv87bdjijoVERGRO4KmyImIiIiIiIiISL6owCQiIiIiIiIiIvmiApOIiIiIiIiIiOSLCkwiIiIiIiIiIpIvKjCJiIiIiIiIiEi+qMAkIiIiIiIiIiL5ogKTiIiIiIiIiIjkiwpMIiIiIiIiIiKSLyowiYiIiIiIiIhIvqjAJCIiIiIiIiIi+aICk4iIiIiIiIiI5IsKTCIiIiIiIiIiki8qMImIiIiIiIiISL6owCQiIiIiIiIiIvmiApOIiIiIiIiIiOSLCkwiIiIiIiIiIpIvzo5OQERERORuduSXPxjZ7f+yxVOSzhZ9MiIiIiJ5pAKTiIiIiANZxpnaQR2yxRNWLXJANiIiIiJ5owKTiIiIiAOVKgVt61TIFt+12gHJiIiIiOSRCkx3AMuyHJ2CiIiIFBILOPzHuRzjIiIiIncKFZjuAMbRCYiIiEihsYAylbL/k0wFJhEREbmTqMAkIiIi4mClncs4OgURERGRfCnl6AREREREREREROTOpgKTiIiIiIiIiIjki6bIiYiIiDhYWlqao1MQERERyRcVmEREREQcTSt6i4iIyB1OBSYRERERB3MqpX+SiYiIyJ1NazCJiIiIiIiIiEi+6NdlIiIiIg6Wlp7q6BRERERE8kUFJhEREREHczIaVF7cbN+5k4VLk3OIH3VANiIiIsWfCkwiIiIiIn9yJTWVmiFtssfnfuqAbERERIo/FZhERERERKTYGzZsIOfOncoWr1TJkylTZjkgIxERuZEKTCIiIiIiUuydO3eK119vlS3+9tsxRZ2KiIjkQBP+RUREREREREQkX1RgEhERERERERGRfFGBSURERERERERE8kUFJhERERERERERyRcVmEREREREREREJF9UYBIRERERERERkXxRgUlERERERERERPLF2dEJiIiIiIgUN0cTk3gl7P9li6cknS36ZERERO4AKjCJiIiIiPxJOi40C2mTLb7iy68dkI2IiEjxpwKTiIiIiMifGbjnHtcc4yIiIpKdCkwiIiIiIjmxHJ2AiIjIneOOKTAZYzoAUwAn4P8sy5rg4JRERERERKSIbN+5k4VLk3OIH3VANnLdsGEDOXfuVLZ4pUqeTJkyywEZiYij3BEFJmOMEzAdaAscA7YaY76yLGu3YzMTERERkZLKyWjD5eLkSmoqNXNYF+vK3E8dkI1cd+7cKV5/vVW2+NtvxxR1KiLiYHdEgQloDPxsWdYvAMaYhUAnQAUmEREREZG7wLljScwbuTDHuIiION6dUmC6H7hx7OsxoImDchERERERkSJ2+mIqm3/6NVv86pVUB2Qj12nqYvGjaYviKMayiv/qhcaYvwEdLMv6e+b7PkATy7JeuKHNQGBg5tt6wL4iT7RweACnHZ2EyB1Az4qIffSsiNhHz4qIffSsiNinpDwrtSzL8szpwJ0yguk4UOOG99UzYzaWZc0CSlw51hgTa1lWkKPzECnu9KyI2EfPioh99KyI2EfPioh97oZn5U5ZuXArUMcY42WMKQ30BL5ycE4iIiIiIiIiIsIdMoLJsqxUY8wLwArACZhtWdYuB6clIiIiIiIiIiLcIQUmAMuyvgW+dXQeDlDipv2JFBI9KyL20bMiYh89KyL20bMiYp8S/6zcEYt8i4iIiIiIiIhI8XWnrMEkIiIiIiIiIiLFlApMxYQxpoMxZp8x5mdjzOgcjpcxxkRmHt9ijKntgDRFHM6OZ+UlY8xuY8wOY8xqY0wtR+Qp4mi3e1ZuaNfNGGMZY0r0riYiObHnOTHGdM/8e2WXMebzos5RpDiw499fNY0xa40xP2X+G+wxR+Qp4mjGmNnGmN+NMTtvctwYY6ZmPks7jDENizrHwqQCUzFgjHECpgOPAg2AXsaYBn9q9gzwh2VZ/wt8BEws2ixFHM/OZ+UnIMiyLD9gEfCvos1SxPHsfFYwxlQEhgFbijZDEcez5zkxxtQB/gk0tyzLGxhe1HmKOJqdf6e8BnxhWVYgGTt+/7tosxQpNsKBDrc4/ihQJ/M1EJhRBDkVGRWYiofGwM+WZf1iWdZVYCHQ6U9tOgGfZX69CAg1xpgizFGkOLjts2JZ1lrLsi5mvt0MVC/iHEWKA3v+XgF4m4xfWFwuyuREigl7npNngemWZf0BYFnW70Wco0hxYM+zYgGVMr+uDJwowvxEig3LstYBSbdo0gmYa2XYDFQxxlQrmuwKnwpMxcP9wNEb3h/LjOXYxrKsVCAZcC+S7ESKD3uelRs9A3xXqBmJFE+3fVYyh2TXsCxrWVEmJlKM2PN3Sl2grjFmgzFmszHmVr+VFimp7HlWxgFPGWOOkbHz94tFk5rIHSe3/z9zR3F2dAIiIoXBGPMUEASEODoXkeLGGFMK+BDo5+BURIo7ZzKmMbQiY0TsOmOMr2VZZx2ZlEgx1AsItyzrA2NMM2CeMcbHsqx0RycmIkVHI5iKh+NAjRveV8+M5djGGONMxtDTM0WSnUjxYc+zgjHmEWAM0NGyrCtFlJtIcXK7Z6Ui4APEGGMSgabAV1roW+4y9vydcgz4yrKsa5ZlHQL2k1FwErmb2POsPAN8AWBZ1iagLOBRJNmJ3Fns+v+ZO5UKTMXDVqCOMcbLGFOajIXxvvpTm6+Avplf/w1YY1mWVYQ5ihQHt31WjDGBwCdkFJe0VobcrW75rFiWlWxZlodlWbUty6pNxnplHS3LinVMuiIOYc+/v5aQMXoJY4wHGVPmfinCHEWKA3uelSNAKIAxpj4ZBaZTRZqlyJ3hK+DpzN3kmgLJlmWddHRSBUVT5IoBy7JSjTEvACsAJ2C2ZVm7jDFvAbGWZX0FfErGUNOfyVg0rKfjMhZxDDuflfcBVyAqcx38I5ZldXRY0iIOYOezInJXs/M5WQG0M8bsBtKAkZZlaQS53FXsfFZeBv6fMWYEGQt+99Mvw+VuZIyJIOMXEx6Za5KNBVwALMuaScYaZY8BPwMXgf6OybRwGD33IiIiIiIiIiKSH5oiJyIiIiIiIiIi+aICk4iIiIiIiIiI5IsKTCIiIiIiIiIiki8qMImIiIiIiIiISL6owCQiIiIiIiIiIvmiApOIiIiIiIiIiOSLCkwiIiIiIiIiIpIvKjCJiIiIiIiIiEi+/H8nj4CRjGdZLQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = total_evaluate_df.columns.tolist()[2:-1]\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.histplot(data = total_evaluate_df[cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_EASE_rec_score    14368\n",
       "RecVAE_rec_score        3924\n",
       "Item_EASE_rec_score     3735\n",
       "AdmmSlim_rec_score      3481\n",
       "MultiDAE_rec_score      1854\n",
       "AutoRec_rec_score       1627\n",
       "MultiVAE_rec_score      1451\n",
       "HOSLIM_rec_score         920\n",
       "Name: total_best_rec_score_name, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_evaluate_df['total_best_rec_score_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user                    15679.500000\n",
       "len                        24.976467\n",
       "User_EASE_rec_score         0.204002\n",
       "Item_EASE_rec_score         0.200207\n",
       "AdmmSlim_rec_score          0.200351\n",
       "HOSLIM_rec_score            0.204554\n",
       "RecVAE_rec_score            0.193332\n",
       "AutoRec_rec_score           0.174758\n",
       "MultiDAE_rec_score          0.182293\n",
       "MultiVAE_rec_score          0.182465\n",
       "all_rec_score               0.320619\n",
       "total_best_rec_score        0.271078\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_evaluate_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "len                        25.295663\n",
    "User_EASE_rec_score         0.203839\n",
    "Item_EASE_rec_score         0.200207\n",
    "AdmmSlim_rec_score          0.200236\n",
    "HOSLIM_rec_score            0.204423\n",
    "RecVAE_rec_score            0.192140\n",
    "AutoRec_rec_score           0.174758\n",
    "MultiDAE_rec_score          0.179330\n",
    "MultiVAE_rec_score          0.179959\n",
    "all_rec_score               0.321936\n",
    "total_best_rec_score        0.271237\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:11, 237.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.31913| HIT@10: 0.20918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:12, 236.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 15| NDCG@10: 0.32036| HIT@10: 0.21128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:12, 237.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 20| NDCG@10: 0.32036| HIT@10: 0.21193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:12, 236.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 25| NDCG@10: 0.31985| HIT@10: 0.21169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:13, 234.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.31917| HIT@10: 0.21114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "880it [00:03, 232.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb Cell 43'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m candidate_cnt \u001b[39min\u001b[39;00m [\u001b[39m5\u001b[39m \u001b[39m*\u001b[39m i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m11\u001b[39m)]:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=2'>3</a>\u001b[0m     ndcg, hit \u001b[39m=\u001b[39m evaluate(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=3'>4</a>\u001b[0m         \u001b[39m# User_EASE = user_ease, \u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=4'>5</a>\u001b[0m         \u001b[39m# Item_EASE = item_ease, \u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=5'>6</a>\u001b[0m         AdmmSlim \u001b[39m=\u001b[39;49m admm_slim, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=6'>7</a>\u001b[0m         HOSLIM \u001b[39m=\u001b[39;49m hoslim,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=7'>8</a>\u001b[0m         RecVAE \u001b[39m=\u001b[39;49m rec_vae, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=8'>9</a>\u001b[0m         \u001b[39m# MultiVAE = multi_vae, \u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=9'>10</a>\u001b[0m         MultiDAE \u001b[39m=\u001b[39;49m multi_dae, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=10'>11</a>\u001b[0m         \u001b[39m# AutoRec = auto_rec,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=11'>12</a>\u001b[0m         X \u001b[39m=\u001b[39;49m X\u001b[39m.\u001b[39;49mtodense(), \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=12'>13</a>\u001b[0m         user_train \u001b[39m=\u001b[39;49m user_train, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=13'>14</a>\u001b[0m         user_valid \u001b[39m=\u001b[39;49m user_valid,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=14'>15</a>\u001b[0m         candidate_cnt \u001b[39m=\u001b[39;49m candidate_cnt)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000156vscode-remote?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcandidate_cnt: \u001b[39m\u001b[39m{\u001b[39;00mcandidate_cnt\u001b[39m}\u001b[39;00m\u001b[39m| NDCG@10: \u001b[39m\u001b[39m{\u001b[39;00mndcg\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m| HIT@10: \u001b[39m\u001b[39m{\u001b[39;00mhit\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb Cell 17'\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(AdmmSlim, HOSLIM, RecVAE, MultiDAE, X, user_train, user_valid, candidate_cnt)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000016vscode-remote?line=70'>71</a>\u001b[0m \u001b[39m# rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000016vscode-remote?line=71'>72</a>\u001b[0m rec_df \u001b[39m=\u001b[39m rec_df\u001b[39m.\u001b[39mfillna(\u001b[39mmax\u001b[39m(score_li))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000016vscode-remote?line=73'>74</a>\u001b[0m rec_df[\u001b[39m'\u001b[39m\u001b[39mtotal_rec_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m rec_df[\u001b[39m'\u001b[39;49m\u001b[39mAdmmSlim_rec_score\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39;49m rec_df[\u001b[39m'\u001b[39;49m\u001b[39mHOSLIM_rec_score\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39;49m rec_df[\u001b[39m'\u001b[39;49m\u001b[39mRecVAE_rec_score\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39m rec_df[\u001b[39m'\u001b[39m\u001b[39mMultiDAE_rec_score\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000016vscode-remote?line=74'>75</a>\u001b[0m rec_df \u001b[39m=\u001b[39m rec_df\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39mtotal_rec_score\u001b[39m\u001b[39m'\u001b[39m, ascending \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/Experiment/Ensemble.ipynb#ch0000016vscode-remote?line=75'>76</a>\u001b[0m up \u001b[39m=\u001b[39m rec_df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mtolist()[:\u001b[39m10\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/ops/common.py?line=65'>66</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/ops/common.py?line=67'>68</a>\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/ops/common.py?line=69'>70</a>\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/arraylike.py:100\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/arraylike.py?line=97'>98</a>\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__add__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/arraylike.py?line=98'>99</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__add__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/arraylike.py?line=99'>100</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49madd)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py:5639\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=5636'>5637</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=5637'>5638</a>\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=5638'>5639</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/base.py:1297\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/base.py?line=1293'>1294</a>\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/base.py?line=1294'>1295</a>\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/base.py?line=1296'>1297</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_result(result, name\u001b[39m=\u001b[39;49mres_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py:3017\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=3012'>3013</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (res1, res2)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=3014'>3015</a>\u001b[0m \u001b[39m# We do not pass dtype to ensure that the Series constructor\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=3015'>3016</a>\u001b[0m \u001b[39m#  does inference in the case where `result` has object-dtype.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=3016'>3017</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(result, index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=3017'>3018</a>\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=3019'>3020</a>\u001b[0m \u001b[39m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=3020'>3021</a>\u001b[0m \u001b[39m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py:451\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=448'>449</a>\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=449'>450</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=450'>451</a>\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=452'>453</a>\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/series.py?line=453'>454</a>\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/construction.py:598\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=594'>595</a>\u001b[0m             subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=595'>596</a>\u001b[0m             subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=597'>598</a>\u001b[0m subarr \u001b[39m=\u001b[39m _sanitize_ndim(subarr, data, dtype, index, allow_2d\u001b[39m=\u001b[39;49mallow_2d)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=599'>600</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subarr, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=600'>601</a>\u001b[0m     \u001b[39m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=601'>602</a>\u001b[0m     dtype \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mdtype, dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/construction.py:643\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=638'>639</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mresult should be arraylike with ndim > 0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=640'>641</a>\u001b[0m \u001b[39melif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=641'>642</a>\u001b[0m     \u001b[39m# the result that we want\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=642'>643</a>\u001b[0m     result \u001b[39m=\u001b[39m _maybe_repeat(result, index)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=644'>645</a>\u001b[0m \u001b[39melif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/pandas/core/construction.py?line=645'>646</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 11)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "        # User_EASE = user_ease, \n",
    "        # Item_EASE = item_ease, \n",
    "        AdmmSlim = admm_slim, \n",
    "        HOSLIM = hoslim,\n",
    "        RecVAE = rec_vae, \n",
    "        # MultiVAE = multi_vae, \n",
    "        MultiDAE = multi_dae, \n",
    "        # AutoRec = auto_rec,\n",
    "        X = X.todense(), \n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid,\n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 11)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "        # User_EASE = user_ease, \n",
    "        # Item_EASE = item_ease, \n",
    "        AdmmSlim = admm_slim, \n",
    "        HOSLIM = hoslim,\n",
    "        RecVAE = rec_vae, \n",
    "        # MultiVAE = multi_vae, \n",
    "        MultiDAE = multi_dae, \n",
    "        # AutoRec = auto_rec,\n",
    "        X = X.todense(), \n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid,\n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4. get_weighted_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:54, 179.98it/s]\n"
     ]
    }
   ],
   "source": [
    "weighted_ensemble_df = get_weighted_ensemble_df(\n",
    "    User_EASE = user_ease, \n",
    "    Item_EASE = item_ease, \n",
    "    AdmmSlim = admm_slim, \n",
    "    HOSLIM = hoslim, \n",
    "    RecVAE = rec_vae, \n",
    "    MultiVAE = multi_vae, \n",
    "    MultiDAE = multi_dae, \n",
    "    AutoRec = auto_rec,\n",
    "    X = X.todense(),\n",
    "    candidate_cnt = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_total</th>\n",
       "      <th>mean_total</th>\n",
       "      <th>rank_sum_total</th>\n",
       "      <th>rank_mean_total</th>\n",
       "      <th>log_rank_sum_total</th>\n",
       "      <th>log_rank_mean_total</th>\n",
       "      <th>sum_total_rank</th>\n",
       "      <th>mean_total_rank</th>\n",
       "      <th>rank_sum_total_rank</th>\n",
       "      <th>rank_mean_total_rank</th>\n",
       "      <th>log_rank_sum_total_rank</th>\n",
       "      <th>log_rank_mean_total_rank</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>77.0</td>\n",
       "      <td>9.625</td>\n",
       "      <td>1.890000</td>\n",
       "      <td>0.236250</td>\n",
       "      <td>3.249907</td>\n",
       "      <td>0.406238</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>89.0</td>\n",
       "      <td>11.125</td>\n",
       "      <td>1.016807</td>\n",
       "      <td>0.127101</td>\n",
       "      <td>2.482270</td>\n",
       "      <td>0.310284</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>103.0</td>\n",
       "      <td>12.875</td>\n",
       "      <td>0.885684</td>\n",
       "      <td>0.110710</td>\n",
       "      <td>2.348951</td>\n",
       "      <td>0.293619</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>160.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.671620</td>\n",
       "      <td>0.083953</td>\n",
       "      <td>2.104386</td>\n",
       "      <td>0.263048</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>156.0</td>\n",
       "      <td>19.500</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.072167</td>\n",
       "      <td>2.015265</td>\n",
       "      <td>0.251908</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>353.0</td>\n",
       "      <td>44.125</td>\n",
       "      <td>0.198256</td>\n",
       "      <td>0.024782</td>\n",
       "      <td>1.478949</td>\n",
       "      <td>0.184869</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.500</td>\n",
       "      <td>6.424242</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>6.778943</td>\n",
       "      <td>0.847368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>55.0</td>\n",
       "      <td>6.875</td>\n",
       "      <td>2.464286</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>3.691374</td>\n",
       "      <td>0.461422</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>76.0</td>\n",
       "      <td>9.500</td>\n",
       "      <td>2.386667</td>\n",
       "      <td>0.298333</td>\n",
       "      <td>3.668348</td>\n",
       "      <td>0.458543</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>92.0</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1.471739</td>\n",
       "      <td>0.183967</td>\n",
       "      <td>2.889752</td>\n",
       "      <td>0.361219</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>77.0</td>\n",
       "      <td>9.625</td>\n",
       "      <td>1.095833</td>\n",
       "      <td>0.136979</td>\n",
       "      <td>2.580394</td>\n",
       "      <td>0.322549</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>216.0</td>\n",
       "      <td>27.000</td>\n",
       "      <td>1.283563</td>\n",
       "      <td>0.160445</td>\n",
       "      <td>2.473155</td>\n",
       "      <td>0.309144</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>112.0</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.888290</td>\n",
       "      <td>0.111036</td>\n",
       "      <td>2.364695</td>\n",
       "      <td>0.295587</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>196.0</td>\n",
       "      <td>24.500</td>\n",
       "      <td>0.987965</td>\n",
       "      <td>0.123496</td>\n",
       "      <td>2.319040</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>200.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.925278</td>\n",
       "      <td>0.115660</td>\n",
       "      <td>2.270949</td>\n",
       "      <td>0.283869</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>203.0</td>\n",
       "      <td>25.375</td>\n",
       "      <td>0.858291</td>\n",
       "      <td>0.107286</td>\n",
       "      <td>2.192795</td>\n",
       "      <td>0.274099</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>145.0</td>\n",
       "      <td>18.125</td>\n",
       "      <td>0.594155</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>2.045158</td>\n",
       "      <td>0.255645</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>159.0</td>\n",
       "      <td>19.875</td>\n",
       "      <td>0.555231</td>\n",
       "      <td>0.069404</td>\n",
       "      <td>1.988171</td>\n",
       "      <td>0.248521</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>257.0</td>\n",
       "      <td>32.125</td>\n",
       "      <td>0.521844</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>1.865490</td>\n",
       "      <td>0.233186</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>193.0</td>\n",
       "      <td>24.125</td>\n",
       "      <td>0.418833</td>\n",
       "      <td>0.052354</td>\n",
       "      <td>1.821193</td>\n",
       "      <td>0.227649</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sum_total  mean_total  rank_sum_total  rank_mean_total  \\\n",
       "197        77.0       9.625        1.890000         0.236250   \n",
       "273        89.0      11.125        1.016807         0.127101   \n",
       "313       103.0      12.875        0.885684         0.110710   \n",
       "42        160.0      20.000        0.671620         0.083953   \n",
       "228       156.0      19.500        0.577337         0.072167   \n",
       "147       353.0      44.125        0.198256         0.024782   \n",
       "933        20.0       2.500        6.424242         0.803030   \n",
       "667        55.0       6.875        2.464286         0.308036   \n",
       "484        76.0       9.500        2.386667         0.298333   \n",
       "376        92.0      11.500        1.471739         0.183967   \n",
       "2200       77.0       9.625        1.095833         0.136979   \n",
       "609       216.0      27.000        1.283563         0.160445   \n",
       "650       112.0      14.000        0.888290         0.111036   \n",
       "718       196.0      24.500        0.987965         0.123496   \n",
       "777       200.0      25.000        0.925278         0.115660   \n",
       "714       203.0      25.375        0.858291         0.107286   \n",
       "760       145.0      18.125        0.594155         0.074269   \n",
       "734       159.0      19.875        0.555231         0.069404   \n",
       "1844      257.0      32.125        0.521844         0.065230   \n",
       "730       193.0      24.125        0.418833         0.052354   \n",
       "\n",
       "      log_rank_sum_total  log_rank_mean_total  sum_total_rank  \\\n",
       "197             3.249907             0.406238               4   \n",
       "273             2.482270             0.310284               6   \n",
       "313             2.348951             0.293619               8   \n",
       "42              2.104386             0.263048              13   \n",
       "228             2.015265             0.251908              11   \n",
       "147             1.478949             0.184869              56   \n",
       "933             6.778943             0.847368               1   \n",
       "667             3.691374             0.461422               2   \n",
       "484             3.668348             0.458543               3   \n",
       "376             2.889752             0.361219               7   \n",
       "2200            2.580394             0.322549               5   \n",
       "609             2.473155             0.309144              19   \n",
       "650             2.364695             0.295587               9   \n",
       "718             2.319040             0.289880              16   \n",
       "777             2.270949             0.283869              17   \n",
       "714             2.192795             0.274099              18   \n",
       "760             2.045158             0.255645              10   \n",
       "734             1.988171             0.248521              12   \n",
       "1844            1.865490             0.233186              26   \n",
       "730             1.821193             0.227649              15   \n",
       "\n",
       "      mean_total_rank  rank_sum_total_rank  rank_mean_total_rank  \\\n",
       "197                 4                    4                     4   \n",
       "273                 6                    8                     8   \n",
       "313                 8                   12                    12   \n",
       "42                 13                   14                    14   \n",
       "228                11                   16                    16   \n",
       "147                56                   55                    55   \n",
       "933                 1                    1                     1   \n",
       "667                 2                    2                     2   \n",
       "484                 3                    3                     3   \n",
       "376                 7                    5                     5   \n",
       "2200                5                    7                     7   \n",
       "609                19                    6                     6   \n",
       "650                 9                   11                    11   \n",
       "718                16                    9                     9   \n",
       "777                17                   10                    10   \n",
       "714                18                   13                    13   \n",
       "760                10                   15                    15   \n",
       "734                12                   17                    17   \n",
       "1844               26                   18                    18   \n",
       "730                15                   20                    20   \n",
       "\n",
       "      log_rank_sum_total_rank  log_rank_mean_total_rank  target  \n",
       "197                         4                         4     1.0  \n",
       "273                         7                         7     1.0  \n",
       "313                        10                        10     1.0  \n",
       "42                         14                        14     1.0  \n",
       "228                        16                        16     1.0  \n",
       "147                        57                        57     1.0  \n",
       "933                         1                         1     NaN  \n",
       "667                         2                         2     NaN  \n",
       "484                         3                         3     NaN  \n",
       "376                         5                         5     NaN  \n",
       "2200                        6                         6     NaN  \n",
       "609                         8                         8     NaN  \n",
       "650                         9                         9     NaN  \n",
       "718                        11                        11     NaN  \n",
       "777                        12                        12     NaN  \n",
       "714                        13                        13     NaN  \n",
       "760                        15                        15     NaN  \n",
       "734                        17                        17     NaN  \n",
       "1844                       18                        18     NaN  \n",
       "730                        19                        19     NaN  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. rank sum 제일 낮은 순\n",
    "2. rank sum mean 제일 낮은 순\n",
    "\n",
    "3. 1/rank sum 제일 높은 순\n",
    "4. 1/rank sum mean 제일 높은 순\n",
    "\n",
    "5. 1 / log(rank + 1) sum 제일 높은 순\n",
    "6. 1 / log(rank + 1) sum mean 제일 높은 순\n",
    "\n",
    "7. 선별 model + 위 과정\n",
    "8. 선별 model + 각 모델별 가중치 + 위 과정\n",
    "'''\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "def get_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / x\n",
    "\n",
    "def get_log_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / np.log2(x + 1)\n",
    "\n",
    "# cols : ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "# weighte : [1.0, 0.6, 0.8, 0.3]| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "\n",
    "df = weighted_ensemble_df[0].copy()\n",
    "cols = df.columns\n",
    "log_rank_score_cols = []\n",
    "rank_score_cols = []\n",
    "for col in cols:\n",
    "    df['rank_score_'+col] = df[col].apply(lambda x : get_rank_score(x))\n",
    "    rank_score_cols.append('rank_score_'+col)\n",
    "\n",
    "    df['log_rank_score_'+col] = df[col].apply(lambda x : get_log_rank_score(x))\n",
    "    log_rank_score_cols.append('log_rank_score_'+col)\n",
    "\n",
    "uv = user_valid[0]\n",
    "up = df.index.tolist()\n",
    "target = list(set(uv) & set(up))\n",
    "\n",
    "rank_score_df = df[rank_score_cols]\n",
    "log_rank_score_df = df[log_rank_score_cols]\n",
    "df = df[cols]\n",
    "\n",
    "rank_score_df = rank_score_df.fillna(rank_score_df.min().min())\n",
    "rank_score_df['rank_sum_total'] = rank_score_df[rank_score_cols].sum(axis = 1)\n",
    "rank_score_df['rank_mean_total'] = rank_score_df[rank_score_cols].mean(axis = 1)\n",
    "\n",
    "log_rank_score_df = log_rank_score_df.fillna(log_rank_score_df.min().min())\n",
    "log_rank_score_df['log_rank_sum_total'] = log_rank_score_df[log_rank_score_cols].sum(axis = 1)\n",
    "log_rank_score_df['log_rank_mean_total'] = log_rank_score_df[log_rank_score_cols].mean(axis = 1)\n",
    "\n",
    "df = df.fillna(df.max().max())\n",
    "df['sum_total'] = df[cols].sum(axis = 1)\n",
    "df['mean_total'] = df[cols].mean(axis = 1)\n",
    "\n",
    "df = pd.concat([df, rank_score_df, log_rank_score_df], axis = 1)\n",
    "\n",
    "df = df[['sum_total', 'mean_total', 'rank_sum_total', 'rank_mean_total', 'log_rank_sum_total', 'log_rank_mean_total']]\n",
    "\n",
    "df = df.sort_values('sum_total', ascending = True)\n",
    "df['sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('mean_total', ascending = True)\n",
    "df['mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_sum_total', ascending = False)\n",
    "df['rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_mean_total', ascending = False)\n",
    "df['rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_sum_total', ascending = False)\n",
    "df['log_rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_mean_total', ascending = False)\n",
    "df['log_rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df.loc[target, 'target'] = 1\n",
    "df.sort_values('target', ascending = True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_total</th>\n",
       "      <th>mean_total</th>\n",
       "      <th>rank_sum_total</th>\n",
       "      <th>rank_mean_total</th>\n",
       "      <th>log_rank_sum_total</th>\n",
       "      <th>log_rank_mean_total</th>\n",
       "      <th>sum_total_rank</th>\n",
       "      <th>mean_total_rank</th>\n",
       "      <th>rank_sum_total_rank</th>\n",
       "      <th>rank_mean_total_rank</th>\n",
       "      <th>log_rank_sum_total_rank</th>\n",
       "      <th>log_rank_mean_total_rank</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>42.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.204167</td>\n",
       "      <td>1.519378</td>\n",
       "      <td>0.379845</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>50.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>1.142500</td>\n",
       "      <td>0.285625</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>49.0</td>\n",
       "      <td>12.25</td>\n",
       "      <td>0.397076</td>\n",
       "      <td>0.099269</td>\n",
       "      <td>1.138615</td>\n",
       "      <td>0.284654</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>68.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.346726</td>\n",
       "      <td>0.086682</td>\n",
       "      <td>1.071282</td>\n",
       "      <td>0.267820</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>62.0</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.299573</td>\n",
       "      <td>0.074893</td>\n",
       "      <td>1.031578</td>\n",
       "      <td>0.257895</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>153.0</td>\n",
       "      <td>38.25</td>\n",
       "      <td>0.118256</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.773783</td>\n",
       "      <td>0.193446</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>14.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>3.278943</td>\n",
       "      <td>0.819736</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2.118067</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.488095</td>\n",
       "      <td>0.372024</td>\n",
       "      <td>2.026196</td>\n",
       "      <td>0.506549</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>21.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1.650418</td>\n",
       "      <td>0.412604</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>83.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>0.688478</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>1.340790</td>\n",
       "      <td>0.335198</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>34.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.123512</td>\n",
       "      <td>1.252370</td>\n",
       "      <td>0.313092</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>118.0</td>\n",
       "      <td>29.50</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>1.228163</td>\n",
       "      <td>0.307041</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>46.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>1.162007</td>\n",
       "      <td>0.290502</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>86.0</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.398918</td>\n",
       "      <td>0.099729</td>\n",
       "      <td>1.104123</td>\n",
       "      <td>0.276031</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>53.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.086150</td>\n",
       "      <td>1.085774</td>\n",
       "      <td>0.271444</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>83.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>0.272870</td>\n",
       "      <td>0.068217</td>\n",
       "      <td>0.987090</td>\n",
       "      <td>0.246772</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>121.0</td>\n",
       "      <td>30.25</td>\n",
       "      <td>0.299232</td>\n",
       "      <td>0.074808</td>\n",
       "      <td>0.980141</td>\n",
       "      <td>0.245035</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>119.0</td>\n",
       "      <td>29.75</td>\n",
       "      <td>0.283590</td>\n",
       "      <td>0.070897</td>\n",
       "      <td>0.971440</td>\n",
       "      <td>0.242860</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>154.0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.959551</td>\n",
       "      <td>0.239888</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sum_total  mean_total  rank_sum_total  rank_mean_total  \\\n",
       "197        42.0       10.50        0.816667         0.204167   \n",
       "313        50.0       12.50        0.405556         0.101389   \n",
       "273        49.0       12.25        0.397076         0.099269   \n",
       "42         68.0       17.00        0.346726         0.086682   \n",
       "228        62.0       15.50        0.299573         0.074893   \n",
       "147       153.0       38.25        0.118256         0.029564   \n",
       "933        14.0        3.50        3.090909         0.772727   \n",
       "484        13.0        3.25        1.500000         0.375000   \n",
       "667        30.0        7.50        1.488095         0.372024   \n",
       "376        21.0        5.25        0.933333         0.233333   \n",
       "714        83.0       20.75        0.688478         0.172120   \n",
       "650        34.0        8.50        0.494048         0.123512   \n",
       "777       118.0       29.50        0.602500         0.150625   \n",
       "2200       46.0       11.50        0.416667         0.104167   \n",
       "718        86.0       21.50        0.398918         0.099729   \n",
       "760        53.0       13.25        0.344600         0.086150   \n",
       "734        83.0       20.75        0.272870         0.068217   \n",
       "717       121.0       30.25        0.299232         0.074808   \n",
       "1354      119.0       29.75        0.283590         0.070897   \n",
       "2427      154.0       38.50        0.310000         0.077500   \n",
       "\n",
       "      log_rank_sum_total  log_rank_mean_total  sum_total_rank  \\\n",
       "197             1.519378             0.379845               6   \n",
       "313             1.142500             0.285625               9   \n",
       "273             1.138615             0.284654               8   \n",
       "42              1.071282             0.267820              12   \n",
       "228             1.031578             0.257895              11   \n",
       "147             0.773783             0.193446              35   \n",
       "933             3.278943             0.819736               2   \n",
       "484             2.118067             0.529517               1   \n",
       "667             2.026196             0.506549               4   \n",
       "376             1.650418             0.412604               3   \n",
       "714             1.340790             0.335198              14   \n",
       "650             1.252370             0.313092               5   \n",
       "777             1.228163             0.307041              21   \n",
       "2200            1.162007             0.290502               7   \n",
       "718             1.104123             0.276031              15   \n",
       "760             1.085774             0.271444              10   \n",
       "734             0.987090             0.246772              13   \n",
       "717             0.980141             0.245035              24   \n",
       "1354            0.971440             0.242860              22   \n",
       "2427            0.959551             0.239888              36   \n",
       "\n",
       "      mean_total_rank  rank_sum_total_rank  rank_mean_total_rank  \\\n",
       "197                 6                    5                     5   \n",
       "313                 9                   10                    10   \n",
       "273                 8                   12                    12   \n",
       "42                 12                   13                    13   \n",
       "228                11                   16                    16   \n",
       "147                35                   37                    37   \n",
       "933                 2                    1                     1   \n",
       "484                 1                    2                     2   \n",
       "667                 4                    3                     3   \n",
       "376                 3                    4                     4   \n",
       "714                14                    6                     6   \n",
       "650                 5                    8                     8   \n",
       "777                21                    7                     7   \n",
       "2200                7                    9                     9   \n",
       "718                15                   11                    11   \n",
       "760                10                   14                    14   \n",
       "734                13                   19                    19   \n",
       "717                24                   17                    17   \n",
       "1354               22                   18                    18   \n",
       "2427               36                   15                    15   \n",
       "\n",
       "      log_rank_sum_total_rank  log_rank_mean_total_rank  target  \n",
       "197                         5                         5     1.0  \n",
       "313                        10                        10     1.0  \n",
       "273                        11                        11     1.0  \n",
       "42                         14                        14     1.0  \n",
       "228                        15                        15     1.0  \n",
       "147                        37                        37     1.0  \n",
       "933                         1                         1     NaN  \n",
       "484                         2                         2     NaN  \n",
       "667                         3                         3     NaN  \n",
       "376                         4                         4     NaN  \n",
       "714                         6                         6     NaN  \n",
       "650                         7                         7     NaN  \n",
       "777                         8                         8     NaN  \n",
       "2200                        9                         9     NaN  \n",
       "718                        12                        12     NaN  \n",
       "760                        13                        13     NaN  \n",
       "734                        16                        16     NaN  \n",
       "717                        17                        17     NaN  \n",
       "1354                       18                        18     NaN  \n",
       "2427                       19                        19     NaN  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "def get_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / x\n",
    "\n",
    "def get_log_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / np.log2(x + 1)\n",
    "\n",
    "# cols : ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "# weighte : [1.0, 0.6, 0.8, 0.3]| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "\n",
    "df = weighted_ensemble_df[0].copy()\n",
    "cols = [col for col in df.columns if col in ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']]\n",
    "log_rank_score_cols = []\n",
    "rank_score_cols = []\n",
    "for col in cols:\n",
    "    df['rank_score_'+col] = df[col].apply(lambda x : get_rank_score(x))\n",
    "    rank_score_cols.append('rank_score_'+col)\n",
    "\n",
    "    df['log_rank_score_'+col] = df[col].apply(lambda x : get_log_rank_score(x))\n",
    "    log_rank_score_cols.append('log_rank_score_'+col)\n",
    "\n",
    "uv = user_valid[0]\n",
    "up = df.index.tolist()\n",
    "target = list(set(uv) & set(up))\n",
    "\n",
    "rank_score_df = df[rank_score_cols]\n",
    "log_rank_score_df = df[log_rank_score_cols]\n",
    "df = df[cols]\n",
    "\n",
    "rank_score_df = rank_score_df.fillna(rank_score_df.min().min())\n",
    "rank_score_df['rank_sum_total'] = rank_score_df[rank_score_cols].sum(axis = 1)\n",
    "rank_score_df['rank_mean_total'] = rank_score_df[rank_score_cols].mean(axis = 1)\n",
    "\n",
    "log_rank_score_df = log_rank_score_df.fillna(log_rank_score_df.min().min())\n",
    "log_rank_score_df['log_rank_sum_total'] = log_rank_score_df[log_rank_score_cols].sum(axis = 1)\n",
    "log_rank_score_df['log_rank_mean_total'] = log_rank_score_df[log_rank_score_cols].mean(axis = 1)\n",
    "\n",
    "df = df.fillna(df.max().max())\n",
    "df['sum_total'] = df[cols].sum(axis = 1)\n",
    "df['mean_total'] = df[cols].mean(axis = 1)\n",
    "\n",
    "df = pd.concat([df, rank_score_df, log_rank_score_df], axis = 1)\n",
    "\n",
    "df = df[['sum_total', 'mean_total', 'rank_sum_total', 'rank_mean_total', 'log_rank_sum_total', 'log_rank_mean_total']]\n",
    "\n",
    "df = df.sort_values('sum_total', ascending = True)\n",
    "df['sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('mean_total', ascending = True)\n",
    "df['mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_sum_total', ascending = False)\n",
    "df['rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_mean_total', ascending = False)\n",
    "df['rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_sum_total', ascending = False)\n",
    "df['log_rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_mean_total', ascending = False)\n",
    "df['log_rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df.loc[target, 'target'] = 1\n",
    "df.sort_values('target', ascending = True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_total</th>\n",
       "      <th>mean_total</th>\n",
       "      <th>rank_sum_total</th>\n",
       "      <th>rank_mean_total</th>\n",
       "      <th>log_rank_sum_total</th>\n",
       "      <th>log_rank_mean_total</th>\n",
       "      <th>sum_total_rank</th>\n",
       "      <th>mean_total_rank</th>\n",
       "      <th>rank_sum_total_rank</th>\n",
       "      <th>rank_mean_total_rank</th>\n",
       "      <th>log_rank_sum_total_rank</th>\n",
       "      <th>log_rank_mean_total_rank</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>32.3</td>\n",
       "      <td>8.075</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.204167</td>\n",
       "      <td>1.222938</td>\n",
       "      <td>0.305735</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>32.1</td>\n",
       "      <td>8.025</td>\n",
       "      <td>0.397076</td>\n",
       "      <td>0.099269</td>\n",
       "      <td>0.896522</td>\n",
       "      <td>0.224131</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>35.1</td>\n",
       "      <td>8.775</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.892268</td>\n",
       "      <td>0.223067</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>38.2</td>\n",
       "      <td>9.550</td>\n",
       "      <td>0.346726</td>\n",
       "      <td>0.086682</td>\n",
       "      <td>0.850596</td>\n",
       "      <td>0.212649</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>37.2</td>\n",
       "      <td>9.300</td>\n",
       "      <td>0.299573</td>\n",
       "      <td>0.074893</td>\n",
       "      <td>0.806808</td>\n",
       "      <td>0.201702</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>118.9</td>\n",
       "      <td>29.725</td>\n",
       "      <td>0.118256</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.536382</td>\n",
       "      <td>0.134096</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>8.7</td>\n",
       "      <td>2.175</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>2.941036</td>\n",
       "      <td>0.735259</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>7.4</td>\n",
       "      <td>1.850</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.813483</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>18.4</td>\n",
       "      <td>4.600</td>\n",
       "      <td>1.488095</td>\n",
       "      <td>0.372024</td>\n",
       "      <td>1.742804</td>\n",
       "      <td>0.435701</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1.371002</td>\n",
       "      <td>0.342750</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>80.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.688478</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>1.012589</td>\n",
       "      <td>0.253147</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>24.2</td>\n",
       "      <td>6.050</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.123512</td>\n",
       "      <td>0.986268</td>\n",
       "      <td>0.246567</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>27.6</td>\n",
       "      <td>6.900</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.920824</td>\n",
       "      <td>0.230206</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>62.5</td>\n",
       "      <td>15.625</td>\n",
       "      <td>0.398918</td>\n",
       "      <td>0.099729</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.213952</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>31.4</td>\n",
       "      <td>7.850</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.086150</td>\n",
       "      <td>0.855459</td>\n",
       "      <td>0.213865</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>106.4</td>\n",
       "      <td>26.600</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>0.848630</td>\n",
       "      <td>0.212158</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>44.2</td>\n",
       "      <td>11.050</td>\n",
       "      <td>0.272870</td>\n",
       "      <td>0.068217</td>\n",
       "      <td>0.779848</td>\n",
       "      <td>0.194962</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>55.9</td>\n",
       "      <td>13.975</td>\n",
       "      <td>0.235323</td>\n",
       "      <td>0.058831</td>\n",
       "      <td>0.727259</td>\n",
       "      <td>0.181815</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>91.6</td>\n",
       "      <td>22.900</td>\n",
       "      <td>0.218135</td>\n",
       "      <td>0.054534</td>\n",
       "      <td>0.717638</td>\n",
       "      <td>0.179410</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>114.1</td>\n",
       "      <td>28.525</td>\n",
       "      <td>0.299232</td>\n",
       "      <td>0.074808</td>\n",
       "      <td>0.685956</td>\n",
       "      <td>0.171489</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sum_total  mean_total  rank_sum_total  rank_mean_total  \\\n",
       "197        32.3       8.075        0.816667         0.204167   \n",
       "273        32.1       8.025        0.397076         0.099269   \n",
       "313        35.1       8.775        0.405556         0.101389   \n",
       "42         38.2       9.550        0.346726         0.086682   \n",
       "228        37.2       9.300        0.299573         0.074893   \n",
       "147       118.9      29.725        0.118256         0.029564   \n",
       "933         8.7       2.175        3.090909         0.772727   \n",
       "484         7.4       1.850        1.500000         0.375000   \n",
       "667        18.4       4.600        1.488095         0.372024   \n",
       "376        12.0       3.000        0.933333         0.233333   \n",
       "714        80.0      20.000        0.688478         0.172120   \n",
       "650        24.2       6.050        0.494048         0.123512   \n",
       "2200       27.6       6.900        0.416667         0.104167   \n",
       "718        62.5      15.625        0.398918         0.099729   \n",
       "760        31.4       7.850        0.344600         0.086150   \n",
       "777       106.4      26.600        0.602500         0.150625   \n",
       "734        44.2      11.050        0.272870         0.068217   \n",
       "730        55.9      13.975        0.235323         0.058831   \n",
       "615        91.6      22.900        0.218135         0.054534   \n",
       "717       114.1      28.525        0.299232         0.074808   \n",
       "\n",
       "      log_rank_sum_total  log_rank_mean_total  sum_total_rank  \\\n",
       "197             1.222938             0.305735               9   \n",
       "273             0.896522             0.224131               8   \n",
       "313             0.892268             0.223067              10   \n",
       "42              0.850596             0.212649              12   \n",
       "228             0.806808             0.201702              11   \n",
       "147             0.536382             0.134096              31   \n",
       "933             2.941036             0.735259               2   \n",
       "484             1.813483             0.453371               1   \n",
       "667             1.742804             0.435701               4   \n",
       "376             1.371002             0.342750               3   \n",
       "714             1.012589             0.253147              20   \n",
       "650             0.986268             0.246567               5   \n",
       "2200            0.920824             0.230206               6   \n",
       "718             0.855809             0.213952              16   \n",
       "760             0.855459             0.213865               7   \n",
       "777             0.848630             0.212158              23   \n",
       "734             0.779848             0.194962              13   \n",
       "730             0.727259             0.181815              14   \n",
       "615             0.717638             0.179410              21   \n",
       "717             0.685956             0.171489              28   \n",
       "\n",
       "      mean_total_rank  rank_sum_total_rank  rank_mean_total_rank  \\\n",
       "197                 9                    5                     5   \n",
       "273                 8                   12                    12   \n",
       "313                10                   10                    10   \n",
       "42                 12                   13                    13   \n",
       "228                11                   16                    16   \n",
       "147                31                   37                    37   \n",
       "933                 2                    1                     1   \n",
       "484                 1                    2                     2   \n",
       "667                 4                    3                     3   \n",
       "376                 3                    4                     4   \n",
       "714                20                    6                     6   \n",
       "650                 5                    8                     8   \n",
       "2200                6                    9                     9   \n",
       "718                16                   11                    11   \n",
       "760                 7                   14                    14   \n",
       "777                23                    7                     7   \n",
       "734                13                   19                    19   \n",
       "730                14                   20                    20   \n",
       "615                21                   21                    21   \n",
       "717                28                   17                    17   \n",
       "\n",
       "      log_rank_sum_total_rank  log_rank_mean_total_rank  target  \n",
       "197                         5                         5     1.0  \n",
       "273                         9                         9     1.0  \n",
       "313                        10                        10     1.0  \n",
       "42                         13                        13     1.0  \n",
       "228                        15                        15     1.0  \n",
       "147                        34                        34     1.0  \n",
       "933                         1                         1     NaN  \n",
       "484                         2                         2     NaN  \n",
       "667                         3                         3     NaN  \n",
       "376                         4                         4     NaN  \n",
       "714                         6                         6     NaN  \n",
       "650                         7                         7     NaN  \n",
       "2200                        8                         8     NaN  \n",
       "718                        11                        11     NaN  \n",
       "760                        12                        12     NaN  \n",
       "777                        14                        14     NaN  \n",
       "734                        16                        16     NaN  \n",
       "730                        17                        17     NaN  \n",
       "615                        18                        18     NaN  \n",
       "717                        19                        19     NaN  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "def get_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / x\n",
    "\n",
    "def get_log_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / np.log2(x + 1)\n",
    "\n",
    "# cols : ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "# weighte : [1.0, 0.6, 0.8, 0.3]| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "\n",
    "df = weighted_ensemble_df[0].copy()\n",
    "cols = [col for col in df.columns if col in ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']]\n",
    "log_rank_score_cols = []\n",
    "rank_score_cols = []\n",
    "for col in cols:\n",
    "    if col == 'HOSLIM_rec_score':\n",
    "        w = 1.0\n",
    "    elif col == 'AdmmSlim_rec_score':\n",
    "        w = 0.6\n",
    "    elif col == 'RecVAE_rec_score':\n",
    "        w = 0.8\n",
    "    elif col == 'MultiDAE_rec_score':\n",
    "        w = 0.3\n",
    "\n",
    "    df[col] = df[col] * w\n",
    "\n",
    "    df['rank_score_'+col] = df[col].apply(lambda x : get_rank_score(x)) * w\n",
    "    rank_score_cols.append('rank_score_'+col)\n",
    "\n",
    "    df['log_rank_score_'+col] = df[col].apply(lambda x : get_log_rank_score(x)) * w\n",
    "    log_rank_score_cols.append('log_rank_score_'+col)\n",
    "\n",
    "uv = user_valid[0]\n",
    "up = df.index.tolist()\n",
    "target = list(set(uv) & set(up))\n",
    "\n",
    "rank_score_df = df[rank_score_cols]\n",
    "log_rank_score_df = df[log_rank_score_cols]\n",
    "df = df[cols]\n",
    "\n",
    "rank_score_df = rank_score_df.fillna(rank_score_df.min().min())\n",
    "rank_score_df['rank_sum_total'] = rank_score_df[rank_score_cols].sum(axis = 1)\n",
    "rank_score_df['rank_mean_total'] = rank_score_df[rank_score_cols].mean(axis = 1)\n",
    "\n",
    "log_rank_score_df = log_rank_score_df.fillna(log_rank_score_df.min().min())\n",
    "log_rank_score_df['log_rank_sum_total'] = log_rank_score_df[log_rank_score_cols].sum(axis = 1)\n",
    "log_rank_score_df['log_rank_mean_total'] = log_rank_score_df[log_rank_score_cols].mean(axis = 1)\n",
    "\n",
    "df = df.fillna(df.max().max())\n",
    "df['sum_total'] = df[cols].sum(axis = 1)\n",
    "df['mean_total'] = df[cols].mean(axis = 1)\n",
    "\n",
    "df = pd.concat([df, rank_score_df, log_rank_score_df], axis = 1)\n",
    "\n",
    "df = df[['sum_total', 'mean_total', 'rank_sum_total', 'rank_mean_total', 'log_rank_sum_total', 'log_rank_mean_total']]\n",
    "\n",
    "df = df.sort_values('sum_total', ascending = True)\n",
    "df['sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('mean_total', ascending = True)\n",
    "df['mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_sum_total', ascending = False)\n",
    "df['rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_mean_total', ascending = False)\n",
    "df['rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_sum_total', ascending = False)\n",
    "df['log_rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_mean_total', ascending = False)\n",
    "df['log_rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df.loc[target, 'target'] = 1\n",
    "df.sort_values('target', ascending = True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-5. serch_best_combination_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "target_cols = ['HOSLIM_rec_score', 'User_EASE_rec_score', 'AdmmSlim_rec_score', 'Item_EASE_rec_score', 'RecVAE_rec_score', 'MultiVAE_rec_score', 'MultiDAE_rec_score']\n",
    "users = weighted_ensemble_df.keys()\n",
    "best_hit = 0\n",
    "\n",
    "for combination_count in tqdm(range(2, 8)):\n",
    "    cols_list = list(map(lambda x: list(x), list(combinations(target_cols, combination_count))))\n",
    "    for cols in cols_list:\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "            df = df.fillna(df[cols].max().max())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = True)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        print(f'cols : {cols}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "        if best_hit < HIT:\n",
    "            best_combinations = cols\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "    print(f'BEST cols : {best_combinations}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f}')\n",
    "\n",
    "print(f'Final BEST cols : {best_combinations}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-6. serch_best_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['HOSLIM_rec_score', 'AdmmSlim_rec_score''MultiDAE_rec_score']\n",
    "weightes_list = [np.round(0.1 * i, 2) for i in range(10, 0, -1)]\n",
    "cols = ['RecVAE_rec_score']\n",
    "weightes = [1.0]\n",
    "users = weighted_ensemble_df.keys()\n",
    "for target_col in target_cols:\n",
    "    cols += [target_col]\n",
    "    best_hit = 0\n",
    "    best_weightes = deepcopy(weightes)\n",
    "\n",
    "    for target_weighte in tqdm(weightes_list):\n",
    "        _weightes = deepcopy(weightes)\n",
    "        _weightes += [target_weighte]\n",
    "\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "\n",
    "            for c, w in zip(cols, _weightes):\n",
    "                df[c] = df[c] * w\n",
    "            \n",
    "            df = df.fillna(df[cols].max().max())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = True)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        if best_hit < HIT:\n",
    "            best_weightes = deepcopy(_weightes)\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "        print(f'cols : {cols}| weighte : {_weightes}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "    weightes = deepcopy(best_weightes)\n",
    "    print(f'BEST cols : {cols}| weighte : {weightes}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f} \\n')\n",
    "\n",
    "print(f'cols : {cols}| weighte : {weightes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능이 좋아지지 않음 차라리 1/log2(rank + 1) 방법에 모델 튜닝 순서를 바꿔보는 것이 더 나은 방법일 수도 있을 것 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [01:44<17:25, 104.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['HOSLIM_rec_score', 'User_EASE_rec_score']| weighte : [1.0, 1.0]| NDCG@10: 0.31120| HIT@10: 0.20443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [03:29<15:41, 104.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['HOSLIM_rec_score', 'User_EASE_rec_score']| weighte : [1.0, 1.1]| NDCG@10: 0.31124| HIT@10: 0.20445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [05:13<13:56, 104.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['HOSLIM_rec_score', 'User_EASE_rec_score']| weighte : [1.0, 1.2]| NDCG@10: 0.31124| HIT@10: 0.20445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [06:58<12:12, 104.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['HOSLIM_rec_score', 'User_EASE_rec_score']| weighte : [1.0, 1.3]| NDCG@10: 0.31123| HIT@10: 0.20444\n"
     ]
    }
   ],
   "source": [
    "target_cols = ['User_EASE_rec_score', 'AdmmSlim_rec_score', 'Item_EASE_rec_score', 'RecVAE_rec_score', 'MultiVAE_rec_score', 'MultiDAE_rec_score']\n",
    "weightes_list = [np.round(1 + 0.1 * i, 2) for i in range(11)]\n",
    "cols = ['HOSLIM_rec_score']\n",
    "weightes = [1.0]\n",
    "users = weighted_ensemble_df.keys()\n",
    "for target_col in target_cols:\n",
    "    cols += [target_col]\n",
    "    best_hit = 0\n",
    "    best_weightes = deepcopy(weightes)\n",
    "\n",
    "    for target_weighte in tqdm(weightes_list):\n",
    "        _weightes = deepcopy(weightes)\n",
    "        _weightes += [target_weighte]\n",
    "\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "\n",
    "            for c, w in zip(cols, _weightes):\n",
    "                df[c] = df[c] * w\n",
    "            \n",
    "            df = df.fillna(df[cols].max().max())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = True)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        if best_hit < HIT:\n",
    "            best_weightes = deepcopy(_weightes)\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "        print(f'cols : {cols}| weighte : {_weightes}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "    weightes = deepcopy(best_weightes)\n",
    "    print(f'BEST cols : {cols}| weighte : {weightes}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f} \\n')\n",
    "\n",
    "print(f'cols : {cols}| weighte : {weightes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-7. weighted_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_evaluate(AdmmSlim, HOSLIM, RecVAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    NDCG = 0\n",
    "    HIT = 0\n",
    "    \n",
    "    RecVAE.eval()\n",
    "    MultiVAE.eval()\n",
    "    # MultiDAE.eval()\n",
    "    # AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    # User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    # Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    # MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    # MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    # AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    # AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (HOSLIM_rec, AdmmSlim_rec, RecVAE_rec, MultiVAE_rec) in tqdm(enumerate(zip(HOSLIM_rec_list, AdmmSlim_rec_list, RecVAE_rec_list, MultiVAE_rec_list))):\n",
    "        \n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(HOSLIM_rec + AdmmSlim_rec + RecVAE_rec + MultiVAE_rec))\n",
    "\n",
    "        rec_df = pd.DataFrame(index = all_rec)\n",
    "        rec_df.loc[HOSLIM_rec, 'HOSLIM_rec_score'] = score_li * 1.0\n",
    "        # rec_df.loc[User_EASE_rec, 'User_EASE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[Item_EASE_rec, 'Item_EASE_rec_score'] = score_li * 0.3\n",
    "        rec_df.loc[AdmmSlim_rec, 'AdmmSlim_rec_score'] = score_li * 1.0\n",
    "        rec_df.loc[RecVAE_rec, 'RecVAE_rec_score'] = score_li * 1.4\n",
    "        rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li * 0.5\n",
    "        # rec_df.loc[MultiDAE_rec, 'MultiDAE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[AutoRec_rec, 'AutoRec_rec_score'] = score_li\n",
    "        rec_df = rec_df.fillna(max(score_li * 0.3))\n",
    "\n",
    "        rec_df['total_rec_score'] = rec_df['HOSLIM_rec_score'] + rec_df['AdmmSlim_rec_score'] + rec_df['RecVAE_rec_score'] + rec_df['MultiVAE_rec_score']\n",
    "        rec_df = rec_df.sort_values('total_rec_score', ascending = False)\n",
    "        up = rec_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(5, 11)]:\n",
    "    \n",
    "    ndcg, hit = weighted_evaluate(\n",
    "        # User_EASE = user_ease, \n",
    "        # Item_EASE = item_ease, \n",
    "        AdmmSlim = admm_slim, \n",
    "        HOSLIM = hoslim,\n",
    "        RecVAE = rec_vae, \n",
    "        MultiVAE = multi_vae, \n",
    "        # MultiDAE = multi_dae, \n",
    "        # AutoRec = auto_rec,\n",
    "        X = X.todense(), \n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid,\n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cols : ['HOSLIM_rec_score', 'User_EASE_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "weighte : [1.0, 0.3, 0.7, 1.0, 0.5, 0.3]| NDCG@10: 0.32325| HIT@10: 0.21271\n",
    "\n",
    "candidate_cnt: 25| NDCG@10: 0.32312| HIT@10: 0.21251\n",
    "candidate_cnt: 30| NDCG@10: 0.32325| HIT@10: 0.21271\n",
    "candidate_cnt: 35| NDCG@10: 0.32319| HIT@10: 0.21263\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cols : ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "weighte : [1.0, 0.6, 0.8, 0.3]| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.32052| HIT@10: 0.20994\n",
    "candidate_cnt: 15| NDCG@10: 0.32192| HIT@10: 0.21139\n",
    "candidate_cnt: 20| NDCG@10: 0.32269| HIT@10: 0.21230\n",
    "candidate_cnt: 25| NDCG@10: 0.32282| HIT@10: 0.21252\n",
    "candidate_cnt: 30| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "candidate_cnt: 35| NDCG@10: 0.32293| HIT@10: 0.21271\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "candidate_cnt: 10| NDCG@10: 0.32002| HIT@10: 0.20909\n",
    "candidate_cnt: 15| NDCG@10: 0.32166| HIT@10: 0.21102\n",
    "candidate_cnt: 20| NDCG@10: 0.32212| HIT@10: 0.21153\n",
    "candidate_cnt: 25| NDCG@10: 0.32225| HIT@10: 0.21174\n",
    "candidate_cnt: 30| NDCG@10: 0.32243| HIT@10: 0.21200\n",
    "candidate_cnt: 35| NDCG@10: 0.32231| HIT@10: 0.21187\n",
    "candidate_cnt: 40| NDCG@10: 0.32231| HIT@10: 0.21193\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:33, 204.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.32229| HIT@10: 0.21208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 30\n",
    "\n",
    "ndcg, hit = weighted_evaluate(\n",
    "    # User_EASE = user_ease, \n",
    "    # Item_EASE = item_ease, \n",
    "    AdmmSlim = admm_slim, \n",
    "    HOSLIM = hoslim,\n",
    "    RecVAE = rec_vae, \n",
    "    # MultiVAE = multi_vae, \n",
    "    MultiDAE = multi_dae, \n",
    "    # AutoRec = auto_rec,\n",
    "    X = X.todense(), \n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid,\n",
    "    candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(HOSLIM, User_EASE, AdmmSlim, RecVAE, MultiVAE, MultiDAE, X, candidate_cnt):\n",
    "    \n",
    "    user2rec = {}\n",
    "\n",
    "    RecVAE.eval()\n",
    "    MultiVAE.eval()\n",
    "    MultiDAE.eval()\n",
    "    # AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    # Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    # AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    # AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (HOSLIM_rec, User_EASE_rec, AdmmSlim_rec, RecVAE_rec, MultiVAE_rec, MultiDAE_rec) in tqdm(enumerate(zip(HOSLIM_rec_list, User_EASE_rec_list, AdmmSlim_rec_list, RecVAE_rec_list, MultiVAE_rec_list, MultiDAE_rec_list))):\n",
    "\n",
    "        # ranking\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(HOSLIM_rec + User_EASE_rec + AdmmSlim_rec + RecVAE_rec + MultiVAE_rec + MultiDAE_rec))\n",
    "\n",
    "        rec_df = pd.DataFrame(index = all_rec)\n",
    "        rec_df.loc[HOSLIM_rec, 'HOSLIM_rec_score'] = score_li * 1.0\n",
    "        rec_df.loc[User_EASE_rec, 'User_EASE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[Item_EASE_rec, 'Item_EASE_rec_score'] = score_li * 0.3\n",
    "        rec_df.loc[AdmmSlim_rec, 'AdmmSlim_rec_score'] = score_li * 0.7\n",
    "        rec_df.loc[RecVAE_rec, 'RecVAE_rec_score'] = score_li * 1.0\n",
    "        rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li * 0.5\n",
    "        rec_df.loc[MultiDAE_rec, 'MultiDAE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[AutoRec_rec, 'AutoRec_rec_score'] = score_li\n",
    "        rec_df = rec_df.fillna(min(score_li * 0.3))\n",
    "\n",
    "        rec_df['total_rec_score'] = rec_df['HOSLIM_rec_score'] + rec_df['User_EASE_rec_score'] + rec_df['AdmmSlim_rec_score'] + rec_df['RecVAE_rec_score'] + rec_df['MultiVAE_rec_score'] + rec_df['MultiDAE_rec_score']\n",
    "        rec_df = rec_df.sort_values('total_rec_score', ascending = False)\n",
    "        up = rec_df.index.tolist()[:10]\n",
    "\n",
    "        user2rec[user] = up\n",
    "\n",
    "    return user2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoslim = HOSLIM(threshold = 3500, lambdaBB = 500, lambdaCC = 15000, rho = 10000)\n",
    "hoslim.fit(X = X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "admm_slim = AdmmSlim(lambda_1 = 10, lambda_2 = 5, rho = 1000)\n",
    "admm_slim.fit(X = X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ease = EASE(X = X_test, reg = 680)\n",
    "user_ease.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ease = EASE(X = X_test.T, reg = 4400)\n",
    "item_ease.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_vae = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "rec_vae.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v7.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_rec = AutoRec(\n",
    "#     num = make_matrix_data_set.num_item, \n",
    "#     num_factor = 64).to(device)\n",
    "\n",
    "# auto_rec.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dae = MultiDAE(\n",
    "    p_dims = [200, 600] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "multi_dae.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_vae = MultiVAE(\n",
    "    p_dims = [200, 600] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.7).to(device)\n",
    "\n",
    "multi_vae.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v4.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:55, 178.44it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    User_EASE = user_ease, \n",
    "    # Item_EASE = item_ease, \n",
    "    AdmmSlim = admm_slim, \n",
    "    HOSLIM = hoslim, \n",
    "    RecVAE = rec_vae, \n",
    "    MultiVAE = multi_vae, \n",
    "    MultiDAE = multi_dae, \n",
    "    # AutoRec = auto_rec, \n",
    "    X = X_test.todense(), \n",
    "    candidate_cnt = 30)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>32587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>2762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11   4886\n",
       "2           11  40815\n",
       "3           11   8961\n",
       "4           11   7373\n",
       "...        ...    ...\n",
       "313595  138493    110\n",
       "313596  138493   5349\n",
       "313597  138493   8970\n",
       "313598  138493  32587\n",
       "313599  138493   2762\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과거-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']\n",
    "[1.0, 0.6, 0.8, 0.7, 1.0]\n",
    "```\n",
    "\n",
    "```\n",
    "['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score'] \n",
    "[1.0, 0.8, 0.9, 1.0, 1.0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model1, model2, model3, model4, RecVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    NDCG = 0.0 # NDCG@10\n",
    "    HIT = 0.0 # HIT@10\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = model3.pred.cpu()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = model4.pred.cpu()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li * 0.6\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li * 0.7\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li * 0.8\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li * 1.0\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li * 1.0\n",
    "        movie_df = movie_df.fillna(min(score_li * 0.6))\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT\n",
    "\n",
    "def predict(model1, model2, model3, model4, RecVAE, X, candidate_cnt):\n",
    "    user2rec = {}\n",
    "\n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = model3.pred.cpu()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = model4.pred.cpu()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5))):\n",
    "        \n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li * 0.6\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li * 0.7\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li * 0.8\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li * 1.0\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li * 1.0\n",
    "        movie_df = movie_df.fillna(min(score_li * 0.6))\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        user2rec[user] = up\n",
    "\n",
    "    return user2rec\n",
    "\n",
    "\n",
    "def total_evaluate(model1, model2, model3, model4, RecVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    df = []\n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = model3.pred.cpu()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = model4.pred.cpu()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        rec12345 = list(set(rec1 + rec2 + rec3 + rec4 + rec5))\n",
    "\n",
    "        df.append(\n",
    "            {\n",
    "               'user' : user,\n",
    "               'len' : len(rec12345),\n",
    "\n",
    "               'rec1' : get_hit(pred_list = rec1, true_list = uv),\n",
    "               'rec2' : get_hit(pred_list = rec2, true_list = uv),\n",
    "               'rec3' : get_hit(pred_list = rec3, true_list = uv),\n",
    "               'rec4' : get_hit(pred_list = rec4, true_list = uv),\n",
    "               'rec5' : get_hit(pred_list = rec5, true_list = uv),\n",
    "\n",
    "               'rec12345' : get_hit(pred_list = rec12345, true_list = uv),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gupkaJHMslCi"
   },
   "source": [
    "## 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdmmSlim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000022vscode-remote?line=0'>1</a>\u001b[0m model3 \u001b[39m=\u001b[39m AdmmSlim(lambda_2 \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, rho \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000022vscode-remote?line=1'>2</a>\u001b[0m model3\u001b[39m.\u001b[39mfit(X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mtoarray())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdmmSlim' is not defined"
     ]
    }
   ],
   "source": [
    "model3 = AdmmSlim(lambda_2 = 1, rho = 1000)\n",
    "model3.fit(X = X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = HOSLIM()\n",
    "model4.fit(X = X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [00:01, 23357.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df = total_evaluate(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    model3 = model3, \n",
    "    model4 = model4, \n",
    "    RecVAE = model5,\n",
    "    X = X.todense(), \n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid, \n",
    "    candidate_cnt = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>len</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec12345</th>\n",
       "      <th>total_val</th>\n",
       "      <th>total_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rec3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>31355</td>\n",
       "      <td>14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>31356</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>31357</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>31358</td>\n",
       "      <td>19</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>31359</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  len  rec1  rec2  rec3  rec4  rec5  rec12345  total_val  \\\n",
       "0          0   19   0.3   0.3   0.3   0.3   0.2       0.5        0.3   \n",
       "1          1   16   0.1   0.1   0.1   0.1   0.2       0.2        0.2   \n",
       "2          2   14   0.3   0.3   0.3   0.3   0.3       0.3        0.3   \n",
       "3          3   15   0.3   0.3   0.4   0.3   0.2       0.4        0.4   \n",
       "4          4   20   0.4   0.3   0.5   0.4   0.4       0.6        0.5   \n",
       "...      ...  ...   ...   ...   ...   ...   ...       ...        ...   \n",
       "31355  31355   14   0.2   0.4   0.3   0.3   0.2       0.4        0.4   \n",
       "31356  31356   19   0.3   0.3   0.2   0.3   0.3       0.4        0.3   \n",
       "31357  31357   15   0.2   0.3   0.2   0.2   0.2       0.3        0.3   \n",
       "31358  31358   19   0.1   0.1   0.1   0.1   0.0       0.1        0.1   \n",
       "31359  31359   23   0.0   0.2   0.0   0.0   0.1       0.2        0.2   \n",
       "\n",
       "      total_name  \n",
       "0           rec1  \n",
       "1           rec5  \n",
       "2           rec1  \n",
       "3           rec3  \n",
       "4           rec3  \n",
       "...          ...  \n",
       "31355       rec2  \n",
       "31356       rec1  \n",
       "31357       rec2  \n",
       "31358       rec1  \n",
       "31359       rec2  \n",
       "\n",
       "[31360 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저들 마다 rec1 or rec2 or rec3 or ranking 등 맞는 방법에 따라사 추천을 해주는 것도 좋은 방법이 될 수 있음\n",
    "\n",
    "new_df = pd.DataFrame(df)\n",
    "\n",
    "def get_total_name(x):\n",
    "    val_list = [x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5']]\n",
    "    max_val = max(val_list)\n",
    "    val_idx = val_list.index(max_val)\n",
    "    if val_idx == 0 : return 'rec1'\n",
    "    elif val_idx == 1 : return 'rec2'\n",
    "    elif val_idx == 2 : return 'rec3'\n",
    "    elif val_idx == 3 : return 'rec4'\n",
    "    elif val_idx == 4 : return 'rec5'\n",
    "\n",
    "new_df['total_val'] = new_df.apply(lambda x: max(x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5']), axis = 1)\n",
    "new_df['total_name'] = new_df.apply(lambda x: get_total_name(x), axis = 1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.histplot(data = new_df[[\"rec1\", \"rec2\", \"rec3\", \"rec4\", \"rec5\", 'rec12345', 'total_val']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec1    17836\n",
       "rec2     4347\n",
       "rec5     4094\n",
       "rec3     3845\n",
       "rec4     1238\n",
       "Name: total_name, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['total_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         15679.500000\n",
       "len             18.487372\n",
       "rec1             0.203839\n",
       "rec2             0.200207\n",
       "rec3             0.200236\n",
       "rec4             0.204426\n",
       "rec5             0.192140\n",
       "rec12345         0.282586\n",
       "total_val        0.254110\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:35, 201.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 35| NDCG@10: 0.32099| HIT@10: 0.21087\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 35\n",
    "\n",
    "ndcg, hit = evaluate(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    model3 = model3, \n",
    "    model4 = model4, \n",
    "    RecVAE = model5, \n",
    "    X = X.todense(),\n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid, \n",
    "    candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:34, 203.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.31945| HIT@10: 0.20952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:34, 202.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 15| NDCG@10: 0.31997| HIT@10: 0.21003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:38, 198.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 20| NDCG@10: 0.32015| HIT@10: 0.21019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:35, 202.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 25| NDCG@10: 0.32026| HIT@10: 0.21032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:37, 199.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.32039| HIT@10: 0.21046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:36, 200.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 35| NDCG@10: 0.32034| HIT@10: 0.21040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:37, 198.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 40| NDCG@10: 0.32030| HIT@10: 0.21037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:39, 196.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 45| NDCG@10: 0.32035| HIT@10: 0.21041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:40, 195.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 50| NDCG@10: 0.32036| HIT@10: 0.21044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:42, 193.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 55| NDCG@10: 0.32036| HIT@10: 0.21043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:46, 188.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 60| NDCG@10: 0.32035| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:45, 188.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 65| NDCG@10: 0.32035| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:53, 180.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 70| NDCG@10: 0.32036| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:53, 181.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 75| NDCG@10: 0.32034| HIT@10: 0.21039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:52, 181.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 80| NDCG@10: 0.32036| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:56, 178.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 85| NDCG@10: 0.32037| HIT@10: 0.21044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:58, 175.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 90| NDCG@10: 0.32036| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [03:02, 172.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 95| NDCG@10: 0.32036| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:59, 174.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 100| NDCG@10: 0.32037| HIT@10: 0.21043\n"
     ]
    }
   ],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "        model1 = model1,\n",
    "        model2 = model2,\n",
    "        model3 = model3,\n",
    "        model4 = model4,\n",
    "        RecVAE = model5,\n",
    "        X = X.todense(),\n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid, \n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:33, 204.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.31989| HIT@10: 0.20949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:33, 203.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 15| NDCG@10: 0.32088| HIT@10: 0.21066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:34, 203.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 20| NDCG@10: 0.32105| HIT@10: 0.21084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:35, 202.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 25| NDCG@10: 0.32116| HIT@10: 0.21093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:36, 200.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.32117| HIT@10: 0.21099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:36, 199.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 35| NDCG@10: 0.32121| HIT@10: 0.21105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:37, 198.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 40| NDCG@10: 0.32112| HIT@10: 0.21095\n"
     ]
    }
   ],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "        model1 = model1,\n",
    "        model2 = model2,\n",
    "        model3 = model3,\n",
    "        model4 = model4,\n",
    "        RecVAE = model5,\n",
    "        X = X.todense(),\n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid, \n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_ensemble_df(model1, model2, model3, model4, RecVAE, X, candidate_cnt):\n",
    "    weighted_ensemble_df = {}\n",
    "    \n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = model3.pred.cpu()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = model4.pred.cpu()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5))):\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li\n",
    "\n",
    "        weighted_ensemble_df[user] = movie_df\n",
    "\n",
    "    return weighted_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [01:48, 289.47it/s]\n"
     ]
    }
   ],
   "source": [
    "weighted_ensemble_df = get_weighted_ensemble_df(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    model3 = model3, \n",
    "    model4 = model4, \n",
    "    RecVAE = model5, \n",
    "    X = X.todense(),\n",
    "    candidate_cnt = 10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [02:09<40:56, 129.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 1.0]| NDCG@10: 0.31945| HIT@10: 0.20952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [04:16<38:24, 128.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 0.95]| NDCG@10: 0.31928| HIT@10: 0.20942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [06:24<36:15, 127.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 0.9]| NDCG@10: 0.31908| HIT@10: 0.20929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [08:31<34:01, 127.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 0.85]| NDCG@10: 0.31873| HIT@10: 0.20901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [10:38<31:52, 127.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 0.8]| NDCG@10: 0.31839| HIT@10: 0.20870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [10:45<32:15, 129.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=26'>27</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39mtotal_score\u001b[39m\u001b[39m'\u001b[39m, ascending \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=27'>28</a>\u001b[0m     up \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mtolist()[:\u001b[39m10\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=29'>30</a>\u001b[0m     NDCG \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m get_ndcg(pred_list \u001b[39m=\u001b[39;49m up, true_list \u001b[39m=\u001b[39;49m uv)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=30'>31</a>\u001b[0m     HIT \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m get_hit(pred_list \u001b[39m=\u001b[39m up, true_list \u001b[39m=\u001b[39m uv)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=32'>33</a>\u001b[0m NDCG \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(users)\n",
      "\u001b[1;32m/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb Cell 16'\u001b[0m in \u001b[0;36mget_ndcg\u001b[0;34m(pred_list, true_list)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000015vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_ndcg\u001b[39m(pred_list, true_list):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000015vscode-remote?line=1'>2</a>\u001b[0m     idcg \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m((\u001b[39m1\u001b[39;49m \u001b[39m/\u001b[39;49m np\u001b[39m.\u001b[39;49mlog2(rank \u001b[39m+\u001b[39;49m \u001b[39m2\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m rank \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(pred_list))))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000015vscode-remote?line=2'>3</a>\u001b[0m     dcg \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000015vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m rank, pred \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pred_list):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target_cols = ['rec5_score']\n",
    "weightes_list = [np.round(0.05 * i, 2) for i in range(20, 0, -1)]\n",
    "cols = ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score']\n",
    "weightes = [1.0, 0.8, 0.9, 1.0]\n",
    "users = weighted_ensemble_df.keys()\n",
    "for target_col in target_cols:\n",
    "    cols += [target_col]\n",
    "    best_hit = 0\n",
    "    best_weightes = deepcopy(weightes)\n",
    "\n",
    "    for target_weighte in tqdm(weightes_list):\n",
    "        _weightes = deepcopy(weightes)\n",
    "        _weightes += [target_weighte]\n",
    "\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "\n",
    "            for c, w in zip(cols, _weightes):\n",
    "                df[c] = df[c] * w\n",
    "            \n",
    "            df = df.fillna(df[cols].min().min())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = False)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        if best_hit < HIT:\n",
    "            best_weightes = deepcopy(_weightes)\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "        print(f'cols : {cols}| weighte : {_weightes}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "    weightes = deepcopy(best_weightes)\n",
    "    print(f'BEST cols : {cols}| weighte : {weightes}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f} \\n')\n",
    "\n",
    "print(f'cols : {cols}| weighte : {weightes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X_test, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X_test.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = AdmmSlim(lambda_2 = 1, rho = 1000)\n",
    "model3.fit(X = X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = HOSLIM(threshold = 3500, lambdaBB = 500, lambdaCC = 10000, rho = 100000)\n",
    "model4.fit(X = X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:36, 200.20it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    model3 = model3, \n",
    "    model4 = model4, \n",
    "    RecVAE = model5, \n",
    "    X = X_test.todense(),\n",
    "    candidate_cnt = 35,)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>27660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11  40815\n",
       "2           11   4886\n",
       "3           11   8961\n",
       "4           11   7373\n",
       "...        ...    ...\n",
       "313595  138493  27660\n",
       "313596  138493    110\n",
       "313597  138493  53125\n",
       "313598  138493   8970\n",
       "313599  138493   1022\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nws4JO2_rgQP"
   },
   "outputs": [],
   "source": [
    "# def evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     NDCG = 0.0 # NDCG@10\n",
    "#     HIT = 0.0 # HIT@10\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "#     score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         # ranking\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[rec1, 'rec1_score'] = score_li * 1.0\n",
    "#         movie_df.loc[rec2, 'rec2_score'] = score_li * 0.4\n",
    "#         movie_df.loc[rec3, 'rec3_score'] = score_li * 0.6\n",
    "#         movie_df.loc[rec4, 'rec4_score'] = score_li * 0.1\n",
    "#         movie_df.loc[rec5, 'rec5_score'] = score_li * 0.3\n",
    "#         movie_df.loc[rec6, 'rec6_score'] = score_li * 0.2\n",
    "#         movie_df = movie_df.fillna(min(score_li) * 0.1)\n",
    "#         movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score'] + movie_df['rec6_score']\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "#         HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "#     NDCG /= len(user_train)\n",
    "#     HIT /= len(user_train)\n",
    "\n",
    "#     return NDCG, HIT\n",
    "\n",
    "# def predict(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, candidate_cnt):\n",
    "#     user2rec = {}\n",
    "\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "#     score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "        \n",
    "#         # ranking\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[rec1, 'rec1_score'] = score_li * 1.0\n",
    "#         movie_df.loc[rec2, 'rec2_score'] = score_li * 0.4\n",
    "#         movie_df.loc[rec3, 'rec3_score'] = score_li * 0.6\n",
    "#         movie_df.loc[rec4, 'rec4_score'] = score_li * 0.1\n",
    "#         movie_df.loc[rec5, 'rec5_score'] = score_li * 0.3\n",
    "#         movie_df.loc[rec6, 'rec6_score'] = score_li * 0.2\n",
    "#         movie_df = movie_df.fillna(min(score_li) * 0.1)\n",
    "#         movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score'] + movie_df['rec6_score']\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         user2rec[user] = up\n",
    "\n",
    "#     return user2rec\n",
    "\n",
    "\n",
    "# def total_evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     df = []\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         # ranking\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         rec123456 = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "#         df.append(\n",
    "#             {\n",
    "#                'user' : user,\n",
    "#                'len' : len(rec123456),\n",
    "\n",
    "#                'rec1' : get_hit(pred_list = rec1, true_list = uv),\n",
    "#                'rec2' : get_hit(pred_list = rec2, true_list = uv),\n",
    "#                'rec3' : get_hit(pred_list = rec3, true_list = uv),\n",
    "#                'rec4' : get_hit(pred_list = rec4, true_list = uv),\n",
    "#                'rec5' : get_hit(pred_list = rec5, true_list = uv),\n",
    "#                'rec6' : get_hit(pred_list = rec6, true_list = uv),\n",
    "\n",
    "#                'rec123456' : get_hit(pred_list = rec123456, true_list = uv),\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# def evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X_df, y_df, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     NDCG = 0.0 # NDCG@10\n",
    "#     HIT = 0.0 # HIT@10\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     copy_recon_mat1 = deepcopy(recon_mat1.sigmoid())\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     copy_recon_mat2 = deepcopy(recon_mat2.sigmoid())\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     copy_recon_mat3 = deepcopy(recon_mat3.sigmoid())\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     copy_recon_mat4 = deepcopy(recon_mat4.sigmoid())\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     copy_recon_mat5 = deepcopy(recon_mat5.sigmoid())\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     copy_recon_mat6 = deepcopy(recon_mat6.sigmoid())\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "\n",
    "#         cif = DecisionTreeClassifier(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "#         score_li = np.array([[copy_recon_mat1.numpy()[user][item], copy_recon_mat2.numpy()[user][item], copy_recon_mat3.numpy()[user][item] , copy_recon_mat4.numpy()[user][item] , copy_recon_mat5.numpy()[user][item] , copy_recon_mat6.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "#         HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "#     NDCG /= len(user_train)\n",
    "#     HIT /= len(user_train)\n",
    "\n",
    "#     return NDCG, HIT\n",
    "\n",
    "\n",
    "# def predict(model1, model2, RecVAE, X_df, y_df, X, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "\n",
    "#     user2rec = {}\n",
    "\n",
    "#     neg = torch.from_numpy(1 - X)\n",
    "#     pos = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     score1 = recon_mat1 * neg\n",
    "#     rec_list1 = score1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     score2 = recon_mat2 * neg\n",
    "#     rec_list2 = score2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(pos.to(device), calculate_loss = False).cpu().detach()\n",
    "#     score3 = recon_mat3 * neg\n",
    "#     rec_list3 = score3.argsort(dim = 1)\n",
    "\n",
    "#     for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "\n",
    "#         cif = LogisticRegression(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3))\n",
    "#         score_li = np.array([[recon_mat1.numpy()[user][item], recon_mat2.numpy()[user][item], recon_mat3.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "        \n",
    "#         user2rec[user] = up\n",
    "\n",
    "#     return user2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "model4.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = MultiDAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = MultiVAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model6.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_ensemble_df(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, candidate_cnt):\n",
    "    weighted_ensemble_df = {}\n",
    "    \n",
    "    RecVAE.eval()\n",
    "    AutoRec.eval()\n",
    "    MultiDAE.eval()\n",
    "    MultiVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "    recon_mat6 = recon_mat6.cpu().detach()\n",
    "    recon_mat6[mat == 1] = -np.inf\n",
    "    rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li\n",
    "        movie_df.loc[rec6, 'rec6_score'] = score_li\n",
    "\n",
    "        weighted_ensemble_df[user] = movie_df\n",
    "\n",
    "    return weighted_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:11, 237.93it/s]\n"
     ]
    }
   ],
   "source": [
    "weighted_ensemble_df = get_weighted_ensemble_df(\n",
    "    model1 = model1,\n",
    "    model2 = model2,\n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4,\n",
    "    MultiDAE = model5,\n",
    "    MultiVAE = model6,\n",
    "    X = X.todense(),\n",
    "    candidate_cnt = 30,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['rec5_score']\n",
    "weightes_list = [np.round(0.05 * i, 2) for i in range(6, 0, -1)]\n",
    "cols = ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']\n",
    "weightes = [1.0, 0.45, 0.85, 0.25]\n",
    "users = weighted_ensemble_df.keys()\n",
    "for target_col in target_cols:\n",
    "    cols += [target_col]\n",
    "    best_hit = 0\n",
    "    best_weightes = deepcopy(weightes)\n",
    "\n",
    "    for target_weighte in tqdm(weightes_list):\n",
    "        _weightes = deepcopy(weightes)\n",
    "        _weightes += [target_weighte]\n",
    "\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "\n",
    "            for c, w in zip(cols, _weightes):\n",
    "                df[c] = df[c] * w\n",
    "            \n",
    "            df = df.fillna(df[cols].min().min())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = False)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        if best_hit < HIT:\n",
    "            best_weightes = deepcopy(_weightes)\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "        print(f'cols : {cols}| weighte : {_weightes}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "    weightes = deepcopy(best_weightes)\n",
    "    print(f'BEST cols : {cols}| weighte : {weightes}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f} \\n')\n",
    "\n",
    "print(f'cols : {cols}| weighte : {weightes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 1.0]| NDCG@10: 0.31060| HIT@10: 0.20423\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.95]| NDCG@10: 0.31082| HIT@10: 0.20423\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.9]| NDCG@10: 0.31086| HIT@10: 0.20416\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.85]| NDCG@10: 0.31099| HIT@10: 0.20427\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.8]| NDCG@10: 0.31102| HIT@10: 0.20427\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.75]| NDCG@10: 0.31105| HIT@10: 0.20429\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.7]| NDCG@10: 0.31112| HIT@10: 0.20438\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.65]| NDCG@10: 0.31119| HIT@10: 0.20445\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.6]| NDCG@10: 0.31103| HIT@10: 0.20430\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.55]| NDCG@10: 0.31109| HIT@10: 0.20425\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.5]| NDCG@10: 0.31124| HIT@10: 0.20434\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.45]| NDCG@10: 0.31135| HIT@10: 0.20441\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.4]| NDCG@10: 0.31130| HIT@10: 0.20438\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.35]| NDCG@10: 0.31131| HIT@10: 0.20437\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.3]| NDCG@10: 0.31121| HIT@10: 0.20433\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.25]| NDCG@10: 0.31123| HIT@10: 0.20437\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.2]| NDCG@10: 0.31117| HIT@10: 0.20435\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.15]| NDCG@10: 0.31094| HIT@10: 0.20416\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.1]| NDCG@10: 0.31076| HIT@10: 0.20401\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.05]| NDCG@10: 0.31059| HIT@10: 0.20387\n",
    "BEST cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.65]| NDCG@10: 0.31119| HIT@10: 0.20445\n",
    "BEST cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.45]| NDCG@10: 0.31135| HIT@10: 0.20441\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 1.0]| NDCG@10: 0.31727| HIT@10: 0.20922\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.95]| NDCG@10: 0.31758| HIT@10: 0.20937\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.9]| NDCG@10: 0.31786| HIT@10: 0.20948\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.85]| NDCG@10: 0.31807| HIT@10: 0.20968\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.8]| NDCG@10: 0.31808| HIT@10: 0.20967\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.75]| NDCG@10: 0.31800| HIT@10: 0.20960\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.7]| NDCG@10: 0.31790| HIT@10: 0.20943\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 1.0]| NDCG@10: 0.31444| HIT@10: 0.20739\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.95]| NDCG@10: 0.31503| HIT@10: 0.20768\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.9]| NDCG@10: 0.31536| HIT@10: 0.20784\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.85]| NDCG@10: 0.31568| HIT@10: 0.20799\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.8]| NDCG@10: 0.31625| HIT@10: 0.20818\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.75]| NDCG@10: 0.31661| HIT@10: 0.20837\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.7]| NDCG@10: 0.31705| HIT@10: 0.20858\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.65]| NDCG@10: 0.31733| HIT@10: 0.20866\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.6]| NDCG@10: 0.31769| HIT@10: 0.20884\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.55]| NDCG@10: 0.31801| HIT@10: 0.20918\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.5]| NDCG@10: 0.31837| HIT@10: 0.20943\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.45]| NDCG@10: 0.31860| HIT@10: 0.20962\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.4]| NDCG@10: 0.31874| HIT@10: 0.20975\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.35]| NDCG@10: 0.31895| HIT@10: 0.20997\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.3]| NDCG@10: 0.31918| HIT@10: 0.21020\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.25]| NDCG@10: 0.31922| HIT@10: 0.21031\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.2]| NDCG@10: 0.31918| HIT@10: 0.21026\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.15]| NDCG@10: 0.31910| HIT@10: 0.21023\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.1]| NDCG@10: 0.31883| HIT@10: 0.21006\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.05]| NDCG@10: 0.31852| HIT@10: 0.20981\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.25]| NDCG@10: 0.31922| HIT@10: 0.21031 \n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 1.0]| NDCG@10: 0.31214| HIT@10: 0.20505\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.95]| NDCG@10: 0.31263| HIT@10: 0.20535\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.9]| NDCG@10: 0.31307| HIT@10: 0.20561\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.85]| NDCG@10: 0.31359| HIT@10: 0.20593\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.8]| NDCG@10: 0.31416| HIT@10: 0.20633\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.75]| NDCG@10: 0.31459| HIT@10: 0.20653\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.7]| NDCG@10: 0.31515| HIT@10: 0.20689\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.65]| NDCG@10: 0.31555| HIT@10: 0.20718\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.6]| NDCG@10: 0.31596| HIT@10: 0.20744\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.55]| NDCG@10: 0.31644| HIT@10: 0.20779\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.5]| NDCG@10: 0.31685| HIT@10: 0.20804\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.45]| NDCG@10: 0.31724| HIT@10: 0.20838\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.4]| NDCG@10: 0.31755| HIT@10: 0.20857\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.35]| NDCG@10: 0.31794| HIT@10: 0.20890\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.3]| NDCG@10: 0.31841| HIT@10: 0.20929\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.25]| NDCG@10: 0.31871| HIT@10: 0.20968\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.2]| NDCG@10: 0.31887| HIT@10: 0.20982\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.15]| NDCG@10: 0.31908| HIT@10: 0.20995\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.1]| NDCG@10: 0.31922| HIT@10: 0.21012\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05]| NDCG@10: 0.31937| HIT@10: 0.21024\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05]| NDCG@10: 0.31937| HIT@10: 0.21024 \n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 1.0]| NDCG@10: 0.31592| HIT@10: 0.20776\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.95]| NDCG@10: 0.31633| HIT@10: 0.20791\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.9]| NDCG@10: 0.31676| HIT@10: 0.20817\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.85]| NDCG@10: 0.31703| HIT@10: 0.20831\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.8]| NDCG@10: 0.31741| HIT@10: 0.20852\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.75]| NDCG@10: 0.31757| HIT@10: 0.20862\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.7]| NDCG@10: 0.31794| HIT@10: 0.20886\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.65]| NDCG@10: 0.31836| HIT@10: 0.20919\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.6]| NDCG@10: 0.31866| HIT@10: 0.20938\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.55]| NDCG@10: 0.31895| HIT@10: 0.20964\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.5]| NDCG@10: 0.31923| HIT@10: 0.20987\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.45]| NDCG@10: 0.31925| HIT@10: 0.20986\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.4]| NDCG@10: 0.31953| HIT@10: 0.21014\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.35]| NDCG@10: 0.31970| HIT@10: 0.21031\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.3]| NDCG@10: 0.31977| HIT@10: 0.21032\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.25]| NDCG@10: 0.31984| HIT@10: 0.21032\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.2]| NDCG@10: 0.31984| HIT@10: 0.21028\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 1.0, 0.1, 0.3, 0.2]| NDCG@10: 0.31908| HIT@10: 0.21014\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.9, 0.1, 0.3, 0.2]| NDCG@10: 0.31957| HIT@10: 0.21027\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.2]| NDCG@10: 0.31995| HIT@10: 0.21040\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.7, 0.1, 0.3, 0.2]| NDCG@10: 0.31992| HIT@10: 0.21022\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.6, 0.1, 0.3, 0.2]| NDCG@10: 0.32010| HIT@10: 0.21036\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.5, 0.1, 0.3, 0.2]| NDCG@10: 0.31996| HIT@10: 0.21033\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.4, 0.1, 0.3, 0.2]| NDCG@10: 0.31992| HIT@10: 0.21044\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.3, 0.1, 0.3, 0.2]| NDCG@10: 0.31947| HIT@10: 0.21024\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.2, 0.1, 0.3, 0.2]| NDCG@10: 0.31892| HIT@10: 0.20997\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.1, 0.1, 0.3, 0.2]| NDCG@10: 0.31806| HIT@10: 0.20938\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.4, 0.1, 0.3, 0.2]| NDCG@10: 0.31992| HIT@10: 0.21044\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 1.0]| NDCG@10: 0.31060| HIT@10: 0.20423\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.9]| NDCG@10: 0.31086| HIT@10: 0.20416\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.8]| NDCG@10: 0.31102| HIT@10: 0.20427\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.7]| NDCG@10: 0.31112| HIT@10: 0.20438\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.6]| NDCG@10: 0.31103| HIT@10: 0.20430\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.5]| NDCG@10: 0.31124| HIT@10: 0.20434\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.4]| NDCG@10: 0.31130| HIT@10: 0.20438\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.3]| NDCG@10: 0.31121| HIT@10: 0.20433\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.2]| NDCG@10: 0.31117| HIT@10: 0.20435\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.1]| NDCG@10: 0.31076| HIT@10: 0.20401\n",
    "BEST cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.4]| NDCG@10: 0.31130| HIT@10: 0.20438\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 1.0]| NDCG@10: 0.31716| HIT@10: 0.20921\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.9]| NDCG@10: 0.31770| HIT@10: 0.20940\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.8]| NDCG@10: 0.31789| HIT@10: 0.20956\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.7]| NDCG@10: 0.31788| HIT@10: 0.20950\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.6]| NDCG@10: 0.31790| HIT@10: 0.20939\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.5]| NDCG@10: 0.31738| HIT@10: 0.20897\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.4]| NDCG@10: 0.31655| HIT@10: 0.20827\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.3]| NDCG@10: 0.31571| HIT@10: 0.20768\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.2]| NDCG@10: 0.31464| HIT@10: 0.20701\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.1]| NDCG@10: 0.31317| HIT@10: 0.20593\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.8]| NDCG@10: 0.31789| HIT@10: 0.20956\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 1.0]| NDCG@10: 0.31056| HIT@10: 0.20408\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.9]| NDCG@10: 0.31171| HIT@10: 0.20482\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.8]| NDCG@10: 0.31265| HIT@10: 0.20543\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.7]| NDCG@10: 0.31363| HIT@10: 0.20602\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.6]| NDCG@10: 0.31465| HIT@10: 0.20672\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.5]| NDCG@10: 0.31570| HIT@10: 0.20752\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.4]| NDCG@10: 0.31650| HIT@10: 0.20812\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.3]| NDCG@10: 0.31727| HIT@10: 0.20872\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.2]| NDCG@10: 0.31779| HIT@10: 0.20912\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.1]| NDCG@10: 0.31793| HIT@10: 0.20937\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.1]| NDCG@10: 0.31793| HIT@10: 0.20937\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 1.0]| NDCG@10: 0.31535| HIT@10: 0.20741\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.9]| NDCG@10: 0.31616| HIT@10: 0.20772\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.8]| NDCG@10: 0.31695| HIT@10: 0.20824\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.7]| NDCG@10: 0.31779| HIT@10: 0.20880\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.6]| NDCG@10: 0.31865| HIT@10: 0.20948\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.5]| NDCG@10: 0.31901| HIT@10: 0.20959\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.4]| NDCG@10: 0.31922| HIT@10: 0.20979\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3]| NDCG@10: 0.31934| HIT@10: 0.21005\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.2]| NDCG@10: 0.31904| HIT@10: 0.20992\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.1]| NDCG@10: 0.31868| HIT@10: 0.20984\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3]| NDCG@10: 0.31934| HIT@10: 0.21005\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 1.0]| NDCG@10: 0.31550| HIT@10: 0.20783\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.9]| NDCG@10: 0.31628| HIT@10: 0.20822\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.8]| NDCG@10: 0.31712| HIT@10: 0.20865\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.7]| NDCG@10: 0.31775| HIT@10: 0.20901\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.6]| NDCG@10: 0.31852| HIT@10: 0.20945\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.5]| NDCG@10: 0.31896| HIT@10: 0.20970\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.4]| NDCG@10: 0.31941| HIT@10: 0.20996\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.3]| NDCG@10: 0.31973| HIT@10: 0.21019\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.2]| NDCG@10: 0.31995| HIT@10: 0.21040\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.1]| NDCG@10: 0.31965| HIT@10: 0.21022\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.2]| NDCG@10: 0.31995| HIT@10: 0.21040\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_evaluate(\n",
    "    model1 = model1,\n",
    "    model2 = model2,\n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4,\n",
    "    MultiDAE = model5,\n",
    "    MultiVAE = model6,\n",
    "    X = X.todense(),\n",
    "    user_train = user_train,\n",
    "    user_valid = user_valid,\n",
    "    candidate_cnt = 10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>len</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec6</th>\n",
       "      <th>rec123456</th>\n",
       "      <th>total_val</th>\n",
       "      <th>total_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>31355</td>\n",
       "      <td>17</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>31356</td>\n",
       "      <td>26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>31357</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>31358</td>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>31359</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  len  rec1  rec2  rec3  rec4  rec5  rec6  rec123456  total_val  \\\n",
       "0          0   27   0.3   0.3   0.2   0.2   0.2   0.2        0.5        0.3   \n",
       "1          1   23   0.1   0.1   0.2   0.1   0.1   0.1        0.2        0.2   \n",
       "2          2   22   0.3   0.3   0.3   0.3   0.2   0.1        0.3        0.3   \n",
       "3          3   19   0.3   0.3   0.2   0.2   0.2   0.2        0.4        0.3   \n",
       "4          4   23   0.4   0.3   0.4   0.3   0.5   0.4        0.5        0.5   \n",
       "...      ...  ...   ...   ...   ...   ...   ...   ...        ...        ...   \n",
       "31355  31355   17   0.2   0.4   0.2   0.2   0.2   0.2        0.4        0.4   \n",
       "31356  31356   26   0.3   0.3   0.3   0.2   0.5   0.0        0.5        0.5   \n",
       "31357  31357   21   0.2   0.3   0.2   0.1   0.1   0.1        0.3        0.3   \n",
       "31358  31358   23   0.1   0.1   0.0   0.0   0.0   0.0        0.1        0.1   \n",
       "31359  31359   35   0.0   0.2   0.1   0.0   0.1   0.0        0.2        0.2   \n",
       "\n",
       "      total_name  \n",
       "0           rec1  \n",
       "1           rec3  \n",
       "2           rec1  \n",
       "3           rec1  \n",
       "4           rec5  \n",
       "...          ...  \n",
       "31355       rec2  \n",
       "31356       rec5  \n",
       "31357       rec2  \n",
       "31358       rec1  \n",
       "31359       rec2  \n",
       "\n",
       "[31360 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저들 마다 rec1 or rec2 or rec3 or ranking 등 맞는 방법에 따라사 추천을 해주는 것도 좋은 방법이 될 수 있음\n",
    "\n",
    "new_df = pd.DataFrame(df)\n",
    "\n",
    "def get_total_name(x):\n",
    "    val_list = [x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5'] , x['rec6']]\n",
    "    max_val = max(val_list)\n",
    "    val_idx = val_list.index(max_val)\n",
    "    if val_idx == 0 : return 'rec1'\n",
    "    elif val_idx == 1 : return 'rec2'\n",
    "    elif val_idx == 2 : return 'rec3'\n",
    "    elif val_idx == 3 : return 'rec4'\n",
    "    elif val_idx == 4 : return 'rec5'\n",
    "    elif val_idx == 5 : return 'rec6'\n",
    "\n",
    "new_df['total_val'] = new_df.apply(lambda x: max(x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5'] , x['rec6']), axis = 1)\n",
    "new_df['total_name'] = new_df.apply(lambda x: get_total_name(x), axis = 1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.histplot(data = new_df[[\"rec1\", \"rec2\", \"rec3\", \"rec4\", \"rec5\", \"rec6\", 'rec123456', 'total_val']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec1    16391\n",
       "rec3     4737\n",
       "rec2     3913\n",
       "rec5     2433\n",
       "rec4     2162\n",
       "rec6     1724\n",
       "Name: total_name, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['total_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         15679.500000\n",
       "len             24.823884\n",
       "rec1             0.203839\n",
       "rec2             0.200207\n",
       "rec3             0.192140\n",
       "rec4             0.174758\n",
       "rec5             0.172388\n",
       "rec6             0.174767\n",
       "rec123456        0.313935\n",
       "total_val        0.263115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = np.concatenate([np.repeat(i, 6807) for i in range(31360)])\n",
    "\n",
    "# model1_score = model1.pred.sigmoid().cpu().numpy().reshape(-1)\n",
    "\n",
    "# model2_score = model2.pred.T.sigmoid().cpu().numpy().reshape(-1)\n",
    "\n",
    "# model3_score = model3(torch.from_numpy(X.todense()).to(device), calculate_loss = False).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model4_score = model4(torch.from_numpy(X.todense()).to(device)).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model5_score = model5(torch.from_numpy(X.todense()).to(device)).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model6_score, _, _ = model6(torch.from_numpy(X.todense()).to(device))\n",
    "# model6_score = model6_score.sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# X_df = np.concatenate([\n",
    "#     users.reshape(-1, 1), \n",
    "#     model1_score.reshape(-1, 1), \n",
    "#     model2_score.reshape(-1, 1), \n",
    "#     model3_score.reshape(-1, 1), \n",
    "#     model4_score.reshape(-1, 1), \n",
    "#     model5_score.reshape(-1, 1),\n",
    "#     model6_score.reshape(-1, 1)], axis = 1)\n",
    "\n",
    "# y_df = X.toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre = pd.read_csv(os.path.join(config.data_path, 'genres.tsv'), sep='\\t')\n",
    "# genre['genres'] = 1\n",
    "# genre['item_idx'] = genre['item'].apply(lambda x : make_matrix_data_set.item_encoder[x])\n",
    "# genre = pd.pivot_table(genre, values='genres', index=['item_idx'], columns=['genre'], aggfunc=np.sum, fill_value=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [16:22, 31.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.17573| HIT@10: 0.13605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# candidate_cnt = 10\n",
    "\n",
    "# ndcg, hit = evaluate(\n",
    "#             model1 = model1, \n",
    "#             model2 = model2, \n",
    "#             RecVAE = model3,\n",
    "#             AutoRec = model4,\n",
    "#             MultiDAE = model5,\n",
    "#             MultiVAE = model6,\n",
    "#             X_df = X_df, \n",
    "#             y_df = y_df,\n",
    "#             X = X.todense(),\n",
    "#             user_train = user_train, \n",
    "#             user_valid = user_valid, \n",
    "#             candidate_cnt = candidate_cnt)\n",
    "\n",
    "# print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for candidate_cnt in [5 * i for i in range(3, 21)]:\n",
    "#     ndcg, hit = evaluate(\n",
    "#             model1 = model1, \n",
    "#             model2 = model2, \n",
    "#             RecVAE = model3,\n",
    "#             X_df = X_df,\n",
    "#             y_df = y_df,\n",
    "#             X = X.todense(),\n",
    "#             user_train = user_train, \n",
    "#             user_valid = user_valid, \n",
    "#             candidate_cnt = candidate_cnt)\n",
    "\n",
    "#     print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:56, 177.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.32010| HIT@10: 0.21036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 30\n",
    "\n",
    "ndcg, hit = evaluate(\n",
    "            model1 = model1, \n",
    "            model2 = model2, \n",
    "            RecVAE = model3,\n",
    "            AutoRec = model4,\n",
    "            MultiDAE = model5,\n",
    "            MultiVAE = model6,\n",
    "            X = X.todense(),\n",
    "            user_train = user_train, \n",
    "            user_valid = user_valid, \n",
    "            candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "NDCG@10: 0.32010| HIT@10: 0.21036\n",
    "NDCG@10: 0.31992| HIT@10: 0.21044\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "                model1 = model1,\n",
    "                model2 = model2, \n",
    "                RecVAE = model3,\n",
    "                AutoRec = model4,\n",
    "                MultiDAE = model5,\n",
    "                MultiVAE = model6,\n",
    "                X = X.todense(),\n",
    "                user_train = user_train, \n",
    "                user_valid = user_valid, \n",
    "                candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델+ log2(rank + 1) + weighted Ensemble [1.0, 0.4, 0.4, 0.1, 0.3, 0.2]\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31722| HIT@10: 0.20723\n",
    "candidate_cnt: 15| NDCG@10: 0.31909| HIT@10: 0.20935\n",
    "candidate_cnt: 20| NDCG@10: 0.31977| HIT@10: 0.21020\n",
    "candidate_cnt: 25| NDCG@10: 0.31992| HIT@10: 0.21041\n",
    "candidate_cnt: 30| NDCG@10: 0.31992| HIT@10: 0.21044\n",
    "candidate_cnt: 35| NDCG@10: 0.31977| HIT@10: 0.21030\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델+ log2(rank + 1) + weighted Ensemble (0.25, 0.25, 0.2, 0.1, 0.1, 0.1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31753| HIT@10: 0.20782\n",
    "candidate_cnt: 15| NDCG@10: 0.31839| HIT@10: 0.20871\n",
    "candidate_cnt: 20| NDCG@10: 0.31884| HIT@10: 0.20924\n",
    "candidate_cnt: 25| NDCG@10: 0.31889| HIT@10: 0.20930\n",
    "candidate_cnt: 30| NDCG@10: 0.31911| HIT@10: 0.20956\n",
    "candidate_cnt: 35| NDCG@10: 0.31907| HIT@10: 0.20955\n",
    "candidate_cnt: 40| NDCG@10: 0.31901| HIT@10: 0.20949\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델 + voting\n",
    "candidate_cnt: 10| NDCG@10: 0.29867| HIT@10: 0.20497\n",
    "candidate_cnt: 15| NDCG@10: 0.28563| HIT@10: 0.20339\n",
    "candidate_cnt: 20| NDCG@10: 0.27253| HIT@10: 0.19996\n",
    "candidate_cnt: 25| NDCG@10: 0.25738| HIT@10: 0.19344\n",
    "candidate_cnt: 30| NDCG@10: 0.24171| HIT@10: 0.18377\n",
    "candidate_cnt: 35| NDCG@10: 0.22492| HIT@10: 0.17286\n",
    "candidate_cnt: 40| NDCG@10: 0.20953| HIT@10: 0.16214\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델 + log2(rank + 1)\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.30926| HIT@10: 0.20194\n",
    "candidate_cnt: 15| NDCG@10: 0.31167| HIT@10: 0.20401\n",
    "candidate_cnt: 20| NDCG@10: 0.31282| HIT@10: 0.20501\n",
    "candidate_cnt: 25| NDCG@10: 0.31330| HIT@10: 0.20542\n",
    "candidate_cnt: 30| NDCG@10: 0.31366| HIT@10: 0.20572\n",
    "candidate_cnt: 35| NDCG@10: 0.31382| HIT@10: 0.20584\n",
    "candidate_cnt: 40| NDCG@10: 0.31397| HIT@10: 0.20594\n",
    "candidate_cnt: 45| NDCG@10: 0.31408| HIT@10: 0.20603\n",
    "candidate_cnt: 50| NDCG@10: 0.31416| HIT@10: 0.20611\n",
    "candidate_cnt: 55| NDCG@10: 0.31422| HIT@10: 0.20613\n",
    "candidate_cnt: 60| NDCG@10: 0.31427| HIT@10: 0.20618\n",
    "candidate_cnt: 65| NDCG@10: 0.31430| HIT@10: 0.20620\n",
    "candidate_cnt: 70| NDCG@10: 0.31435| HIT@10: 0.20623\n",
    "candidate_cnt: 75| NDCG@10: 0.31435| HIT@10: 0.20624\n",
    "candidate_cnt: 80| NDCG@10: 0.31438| HIT@10: 0.20627\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "EASE2개 + RecVAE-v3 + log2(rank + 1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31412| HIT@10: 0.20595\n",
    "candidate_cnt: 15| NDCG@10: 0.31573| HIT@10: 0.20745\n",
    "candidate_cnt: 20| NDCG@10: 0.31644| HIT@10: 0.20807\n",
    "candidate_cnt: 25| NDCG@10: 0.31687| HIT@10: 0.20851\n",
    "candidate_cnt: 30| NDCG@10: 0.31696| HIT@10: 0.20863\n",
    "candidate_cnt: 35| NDCG@10: 0.31708| HIT@10: 0.20872\n",
    "candidate_cnt: 40| NDCG@10: 0.31712| HIT@10: 0.20878\n",
    "candidate_cnt: 45| NDCG@10: 0.31717| HIT@10: 0.20882\n",
    "candidate_cnt: 50| NDCG@10: 0.31723| HIT@10: 0.20886\n",
    "candidate_cnt: 55| NDCG@10: 0.31723| HIT@10: 0.20884\n",
    "candidate_cnt: 60| NDCG@10: 0.31726| HIT@10: 0.20887\n",
    "candidate_cnt: 65| NDCG@10: 0.31729| HIT@10: 0.20888\n",
    "candidate_cnt: 70| NDCG@10: 0.31727| HIT@10: 0.20887\n",
    "candidate_cnt: 75| NDCG@10: 0.31730| HIT@10: 0.20889\n",
    "candidate_cnt: 80| NDCG@10: 0.31730| HIT@10: 0.20890\n",
    "candidate_cnt: 85| NDCG@10: 0.31733| HIT@10: 0.20888\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "EASE2개 + RecVAE-v5 + log2(rank + 1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "candidate_cnt: 15| NDCG@10: 0.31518| HIT@10: 0.20735\n",
    "candidate_cnt: 20| NDCG@10: 0.31569| HIT@10: 0.20779\n",
    "candidate_cnt: 25| NDCG@10: 0.31605| HIT@10: 0.20812\n",
    "candidate_cnt: 30| NDCG@10: 0.31616| HIT@10: 0.20822\n",
    "candidate_cnt: 35| NDCG@10: 0.31627| HIT@10: 0.20833\n",
    "candidate_cnt: 40| NDCG@10: 0.31636| HIT@10: 0.20843\n",
    "candidate_cnt: 45| NDCG@10: 0.31643| HIT@10: 0.20846\n",
    "candidate_cnt: 50| NDCG@10: 0.31644| HIT@10: 0.20848\n",
    "candidate_cnt: 55| NDCG@10: 0.31653| HIT@10: 0.20854\n",
    "candidate_cnt: 60| NDCG@10: 0.31657| HIT@10: 0.20857\n",
    "candidate_cnt: 65| NDCG@10: 0.31652| HIT@10: 0.20856\n",
    "candidate_cnt: 70| NDCG@10: 0.31653| HIT@10: 0.20856\n",
    "candidate_cnt: 75| NDCG@10: 0.31651| HIT@10: 0.20855\n",
    "candidate_cnt: 80| NDCG@10: 0.31658| HIT@10: 0.20858\n",
    "candidate_cnt: 85| NDCG@10: 0.31660| HIT@10: 0.20859\n",
    "candidate_cnt: 90| NDCG@10: 0.31658| HIT@10: 0.20860\n",
    "candidate_cnt: 95| NDCG@10: 0.31662| HIT@10: 0.20862\n",
    "candidate_cnt: 100| NDCG@10: 0.31658| HIT@10: 0.20861\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "none + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31411| HIT@10: 0.20686\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31568| HIT@10: 0.20702\n",
    "```\n",
    "\n",
    "```\n",
    "softmax + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.28598| HIT@10: 0.19227\n",
    "```\n",
    "\n",
    "```\n",
    "none + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31381| HIT@10: 0.20633\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31469| HIT@10: 0.20636\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[147, 197, 188, 313, 228, 273, 189, 114, 42, 242]\n",
    "\n",
    "```\n",
    "non softmax\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.902873     0.411256     1.314129\n",
    "42    0.815624     0.411256     1.226880\n",
    "933   0.981398     0.172427     1.153824\n",
    "718   0.671753     0.402721     1.074474\n",
    "484   0.923667     0.149443     1.073110\n",
    "376   0.883676     0.173539     1.057215\n",
    "667   0.919388     0.097644     1.017032\n",
    "650   0.855481     0.151946     1.007427\n",
    "2200  0.878635     0.125442     1.004077\n",
    "714   0.719053     0.210817     0.929870\n",
    "1844  0.698690     0.226953     0.925643\n",
    "273   0.810516     0.097710     0.908226\n",
    "760   0.763495     0.036601     0.800096\n",
    "313   0.766302     0.027069     0.793371\n",
    "777   0.641927     0.142652     0.784579\n",
    "228   0.733693     0.044058     0.777750\n",
    "734   0.738835     0.031143     0.769978\n",
    "1354  0.438386     0.122450     0.560836\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "softmax\n",
    "\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.053804     0.411256     0.465060\n",
    "42    0.053799     0.411256     0.465055\n",
    "718   0.053844     0.402721     0.456565\n",
    "1844  0.053790     0.226953     0.280743\n",
    "714   0.053817     0.210817     0.264634\n",
    "376   0.053824     0.173539     0.227363\n",
    "933   0.053912     0.172427     0.226339\n",
    "650   0.053820     0.151946     0.205766\n",
    "484   0.053827     0.149443     0.203270\n",
    "777   0.053828     0.142652     0.196481\n",
    "2200  0.053810     0.125442     0.179252\n",
    "1354  0.053825     0.122450     0.176275\n",
    "273   0.053800     0.097710     0.151510\n",
    "667   0.053807     0.097644     0.151450\n",
    "228   0.053814     0.044058     0.097871\n",
    "760   0.053811     0.036601     0.090412\n",
    "734   0.053804     0.031143     0.084947\n",
    "313   0.053817     0.027069     0.080885\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X_test, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X_test.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "model4.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = MultiDAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = MultiVAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model6.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:56, 177.81it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    model1 = model1, \n",
    "    model2 = model2,\n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4,\n",
    "    MultiDAE = model5,\n",
    "    MultiVAE = model6,\n",
    "    X = X_test.todense(),\n",
    "    candidate_cnt = 30,)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>27660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11   4886\n",
       "2           11  40815\n",
       "3           11   8961\n",
       "4           11   7373\n",
       "...        ...    ...\n",
       "313595  138493   8970\n",
       "313596  138493  27660\n",
       "313597  138493   8961\n",
       "313598  138493    589\n",
       "313599  138493   5349\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
