{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ug-br-pPu9vZ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from box import Box\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbRKDSg4u9vc"
   },
   "source": [
    "# 1. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MEhK_fLIu9vd"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n",
    "    'model_path' : \"../model\",\n",
    "\n",
    "\n",
    "    'submission_path' : \"../submission\",\n",
    "    'submission_name' : 'Ensembel_v11_submission.csv',\n",
    "\n",
    "    'candidate_item_num' : 50,\n",
    "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
    "    'seed' : 22,\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjDxy0fJu9vf"
   },
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W64BYWl0u9vg"
   },
   "outputs": [],
   "source": [
    "class MakeMatrixDataSet():\n",
    "    \"\"\"\n",
    "    MatrixDataSet 생성\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n",
    "        \n",
    "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n",
    "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n",
    "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
    "\n",
    "        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n",
    "        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n",
    "\n",
    "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
    "\n",
    "    def generate_encoder_decoder(self, col : str) -> dict:\n",
    "        \"\"\"\n",
    "        encoder, decoder 생성\n",
    "\n",
    "        Args:\n",
    "            col (str): 생성할 columns 명\n",
    "        Returns:\n",
    "            dict: 생성된 user encoder, decoder\n",
    "        \"\"\"\n",
    "\n",
    "        encoder = {}\n",
    "        decoder = {}\n",
    "        ids = self.df[col].unique()\n",
    "\n",
    "        for idx, _id in enumerate(ids):\n",
    "            encoder[_id] = idx\n",
    "            decoder[idx] = _id\n",
    "\n",
    "        return encoder, decoder\n",
    "    \n",
    "    def generate_sequence_data(self) -> dict:\n",
    "        \"\"\"\n",
    "        sequence_data 생성\n",
    "\n",
    "        Returns:\n",
    "            dict: train user sequence / valid user sequence\n",
    "        \"\"\"\n",
    "        users = defaultdict(list)\n",
    "        user_train = {}\n",
    "        user_valid = {}\n",
    "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n",
    "            users[user].append(item)\n",
    "        \n",
    "        for user in users:\n",
    "            np.random.seed(self.config.seed)\n",
    "\n",
    "            user_total = users[user]\n",
    "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
    "            train = list(set(user_total) - set(valid))\n",
    "\n",
    "            user_train[user] = train\n",
    "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
    "\n",
    "        return user_train, user_valid\n",
    "    \n",
    "    def get_train_valid_data(self):\n",
    "        return self.user_train, self.user_valid\n",
    "\n",
    "    def make_matrix(self, user_list, train = True):\n",
    "        \"\"\"\n",
    "        user_item_dict를 바탕으로 행렬 생성\n",
    "        \"\"\"\n",
    "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
    "        for idx, user in enumerate(user_list):\n",
    "            if train:\n",
    "                mat[idx, self.user_train[user.item()]] = 1\n",
    "            else:\n",
    "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
    "        return mat\n",
    "\n",
    "    def make_sparse_matrix(self, test = False):\n",
    "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
    "        \n",
    "        for user in self.user_train.keys():\n",
    "            item_list = self.user_train[user]\n",
    "            X[user, item_list] = 1.0\n",
    "        \n",
    "        if test:\n",
    "            for user in self.user_valid.keys():\n",
    "                item_list = self.user_valid[user]\n",
    "                X[user, item_list] = 1.0\n",
    "\n",
    "        return X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IldCGmY8u9vh"
   },
   "outputs": [],
   "source": [
    "class AEDataSet(Dataset):\n",
    "    def __init__(self, num_user):\n",
    "        self.num_user = num_user\n",
    "        self.users = [i for i in range(num_user)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_user\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        user = self.users[idx]\n",
    "        return torch.LongTensor([user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysia457Su9vi"
   },
   "source": [
    "# 3. 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOSLIM():\n",
    "    def __init__(self, threshold = 3500, lambdaBB = 500, lambdaCC = 5000, rho = 100000, epochs = 40):\n",
    "        self.threshold = threshold\n",
    "        self.lambdaBB = lambdaBB\n",
    "        self.lambdaCC = lambdaCC\n",
    "        self.rho = rho\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def create_list_feature_pairs(self, XtX):\n",
    "        AA = np.triu(np.abs(XtX))\n",
    "        AA[ np.diag_indices(AA.shape[0]) ]=0.0\n",
    "        ii_pairs = np.where((AA > self.threshold) == True)\n",
    "        return ii_pairs\n",
    "    \n",
    "    def create_matrix_Z(self, ii_pairs, X):\n",
    "        MM = np.zeros( (len(ii_pairs[0]), X.shape[1]),    dtype=np.float)\n",
    "        MM[np.arange(MM.shape[0]) , ii_pairs[0]   ]=1.0\n",
    "        MM[np.arange(MM.shape[0]) , ii_pairs[1]   ]=1.0\n",
    "        CCmask = 1.0-MM\n",
    "        MM = MM.T\n",
    "        Z=  X.dot(MM)\n",
    "        Z= (Z == 2.0 )\n",
    "        Z=Z*1.0\n",
    "        return Z, CCmask\n",
    "\n",
    "    def train_higher(self, XtX, XtXdiag, ZtZ, ZtZdiag, CCmask, ZtX):\n",
    "        ii_diag=np.diag_indices(XtX.shape[0])\n",
    "        XtX[ii_diag] = XtXdiag + self.lambdaBB\n",
    "        PP = np.linalg.inv(XtX)\n",
    "        ii_diag_ZZ=np.diag_indices(ZtZ.shape[0])\n",
    "        ZtZ[ii_diag_ZZ] = ZtZdiag + self.lambdaCC + self.rho\n",
    "        QQ=np.linalg.inv(ZtZ)\n",
    "        CC = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float )\n",
    "        DD = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float )\n",
    "        UU = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float )\n",
    "\n",
    "        for iter in range(self.epochs):\n",
    "            # learn BB\n",
    "            XtX[ii_diag] = XtXdiag\n",
    "            BB= PP.dot(XtX-ZtX.T.dot(CC))\n",
    "            gamma = np.diag(BB) / np.diag(PP)\n",
    "            BB-= PP * gamma\n",
    "            # learn CC\n",
    "            CC= QQ.dot(ZtX-ZtX.dot(BB) + self.rho * (DD-UU))\n",
    "            # learn DD\n",
    "            DD=  CC  * CCmask \n",
    "            #DD= np.maximum(0.0, DD) # if you want to enforce non-negative parameters\n",
    "            # learn UU (is Gamma in paper)\n",
    "            UU+= CC-DD\n",
    "        \n",
    "        return BB, DD\n",
    "\n",
    "    def fit(self, X):\n",
    "        XtX = X.T.dot(X)\n",
    "        XtXdiag = deepcopy(np.diag(XtX))\n",
    "        ii_pairs = self.create_list_feature_pairs(XtX)\n",
    "        Z, CCmask = self.create_matrix_Z(ii_pairs, X)\n",
    "\n",
    "        ZtZ = Z.T.dot(Z)\n",
    "        ZtZdiag = deepcopy(np.diag(ZtZ))\n",
    "\n",
    "        ZtX = Z.T.dot(X)\n",
    "\n",
    "        BB, CC = self.train_higher(XtX, XtXdiag, ZtZ, ZtZdiag, CCmask, ZtX)\n",
    "\n",
    "        self.pred = torch.from_numpy(X.dot(BB) + Z.dot(CC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdmmSlim():\n",
    "    def __init__(self, lambda_1=1, lambda_2=500, rho=10000, positive=True, n_iter=50, eps_rel=1e-4, eps_abs=1e-3, verbose=False):\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.rho = rho\n",
    "        self.positive = positive\n",
    "        self.n_iter = n_iter\n",
    "        self.eps_rel = eps_rel\n",
    "        self.eps_abs = eps_abs\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def soft_thresholding(self, B, Gamma):\n",
    "        if self.lambda_1 == 0:\n",
    "            if self.positive:\n",
    "                return np.abs(B)\n",
    "            else:\n",
    "                return B\n",
    "        else:\n",
    "            x = B + Gamma / self.rho\n",
    "            threshold = self.lambda_1 / self.rho\n",
    "            if self.positive:\n",
    "                return np.where(threshold < x, x - threshold, 0)\n",
    "            else:\n",
    "                return np.where(threshold < x, x - threshold,\n",
    "                                np.where(x < - threshold, x + threshold, 0))\n",
    "\n",
    "    def is_converged(self, B, C, C_old, Gamma):\n",
    "        B_norm = np.linalg.norm(B)\n",
    "        C_norm = np.linalg.norm(C)\n",
    "        Gamma_norm = np.linalg.norm(Gamma)\n",
    "\n",
    "        eps_primal = self.eps_abs * B.shape[0] - self.eps_rel * np.max([B_norm, C_norm])\n",
    "        eps_dual = self.eps_abs * B.shape[0] - self.eps_rel * Gamma_norm\n",
    "\n",
    "        R_primal_norm = np.linalg.norm(B - C)\n",
    "        R_dual_norm = np.linalg.norm(C  - C_old) * self.rho\n",
    "\n",
    "        converged = R_primal_norm < eps_primal and R_dual_norm < eps_dual\n",
    "        return converged\n",
    "\n",
    "    def fit(self, X):\n",
    "        XtX = X.T.dot(X)\n",
    "        if sp.issparse(XtX):\n",
    "            XtX = XtX.todense().A\n",
    "\n",
    "        if self.verbose:\n",
    "            print(' --- init')\n",
    "        identity_mat = np.identity(XtX.shape[0])\n",
    "        diags = identity_mat * (self.lambda_2 + self.rho)\n",
    "        P = np.linalg.inv(XtX + diags).astype(np.float32)\n",
    "        B_aux = P.dot(XtX)\n",
    "\n",
    "        Gamma = np.zeros_like(XtX, dtype=np.float32)\n",
    "        C = np.zeros_like(XtX, dtype=np.float32)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(' --- iteration start.')\n",
    "        for iter in range(self.n_iter):\n",
    "            if self.verbose:\n",
    "                print(f' --- iteration {iter+1}/{self.n_iter}')\n",
    "            C_old = C.copy()\n",
    "            B_tilde = B_aux + P.dot(self.rho * C - Gamma)\n",
    "            gamma = np.diag(B_tilde) / (np.diag(P) + 1e-8)\n",
    "            B = B_tilde - P * gamma\n",
    "            C = self.soft_thresholding(B, Gamma)\n",
    "            Gamma = Gamma + self.rho * (B - C)\n",
    "            if self.is_converged(B, C, C_old, Gamma):\n",
    "                if self.verbose:\n",
    "                    print(f' --- Converged. Stopped iteration.')\n",
    "                break\n",
    "\n",
    "        coef = C\n",
    "\n",
    "        self.pred = torch.from_numpy(X.dot(coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, dropout_rate = 0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "\n",
    "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
    "\n",
    "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
    "\n",
    "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
    "\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.encode(input)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def encode(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                mu = h[:, :self.q_dims[-1]]\n",
    "                logvar = h[:, self.q_dims[-1]:]\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.q_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.p_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, dropout_rate = 0.5):\n",
    "        super(MultiDAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.q_dims = p_dims[::-1]\n",
    "\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num, num_factor):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num, num_factor),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_factor, num_factor // 2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_factor // 2, num_factor),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_factor, num),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, mat):\n",
    "        latent = self.encoder(mat)\n",
    "        recont_mat = self.decoder(latent)\n",
    "\n",
    "        return recont_mat\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.encoder:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                size = layer.weight.size()\n",
    "                fan_out = size[0]\n",
    "                fan_in = size[1]\n",
    "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "                layer.weight.data.normal_(0.0, std)\n",
    "                layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.decoder:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                size = layer.weight.size()\n",
    "                fan_out = size[0]\n",
    "                fan_in = size[1]\n",
    "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "                layer.weight.data.normal_(0.0, std)\n",
    "                layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE():\n",
    "    def __init__(self, X, reg):\n",
    "        self.X = self._convert_sp_mat_to_sp_tensor(X)\n",
    "        self.reg = reg\n",
    "    \n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        \"\"\"\n",
    "        Convert scipy sparse matrix to PyTorch sparse matrix\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        X = Adjacency matrix, scipy sparse matrix\n",
    "        \"\"\"\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "        v = torch.FloatTensor(coo.data)\n",
    "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "        return res\n",
    "    \n",
    "    def fit(self):\n",
    "        '''\n",
    "\n",
    "        진짜 정말 간단한 식으로 모델을 만듬\n",
    "\n",
    "        '''\n",
    "        G = self.X.to_dense().t() @ self.X.to_dense()\n",
    "        diagIndices = torch.eye(G.shape[0]) == 1\n",
    "        G[diagIndices] += self.reg\n",
    "\n",
    "        P = G.inverse()\n",
    "        B = P / (-1 * P.diag())\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.pred = self.X.to_dense() @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x.mul(torch.sigmoid(x))\n",
    "\n",
    "def log_norm_pdf(x, mu, logvar):\n",
    "    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n",
    "\n",
    "class CompositePrior(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n",
    "        super(CompositePrior, self).__init__()\n",
    "        \n",
    "        self.mixture_weights = mixture_weights\n",
    "        \n",
    "        self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.mu_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_uniform_prior.data.fill_(10)\n",
    "        \n",
    "        self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.encoder_old.requires_grad_(False)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "\n",
    "        post_mu, post_logvar = self.encoder_old(x, dropout_rate = 0)\n",
    "\n",
    "        stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n",
    "        post_prior = log_norm_pdf(z, post_mu, post_logvar)\n",
    "        unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n",
    "        \n",
    "        gaussians = [stnd_prior, post_prior, unif_prior]\n",
    "        gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n",
    "\n",
    "        density_per_gaussian = torch.stack(gaussians, dim=-1)\n",
    "\n",
    "        return torch.logsumexp(density_per_gaussian, dim=-1)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x, dropout_rate):\n",
    "        norm = x.pow(2).sum(dim=-1).sqrt()\n",
    "        x = x / norm[:, None]\n",
    "    \n",
    "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "        \n",
    "        h1 = self.ln1(swish(self.fc1(x)))\n",
    "        h2 = self.ln2(swish(self.fc2(h1) + h1))\n",
    "        h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n",
    "        h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n",
    "        h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n",
    "        return self.fc_mu(h5), self.fc_logvar(h5)\n",
    "\n",
    "\n",
    "class RecVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 600, latent_dim = 200):\n",
    "        super(RecVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n",
    "        self.decoder = nn.Linear(latent_dim, input_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, user_ratings, beta=None, gamma=0.0005, dropout_rate=0.7, calculate_loss=True):\n",
    "        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)    \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_pred = self.decoder(z)\n",
    "\n",
    "        if calculate_loss:\n",
    "            if gamma:\n",
    "                norm = user_ratings.sum(dim=-1)\n",
    "                kl_weight = gamma * norm\n",
    "            elif beta:\n",
    "                kl_weight = beta\n",
    "\n",
    "            mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n",
    "            kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n",
    "            negative_elbo = -(mll - kld)\n",
    "            \n",
    "            return (mll, kld), negative_elbo\n",
    "            \n",
    "        else:\n",
    "            return x_pred\n",
    "\n",
    "    def update_prior(self):\n",
    "        self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwSexh43u9vk"
   },
   "source": [
    "# 4. 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg(pred_list, true_list):\n",
    "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
    "    dcg = 0\n",
    "    for rank, pred in enumerate(pred_list):\n",
    "        if pred in true_list:\n",
    "            dcg += 1 / np.log2(rank + 2)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "# hit == recall == precision\n",
    "def get_hit(pred_list, true_list):\n",
    "    hit_list = set(true_list) & set(pred_list)\n",
    "    hit = len(hit_list) / len(true_list)\n",
    "    return hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(AdmmSlim, HOSLIM, RecVAE, MultiDAE, X, user_train, user_valid, candidate_cnt):\n",
    "    NDCG = 0\n",
    "    HIT = 0\n",
    "    \n",
    "    RecVAE.eval()\n",
    "    # MultiVAE.eval()\n",
    "    MultiDAE.eval()\n",
    "    # AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    # User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    # Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    # MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    # MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    # MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    # AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    # AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (HOSLIM_rec, AdmmSlim_rec, RecVAE_rec, MultiDAE_rec) in tqdm(enumerate(zip(HOSLIM_rec_list, AdmmSlim_rec_list, RecVAE_rec_list, MultiDAE_rec_list))):\n",
    "        \n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(HOSLIM_rec + AdmmSlim_rec + RecVAE_rec + MultiDAE_rec))\n",
    "\n",
    "        rec_df = pd.DataFrame(index = all_rec)\n",
    "        rec_df.loc[HOSLIM_rec, 'HOSLIM_rec_score'] = score_li * 1.0\n",
    "        # rec_df.loc[User_EASE_rec, 'User_EASE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[Item_EASE_rec, 'Item_EASE_rec_score'] = score_li * 0.3\n",
    "        rec_df.loc[AdmmSlim_rec, 'AdmmSlim_rec_score'] = score_li * 0.6\n",
    "        rec_df.loc[RecVAE_rec, 'RecVAE_rec_score'] = score_li * 0.8\n",
    "        # rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li * 0.3\n",
    "        rec_df.loc[MultiDAE_rec, 'MultiDAE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[AutoRec_rec, 'AutoRec_rec_score'] = score_li\n",
    "        rec_df = rec_df.fillna(rec_df.min().min())\n",
    "\n",
    "        rec_df['total_rec_score'] = rec_df.sum(axis = 1)\n",
    "        rec_df = rec_df.sort_values('total_rec_score', ascending = False)\n",
    "        up = rec_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_evaluate_df(User_EASE, Item_EASE, AdmmSlim, HOSLIM, RecVAE, MultiVAE, MultiDAE, AutoRec, X, user_train, user_valid, candidate_cnt):\n",
    "    total_evaluate_df = []\n",
    "\n",
    "    RecVAE.eval()\n",
    "    MultiVAE.eval()\n",
    "    MultiDAE.eval()\n",
    "    AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "    \n",
    "    User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    for user, (User_EASE_rec, Item_EASE_rec, AdmmSlim_rec, HOSLIM_rec, RecVAE_rec, AutoRec_rec, MultiDAE_rec, MultiVAE_rec) in tqdm(enumerate(zip(User_EASE_rec_list, Item_EASE_rec_list, AdmmSlim_rec_list, HOSLIM_rec_list, RecVAE_rec_list, AutoRec_rec_list, MultiDAE_rec_list, MultiVAE_rec_list))):\n",
    "        \n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(User_EASE_rec + Item_EASE_rec + AdmmSlim_rec + HOSLIM_rec + RecVAE_rec + AutoRec_rec + MultiDAE_rec + MultiVAE_rec))\n",
    "\n",
    "        total_evaluate_df.append(\n",
    "            {\n",
    "               'user' : user,\n",
    "               'len' : len(all_rec),\n",
    "\n",
    "               'User_EASE_rec_score' : get_hit(pred_list = User_EASE_rec, true_list = uv),\n",
    "               'Item_EASE_rec_score' : get_hit(pred_list = Item_EASE_rec, true_list = uv),\n",
    "               'AdmmSlim_rec_score' : get_hit(pred_list = AdmmSlim_rec, true_list = uv),\n",
    "               'HOSLIM_rec_score' : get_hit(pred_list = HOSLIM_rec, true_list = uv),\n",
    "               'RecVAE_rec_score' : get_hit(pred_list = RecVAE_rec, true_list = uv),\n",
    "               'AutoRec_rec_score' : get_hit(pred_list = AutoRec_rec, true_list = uv),\n",
    "               'MultiDAE_rec_score' : get_hit(pred_list = MultiDAE_rec, true_list = uv),\n",
    "               'MultiVAE_rec_score' : get_hit(pred_list = MultiVAE_rec, true_list = uv),\n",
    "\n",
    "               'all_rec_score' : get_hit(pred_list = all_rec, true_list = uv),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return total_evaluate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_ensemble_df(User_EASE, Item_EASE, AdmmSlim, HOSLIM, RecVAE, MultiVAE, MultiDAE, AutoRec, X, candidate_cnt):\n",
    "    \n",
    "    weighted_ensemble_df = {}\n",
    "\n",
    "    RecVAE.eval()\n",
    "    MultiVAE.eval()\n",
    "    MultiDAE.eval()\n",
    "    AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "    \n",
    "    User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (User_EASE_rec, Item_EASE_rec, AdmmSlim_rec, HOSLIM_rec, RecVAE_rec, AutoRec_rec, MultiDAE_rec, MultiVAE_rec) in tqdm(enumerate(zip(User_EASE_rec_list, Item_EASE_rec_list, AdmmSlim_rec_list, HOSLIM_rec_list, RecVAE_rec_list, AutoRec_rec_list, MultiDAE_rec_list, MultiVAE_rec_list))):\n",
    "\n",
    "        # ranking\n",
    "        User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(User_EASE_rec + Item_EASE_rec + AdmmSlim_rec + HOSLIM_rec + RecVAE_rec + AutoRec_rec + MultiDAE_rec + MultiVAE_rec))\n",
    "\n",
    "        rec_df = pd.DataFrame(index = all_rec)\n",
    "        rec_df.loc[User_EASE_rec, 'User_EASE_rec_score'] = score_li\n",
    "        rec_df.loc[Item_EASE_rec, 'Item_EASE_rec_score'] = score_li\n",
    "        rec_df.loc[AdmmSlim_rec, 'AdmmSlim_rec_score'] = score_li\n",
    "        rec_df.loc[HOSLIM_rec, 'HOSLIM_rec_score'] = score_li\n",
    "        rec_df.loc[RecVAE_rec, 'RecVAE_rec_score'] = score_li\n",
    "        rec_df.loc[AutoRec_rec, 'AutoRec_rec_score'] = score_li\n",
    "        rec_df.loc[MultiDAE_rec, 'MultiDAE_rec_score'] = score_li\n",
    "        rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li\n",
    "\n",
    "        weighted_ensemble_df[user] = rec_df\n",
    "\n",
    "    return weighted_ensemble_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gupkaJHMslCi"
   },
   "source": [
    "# 5. 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 모델 init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hoslim = HOSLIM(threshold = 3500, lambdaBB = 500, lambdaCC = 10000, rho = 50000)\n",
    "# hoslim.fit(X = X.toarray())\n",
    "\n",
    "hoslim = HOSLIM(threshold = 3500, lambdaBB = 500, lambdaCC = 15000, rho = 10000)\n",
    "hoslim.fit(X = X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "threshold = 3500, lambdaBB = 500, lambdaCC = 15000, rho = 10000 | NDCG@10: 0.31118| HIT@10: 0.20455\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admm_slim = AdmmSlim(lambda_2 = 1, rho = 1000)\n",
    "# admm_slim.fit(X = X.toarray())\n",
    "\n",
    "admm_slim = AdmmSlim(lambda_1 = 10, lambda_2 = 5, rho = 1000)\n",
    "admm_slim.fit(X = X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "lambda_1 = 10, lambda_2 = 5, rho = 1000 | NDCG@10: 0.30627| HIT@10: 0.20035\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ease = EASE(X = X, reg = 750)\n",
    "# user_ease.fit()\n",
    "\n",
    "user_ease = EASE(X = X, reg = 680)\n",
    "user_ease.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "reg: 680| NDCG@10: 0.23002| HIT@10: 0.20400\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ease = EASE(X = X.T, reg = 4400)\n",
    "item_ease.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_vae = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,\n",
    "    latent_dim = 200).to(device)\n",
    "\n",
    "rec_vae.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3_1_best.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RecVAE_v3 | 0.192140\n",
    "\n",
    "Multi-DAE_v2 | 0.179330\n",
    "\n",
    "Multi-VAE_v2 | 0.179959\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_rec = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "auto_rec.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dae = MultiDAE(\n",
    "    p_dims = [200, 600] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "multi_dae.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_vae = MultiVAE(\n",
    "    p_dims = [200, 600] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.7).to(device)\n",
    "\n",
    "multi_vae.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v4.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. total_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_evaluate_df = get_total_evaluate_df(\n",
    "    User_EASE = user_ease, \n",
    "    Item_EASE = item_ease, \n",
    "    AdmmSlim = admm_slim, \n",
    "    HOSLIM = hoslim, \n",
    "    RecVAE = rec_vae, \n",
    "    MultiVAE = multi_vae, \n",
    "    MultiDAE = multi_dae, \n",
    "    AutoRec = auto_rec,\n",
    "    X = X.todense(), \n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid, \n",
    "    candidate_cnt = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_evaluate_df = pd.DataFrame(total_evaluate_df)\n",
    "\n",
    "def get_total_name(x):\n",
    "    val_list = [x['User_EASE_rec_score'], x['Item_EASE_rec_score'], x['AdmmSlim_rec_score'], x['HOSLIM_rec_score'], x['RecVAE_rec_score'], x['AutoRec_rec_score'], x['MultiDAE_rec_score'], x['MultiVAE_rec_score']]\n",
    "    max_val = max(val_list)\n",
    "    val_idx = val_list.index(max_val)\n",
    "    if val_idx == 0 : return 'User_EASE_rec_score'\n",
    "    elif val_idx == 1 : return 'Item_EASE_rec_score'\n",
    "    elif val_idx == 2 : return 'AdmmSlim_rec_score'\n",
    "    elif val_idx == 3 : return 'HOSLIM_rec_score'\n",
    "    elif val_idx == 4 : return 'RecVAE_rec_score'\n",
    "    elif val_idx == 5 : return 'AutoRec_rec_score'\n",
    "    elif val_idx == 6 : return 'MultiDAE_rec_score'\n",
    "    elif val_idx == 7 : return 'MultiVAE_rec_score'\n",
    "\n",
    "total_evaluate_df['total_best_rec_score'] = total_evaluate_df.apply(lambda x: max(x['User_EASE_rec_score'], x['Item_EASE_rec_score'], x['AdmmSlim_rec_score'], x['HOSLIM_rec_score'], x['RecVAE_rec_score'], x['AutoRec_rec_score'], x['MultiDAE_rec_score'], x['MultiVAE_rec_score']), axis = 1)\n",
    "total_evaluate_df['total_best_rec_score_name'] = total_evaluate_df.apply(lambda x: get_total_name(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = total_evaluate_df.columns.tolist()[2:-1]\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.histplot(data = total_evaluate_df[cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_EASE_rec_score    14955\n",
       "Item_EASE_rec_score     3846\n",
       "AdmmSlim_rec_score      3534\n",
       "RecVAE_rec_score        2480\n",
       "MultiDAE_rec_score      2068\n",
       "MultiVAE_rec_score      1815\n",
       "AutoRec_rec_score       1709\n",
       "HOSLIM_rec_score         953\n",
       "Name: total_best_rec_score_name, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_evaluate_df['total_best_rec_score_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user                    15679.500000\n",
       "len                        24.937596\n",
       "User_EASE_rec_score         0.204002\n",
       "Item_EASE_rec_score         0.200207\n",
       "AdmmSlim_rec_score          0.200351\n",
       "HOSLIM_rec_score            0.204554\n",
       "RecVAE_rec_score            0.168103\n",
       "AutoRec_rec_score           0.174758\n",
       "MultiDAE_rec_score          0.182293\n",
       "MultiVAE_rec_score          0.182465\n",
       "all_rec_score               0.316706\n",
       "total_best_rec_score        0.267879\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_evaluate_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "len                        24.976467\n",
    "User_EASE_rec_score         0.204002\n",
    "Item_EASE_rec_score         0.200207\n",
    "AdmmSlim_rec_score          0.200351\n",
    "HOSLIM_rec_score            0.204554\n",
    "RecVAE_rec_score            0.193332\n",
    "AutoRec_rec_score           0.174758\n",
    "MultiDAE_rec_score          0.182293\n",
    "MultiVAE_rec_score          0.182465\n",
    "all_rec_score               0.320619\n",
    "total_best_rec_score        0.271078\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "len                        25.295663\n",
    "User_EASE_rec_score         0.203839\n",
    "Item_EASE_rec_score         0.200207\n",
    "AdmmSlim_rec_score          0.200236\n",
    "HOSLIM_rec_score            0.204423\n",
    "RecVAE_rec_score            0.192140\n",
    "AutoRec_rec_score           0.174758\n",
    "MultiDAE_rec_score          0.179330\n",
    "MultiVAE_rec_score          0.179959\n",
    "all_rec_score               0.321936\n",
    "total_best_rec_score        0.271237\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 11)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "        # User_EASE = user_ease, \n",
    "        # Item_EASE = item_ease, \n",
    "        AdmmSlim = admm_slim, \n",
    "        HOSLIM = hoslim,\n",
    "        RecVAE = rec_vae, \n",
    "        # MultiVAE = multi_vae, \n",
    "        MultiDAE = multi_dae, \n",
    "        # AutoRec = auto_rec,\n",
    "        X = X.todense(), \n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid,\n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 11)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "        # User_EASE = user_ease, \n",
    "        # Item_EASE = item_ease, \n",
    "        AdmmSlim = admm_slim, \n",
    "        HOSLIM = hoslim,\n",
    "        RecVAE = rec_vae, \n",
    "        # MultiVAE = multi_vae, \n",
    "        MultiDAE = multi_dae, \n",
    "        # AutoRec = auto_rec,\n",
    "        X = X.todense(), \n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid,\n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4. get_weighted_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:53, 180.74it/s]\n"
     ]
    }
   ],
   "source": [
    "weighted_ensemble_df = get_weighted_ensemble_df(\n",
    "    User_EASE = user_ease, \n",
    "    Item_EASE = item_ease, \n",
    "    AdmmSlim = admm_slim, \n",
    "    HOSLIM = hoslim, \n",
    "    RecVAE = rec_vae, \n",
    "    MultiVAE = multi_vae, \n",
    "    MultiDAE = multi_dae, \n",
    "    AutoRec = auto_rec,\n",
    "    X = X.todense(),\n",
    "    candidate_cnt = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_total</th>\n",
       "      <th>mean_total</th>\n",
       "      <th>rank_sum_total</th>\n",
       "      <th>rank_mean_total</th>\n",
       "      <th>log_rank_sum_total</th>\n",
       "      <th>log_rank_mean_total</th>\n",
       "      <th>sum_total_rank</th>\n",
       "      <th>mean_total_rank</th>\n",
       "      <th>rank_sum_total_rank</th>\n",
       "      <th>rank_mean_total_rank</th>\n",
       "      <th>log_rank_sum_total_rank</th>\n",
       "      <th>log_rank_mean_total_rank</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>77.0</td>\n",
       "      <td>9.625</td>\n",
       "      <td>1.890000</td>\n",
       "      <td>0.236250</td>\n",
       "      <td>3.249907</td>\n",
       "      <td>0.406238</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>89.0</td>\n",
       "      <td>11.125</td>\n",
       "      <td>1.016807</td>\n",
       "      <td>0.127101</td>\n",
       "      <td>2.482270</td>\n",
       "      <td>0.310284</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>103.0</td>\n",
       "      <td>12.875</td>\n",
       "      <td>0.885684</td>\n",
       "      <td>0.110710</td>\n",
       "      <td>2.348951</td>\n",
       "      <td>0.293619</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>160.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.671620</td>\n",
       "      <td>0.083953</td>\n",
       "      <td>2.104386</td>\n",
       "      <td>0.263048</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>156.0</td>\n",
       "      <td>19.500</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.072167</td>\n",
       "      <td>2.015265</td>\n",
       "      <td>0.251908</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>353.0</td>\n",
       "      <td>44.125</td>\n",
       "      <td>0.198256</td>\n",
       "      <td>0.024782</td>\n",
       "      <td>1.478949</td>\n",
       "      <td>0.184869</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.500</td>\n",
       "      <td>6.424242</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>6.778943</td>\n",
       "      <td>0.847368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>55.0</td>\n",
       "      <td>6.875</td>\n",
       "      <td>2.464286</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>3.691374</td>\n",
       "      <td>0.461422</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>76.0</td>\n",
       "      <td>9.500</td>\n",
       "      <td>2.386667</td>\n",
       "      <td>0.298333</td>\n",
       "      <td>3.668348</td>\n",
       "      <td>0.458543</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>92.0</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1.471739</td>\n",
       "      <td>0.183967</td>\n",
       "      <td>2.889752</td>\n",
       "      <td>0.361219</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>77.0</td>\n",
       "      <td>9.625</td>\n",
       "      <td>1.095833</td>\n",
       "      <td>0.136979</td>\n",
       "      <td>2.580394</td>\n",
       "      <td>0.322549</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>216.0</td>\n",
       "      <td>27.000</td>\n",
       "      <td>1.283563</td>\n",
       "      <td>0.160445</td>\n",
       "      <td>2.473155</td>\n",
       "      <td>0.309144</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>112.0</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.888290</td>\n",
       "      <td>0.111036</td>\n",
       "      <td>2.364695</td>\n",
       "      <td>0.295587</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>196.0</td>\n",
       "      <td>24.500</td>\n",
       "      <td>0.987965</td>\n",
       "      <td>0.123496</td>\n",
       "      <td>2.319040</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>200.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.925278</td>\n",
       "      <td>0.115660</td>\n",
       "      <td>2.270949</td>\n",
       "      <td>0.283869</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>203.0</td>\n",
       "      <td>25.375</td>\n",
       "      <td>0.858291</td>\n",
       "      <td>0.107286</td>\n",
       "      <td>2.192795</td>\n",
       "      <td>0.274099</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>145.0</td>\n",
       "      <td>18.125</td>\n",
       "      <td>0.594155</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>2.045158</td>\n",
       "      <td>0.255645</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>159.0</td>\n",
       "      <td>19.875</td>\n",
       "      <td>0.555231</td>\n",
       "      <td>0.069404</td>\n",
       "      <td>1.988171</td>\n",
       "      <td>0.248521</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>257.0</td>\n",
       "      <td>32.125</td>\n",
       "      <td>0.521844</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>1.865490</td>\n",
       "      <td>0.233186</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>193.0</td>\n",
       "      <td>24.125</td>\n",
       "      <td>0.418833</td>\n",
       "      <td>0.052354</td>\n",
       "      <td>1.821193</td>\n",
       "      <td>0.227649</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sum_total  mean_total  rank_sum_total  rank_mean_total  \\\n",
       "197        77.0       9.625        1.890000         0.236250   \n",
       "273        89.0      11.125        1.016807         0.127101   \n",
       "313       103.0      12.875        0.885684         0.110710   \n",
       "42        160.0      20.000        0.671620         0.083953   \n",
       "228       156.0      19.500        0.577337         0.072167   \n",
       "147       353.0      44.125        0.198256         0.024782   \n",
       "933        20.0       2.500        6.424242         0.803030   \n",
       "667        55.0       6.875        2.464286         0.308036   \n",
       "484        76.0       9.500        2.386667         0.298333   \n",
       "376        92.0      11.500        1.471739         0.183967   \n",
       "2200       77.0       9.625        1.095833         0.136979   \n",
       "609       216.0      27.000        1.283563         0.160445   \n",
       "650       112.0      14.000        0.888290         0.111036   \n",
       "718       196.0      24.500        0.987965         0.123496   \n",
       "777       200.0      25.000        0.925278         0.115660   \n",
       "714       203.0      25.375        0.858291         0.107286   \n",
       "760       145.0      18.125        0.594155         0.074269   \n",
       "734       159.0      19.875        0.555231         0.069404   \n",
       "1844      257.0      32.125        0.521844         0.065230   \n",
       "730       193.0      24.125        0.418833         0.052354   \n",
       "\n",
       "      log_rank_sum_total  log_rank_mean_total  sum_total_rank  \\\n",
       "197             3.249907             0.406238               4   \n",
       "273             2.482270             0.310284               6   \n",
       "313             2.348951             0.293619               8   \n",
       "42              2.104386             0.263048              13   \n",
       "228             2.015265             0.251908              11   \n",
       "147             1.478949             0.184869              56   \n",
       "933             6.778943             0.847368               1   \n",
       "667             3.691374             0.461422               2   \n",
       "484             3.668348             0.458543               3   \n",
       "376             2.889752             0.361219               7   \n",
       "2200            2.580394             0.322549               5   \n",
       "609             2.473155             0.309144              19   \n",
       "650             2.364695             0.295587               9   \n",
       "718             2.319040             0.289880              16   \n",
       "777             2.270949             0.283869              17   \n",
       "714             2.192795             0.274099              18   \n",
       "760             2.045158             0.255645              10   \n",
       "734             1.988171             0.248521              12   \n",
       "1844            1.865490             0.233186              26   \n",
       "730             1.821193             0.227649              15   \n",
       "\n",
       "      mean_total_rank  rank_sum_total_rank  rank_mean_total_rank  \\\n",
       "197                 4                    4                     4   \n",
       "273                 6                    8                     8   \n",
       "313                 8                   12                    12   \n",
       "42                 13                   14                    14   \n",
       "228                11                   16                    16   \n",
       "147                56                   55                    55   \n",
       "933                 1                    1                     1   \n",
       "667                 2                    2                     2   \n",
       "484                 3                    3                     3   \n",
       "376                 7                    5                     5   \n",
       "2200                5                    7                     7   \n",
       "609                19                    6                     6   \n",
       "650                 9                   11                    11   \n",
       "718                16                    9                     9   \n",
       "777                17                   10                    10   \n",
       "714                18                   13                    13   \n",
       "760                10                   15                    15   \n",
       "734                12                   17                    17   \n",
       "1844               26                   18                    18   \n",
       "730                15                   20                    20   \n",
       "\n",
       "      log_rank_sum_total_rank  log_rank_mean_total_rank  target  \n",
       "197                         4                         4     1.0  \n",
       "273                         7                         7     1.0  \n",
       "313                        10                        10     1.0  \n",
       "42                         14                        14     1.0  \n",
       "228                        16                        16     1.0  \n",
       "147                        57                        57     1.0  \n",
       "933                         1                         1     NaN  \n",
       "667                         2                         2     NaN  \n",
       "484                         3                         3     NaN  \n",
       "376                         5                         5     NaN  \n",
       "2200                        6                         6     NaN  \n",
       "609                         8                         8     NaN  \n",
       "650                         9                         9     NaN  \n",
       "718                        11                        11     NaN  \n",
       "777                        12                        12     NaN  \n",
       "714                        13                        13     NaN  \n",
       "760                        15                        15     NaN  \n",
       "734                        17                        17     NaN  \n",
       "1844                       18                        18     NaN  \n",
       "730                        19                        19     NaN  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. rank sum 제일 낮은 순\n",
    "2. rank sum mean 제일 낮은 순\n",
    "\n",
    "3. 1/rank sum 제일 높은 순\n",
    "4. 1/rank sum mean 제일 높은 순\n",
    "\n",
    "5. 1 / log(rank + 1) sum 제일 높은 순\n",
    "6. 1 / log(rank + 1) sum mean 제일 높은 순\n",
    "\n",
    "7. 선별 model + 위 과정\n",
    "8. 선별 model + 각 모델별 가중치 + 위 과정\n",
    "'''\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "def get_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / x\n",
    "\n",
    "def get_log_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / np.log2(x + 1)\n",
    "\n",
    "# cols : ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "# weighte : [1.0, 0.6, 0.8, 0.3]| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "\n",
    "df = weighted_ensemble_df[0].copy()\n",
    "cols = df.columns\n",
    "log_rank_score_cols = []\n",
    "rank_score_cols = []\n",
    "for col in cols:\n",
    "    df['rank_score_'+col] = df[col].apply(lambda x : get_rank_score(x))\n",
    "    rank_score_cols.append('rank_score_'+col)\n",
    "\n",
    "    df['log_rank_score_'+col] = df[col].apply(lambda x : get_log_rank_score(x))\n",
    "    log_rank_score_cols.append('log_rank_score_'+col)\n",
    "\n",
    "uv = user_valid[0]\n",
    "up = df.index.tolist()\n",
    "target = list(set(uv) & set(up))\n",
    "\n",
    "rank_score_df = df[rank_score_cols]\n",
    "log_rank_score_df = df[log_rank_score_cols]\n",
    "df = df[cols]\n",
    "\n",
    "rank_score_df = rank_score_df.fillna(rank_score_df.min().min())\n",
    "rank_score_df['rank_sum_total'] = rank_score_df[rank_score_cols].sum(axis = 1)\n",
    "rank_score_df['rank_mean_total'] = rank_score_df[rank_score_cols].mean(axis = 1)\n",
    "\n",
    "log_rank_score_df = log_rank_score_df.fillna(log_rank_score_df.min().min())\n",
    "log_rank_score_df['log_rank_sum_total'] = log_rank_score_df[log_rank_score_cols].sum(axis = 1)\n",
    "log_rank_score_df['log_rank_mean_total'] = log_rank_score_df[log_rank_score_cols].mean(axis = 1)\n",
    "\n",
    "df = df.fillna(df.max().max())\n",
    "df['sum_total'] = df[cols].sum(axis = 1)\n",
    "df['mean_total'] = df[cols].mean(axis = 1)\n",
    "\n",
    "df = pd.concat([df, rank_score_df, log_rank_score_df], axis = 1)\n",
    "\n",
    "df = df[['sum_total', 'mean_total', 'rank_sum_total', 'rank_mean_total', 'log_rank_sum_total', 'log_rank_mean_total']]\n",
    "\n",
    "df = df.sort_values('sum_total', ascending = True)\n",
    "df['sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('mean_total', ascending = True)\n",
    "df['mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_sum_total', ascending = False)\n",
    "df['rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_mean_total', ascending = False)\n",
    "df['rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_sum_total', ascending = False)\n",
    "df['log_rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_mean_total', ascending = False)\n",
    "df['log_rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df.loc[target, 'target'] = 1\n",
    "df.sort_values('target', ascending = True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_total</th>\n",
       "      <th>mean_total</th>\n",
       "      <th>rank_sum_total</th>\n",
       "      <th>rank_mean_total</th>\n",
       "      <th>log_rank_sum_total</th>\n",
       "      <th>log_rank_mean_total</th>\n",
       "      <th>sum_total_rank</th>\n",
       "      <th>mean_total_rank</th>\n",
       "      <th>rank_sum_total_rank</th>\n",
       "      <th>rank_mean_total_rank</th>\n",
       "      <th>log_rank_sum_total_rank</th>\n",
       "      <th>log_rank_mean_total_rank</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>42.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.204167</td>\n",
       "      <td>1.519378</td>\n",
       "      <td>0.379845</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>50.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>1.142500</td>\n",
       "      <td>0.285625</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>49.0</td>\n",
       "      <td>12.25</td>\n",
       "      <td>0.397076</td>\n",
       "      <td>0.099269</td>\n",
       "      <td>1.138615</td>\n",
       "      <td>0.284654</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>68.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.346726</td>\n",
       "      <td>0.086682</td>\n",
       "      <td>1.071282</td>\n",
       "      <td>0.267820</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>62.0</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.299573</td>\n",
       "      <td>0.074893</td>\n",
       "      <td>1.031578</td>\n",
       "      <td>0.257895</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>153.0</td>\n",
       "      <td>38.25</td>\n",
       "      <td>0.118256</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.773783</td>\n",
       "      <td>0.193446</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>14.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>3.278943</td>\n",
       "      <td>0.819736</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2.118067</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.488095</td>\n",
       "      <td>0.372024</td>\n",
       "      <td>2.026196</td>\n",
       "      <td>0.506549</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>21.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1.650418</td>\n",
       "      <td>0.412604</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>83.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>0.688478</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>1.340790</td>\n",
       "      <td>0.335198</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>34.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.123512</td>\n",
       "      <td>1.252370</td>\n",
       "      <td>0.313092</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>118.0</td>\n",
       "      <td>29.50</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>1.228163</td>\n",
       "      <td>0.307041</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>46.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>1.162007</td>\n",
       "      <td>0.290502</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>86.0</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.398918</td>\n",
       "      <td>0.099729</td>\n",
       "      <td>1.104123</td>\n",
       "      <td>0.276031</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>53.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.086150</td>\n",
       "      <td>1.085774</td>\n",
       "      <td>0.271444</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>83.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>0.272870</td>\n",
       "      <td>0.068217</td>\n",
       "      <td>0.987090</td>\n",
       "      <td>0.246772</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>121.0</td>\n",
       "      <td>30.25</td>\n",
       "      <td>0.299232</td>\n",
       "      <td>0.074808</td>\n",
       "      <td>0.980141</td>\n",
       "      <td>0.245035</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>119.0</td>\n",
       "      <td>29.75</td>\n",
       "      <td>0.283590</td>\n",
       "      <td>0.070897</td>\n",
       "      <td>0.971440</td>\n",
       "      <td>0.242860</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>154.0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.959551</td>\n",
       "      <td>0.239888</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sum_total  mean_total  rank_sum_total  rank_mean_total  \\\n",
       "197        42.0       10.50        0.816667         0.204167   \n",
       "313        50.0       12.50        0.405556         0.101389   \n",
       "273        49.0       12.25        0.397076         0.099269   \n",
       "42         68.0       17.00        0.346726         0.086682   \n",
       "228        62.0       15.50        0.299573         0.074893   \n",
       "147       153.0       38.25        0.118256         0.029564   \n",
       "933        14.0        3.50        3.090909         0.772727   \n",
       "484        13.0        3.25        1.500000         0.375000   \n",
       "667        30.0        7.50        1.488095         0.372024   \n",
       "376        21.0        5.25        0.933333         0.233333   \n",
       "714        83.0       20.75        0.688478         0.172120   \n",
       "650        34.0        8.50        0.494048         0.123512   \n",
       "777       118.0       29.50        0.602500         0.150625   \n",
       "2200       46.0       11.50        0.416667         0.104167   \n",
       "718        86.0       21.50        0.398918         0.099729   \n",
       "760        53.0       13.25        0.344600         0.086150   \n",
       "734        83.0       20.75        0.272870         0.068217   \n",
       "717       121.0       30.25        0.299232         0.074808   \n",
       "1354      119.0       29.75        0.283590         0.070897   \n",
       "2427      154.0       38.50        0.310000         0.077500   \n",
       "\n",
       "      log_rank_sum_total  log_rank_mean_total  sum_total_rank  \\\n",
       "197             1.519378             0.379845               6   \n",
       "313             1.142500             0.285625               9   \n",
       "273             1.138615             0.284654               8   \n",
       "42              1.071282             0.267820              12   \n",
       "228             1.031578             0.257895              11   \n",
       "147             0.773783             0.193446              35   \n",
       "933             3.278943             0.819736               2   \n",
       "484             2.118067             0.529517               1   \n",
       "667             2.026196             0.506549               4   \n",
       "376             1.650418             0.412604               3   \n",
       "714             1.340790             0.335198              14   \n",
       "650             1.252370             0.313092               5   \n",
       "777             1.228163             0.307041              21   \n",
       "2200            1.162007             0.290502               7   \n",
       "718             1.104123             0.276031              15   \n",
       "760             1.085774             0.271444              10   \n",
       "734             0.987090             0.246772              13   \n",
       "717             0.980141             0.245035              24   \n",
       "1354            0.971440             0.242860              22   \n",
       "2427            0.959551             0.239888              36   \n",
       "\n",
       "      mean_total_rank  rank_sum_total_rank  rank_mean_total_rank  \\\n",
       "197                 6                    5                     5   \n",
       "313                 9                   10                    10   \n",
       "273                 8                   12                    12   \n",
       "42                 12                   13                    13   \n",
       "228                11                   16                    16   \n",
       "147                35                   37                    37   \n",
       "933                 2                    1                     1   \n",
       "484                 1                    2                     2   \n",
       "667                 4                    3                     3   \n",
       "376                 3                    4                     4   \n",
       "714                14                    6                     6   \n",
       "650                 5                    8                     8   \n",
       "777                21                    7                     7   \n",
       "2200                7                    9                     9   \n",
       "718                15                   11                    11   \n",
       "760                10                   14                    14   \n",
       "734                13                   19                    19   \n",
       "717                24                   17                    17   \n",
       "1354               22                   18                    18   \n",
       "2427               36                   15                    15   \n",
       "\n",
       "      log_rank_sum_total_rank  log_rank_mean_total_rank  target  \n",
       "197                         5                         5     1.0  \n",
       "313                        10                        10     1.0  \n",
       "273                        11                        11     1.0  \n",
       "42                         14                        14     1.0  \n",
       "228                        15                        15     1.0  \n",
       "147                        37                        37     1.0  \n",
       "933                         1                         1     NaN  \n",
       "484                         2                         2     NaN  \n",
       "667                         3                         3     NaN  \n",
       "376                         4                         4     NaN  \n",
       "714                         6                         6     NaN  \n",
       "650                         7                         7     NaN  \n",
       "777                         8                         8     NaN  \n",
       "2200                        9                         9     NaN  \n",
       "718                        12                        12     NaN  \n",
       "760                        13                        13     NaN  \n",
       "734                        16                        16     NaN  \n",
       "717                        17                        17     NaN  \n",
       "1354                       18                        18     NaN  \n",
       "2427                       19                        19     NaN  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "def get_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / x\n",
    "\n",
    "def get_log_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / np.log2(x + 1)\n",
    "\n",
    "# cols : ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "# weighte : [1.0, 0.6, 0.8, 0.3]| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "\n",
    "df = weighted_ensemble_df[0].copy()\n",
    "cols = [col for col in df.columns if col in ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']]\n",
    "log_rank_score_cols = []\n",
    "rank_score_cols = []\n",
    "for col in cols:\n",
    "    df['rank_score_'+col] = df[col].apply(lambda x : get_rank_score(x))\n",
    "    rank_score_cols.append('rank_score_'+col)\n",
    "\n",
    "    df['log_rank_score_'+col] = df[col].apply(lambda x : get_log_rank_score(x))\n",
    "    log_rank_score_cols.append('log_rank_score_'+col)\n",
    "\n",
    "uv = user_valid[0]\n",
    "up = df.index.tolist()\n",
    "target = list(set(uv) & set(up))\n",
    "\n",
    "rank_score_df = df[rank_score_cols]\n",
    "log_rank_score_df = df[log_rank_score_cols]\n",
    "df = df[cols]\n",
    "\n",
    "rank_score_df = rank_score_df.fillna(rank_score_df.min().min())\n",
    "rank_score_df['rank_sum_total'] = rank_score_df[rank_score_cols].sum(axis = 1)\n",
    "rank_score_df['rank_mean_total'] = rank_score_df[rank_score_cols].mean(axis = 1)\n",
    "\n",
    "log_rank_score_df = log_rank_score_df.fillna(log_rank_score_df.min().min())\n",
    "log_rank_score_df['log_rank_sum_total'] = log_rank_score_df[log_rank_score_cols].sum(axis = 1)\n",
    "log_rank_score_df['log_rank_mean_total'] = log_rank_score_df[log_rank_score_cols].mean(axis = 1)\n",
    "\n",
    "df = df.fillna(df.max().max())\n",
    "df['sum_total'] = df[cols].sum(axis = 1)\n",
    "df['mean_total'] = df[cols].mean(axis = 1)\n",
    "\n",
    "df = pd.concat([df, rank_score_df, log_rank_score_df], axis = 1)\n",
    "\n",
    "df = df[['sum_total', 'mean_total', 'rank_sum_total', 'rank_mean_total', 'log_rank_sum_total', 'log_rank_mean_total']]\n",
    "\n",
    "df = df.sort_values('sum_total', ascending = True)\n",
    "df['sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('mean_total', ascending = True)\n",
    "df['mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_sum_total', ascending = False)\n",
    "df['rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_mean_total', ascending = False)\n",
    "df['rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_sum_total', ascending = False)\n",
    "df['log_rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_mean_total', ascending = False)\n",
    "df['log_rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df.loc[target, 'target'] = 1\n",
    "df.sort_values('target', ascending = True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_total</th>\n",
       "      <th>mean_total</th>\n",
       "      <th>rank_sum_total</th>\n",
       "      <th>rank_mean_total</th>\n",
       "      <th>log_rank_sum_total</th>\n",
       "      <th>log_rank_mean_total</th>\n",
       "      <th>sum_total_rank</th>\n",
       "      <th>mean_total_rank</th>\n",
       "      <th>rank_sum_total_rank</th>\n",
       "      <th>rank_mean_total_rank</th>\n",
       "      <th>log_rank_sum_total_rank</th>\n",
       "      <th>log_rank_mean_total_rank</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>32.3</td>\n",
       "      <td>8.075</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.204167</td>\n",
       "      <td>1.222938</td>\n",
       "      <td>0.305735</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>32.1</td>\n",
       "      <td>8.025</td>\n",
       "      <td>0.397076</td>\n",
       "      <td>0.099269</td>\n",
       "      <td>0.896522</td>\n",
       "      <td>0.224131</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>35.1</td>\n",
       "      <td>8.775</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.892268</td>\n",
       "      <td>0.223067</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>38.2</td>\n",
       "      <td>9.550</td>\n",
       "      <td>0.346726</td>\n",
       "      <td>0.086682</td>\n",
       "      <td>0.850596</td>\n",
       "      <td>0.212649</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>37.2</td>\n",
       "      <td>9.300</td>\n",
       "      <td>0.299573</td>\n",
       "      <td>0.074893</td>\n",
       "      <td>0.806808</td>\n",
       "      <td>0.201702</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>118.9</td>\n",
       "      <td>29.725</td>\n",
       "      <td>0.118256</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.536382</td>\n",
       "      <td>0.134096</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>8.7</td>\n",
       "      <td>2.175</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>2.941036</td>\n",
       "      <td>0.735259</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>7.4</td>\n",
       "      <td>1.850</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.813483</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>18.4</td>\n",
       "      <td>4.600</td>\n",
       "      <td>1.488095</td>\n",
       "      <td>0.372024</td>\n",
       "      <td>1.742804</td>\n",
       "      <td>0.435701</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1.371002</td>\n",
       "      <td>0.342750</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>80.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.688478</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>1.012589</td>\n",
       "      <td>0.253147</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>24.2</td>\n",
       "      <td>6.050</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.123512</td>\n",
       "      <td>0.986268</td>\n",
       "      <td>0.246567</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>27.6</td>\n",
       "      <td>6.900</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.920824</td>\n",
       "      <td>0.230206</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>62.5</td>\n",
       "      <td>15.625</td>\n",
       "      <td>0.398918</td>\n",
       "      <td>0.099729</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.213952</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>31.4</td>\n",
       "      <td>7.850</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.086150</td>\n",
       "      <td>0.855459</td>\n",
       "      <td>0.213865</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>106.4</td>\n",
       "      <td>26.600</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>0.848630</td>\n",
       "      <td>0.212158</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>44.2</td>\n",
       "      <td>11.050</td>\n",
       "      <td>0.272870</td>\n",
       "      <td>0.068217</td>\n",
       "      <td>0.779848</td>\n",
       "      <td>0.194962</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>55.9</td>\n",
       "      <td>13.975</td>\n",
       "      <td>0.235323</td>\n",
       "      <td>0.058831</td>\n",
       "      <td>0.727259</td>\n",
       "      <td>0.181815</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>91.6</td>\n",
       "      <td>22.900</td>\n",
       "      <td>0.218135</td>\n",
       "      <td>0.054534</td>\n",
       "      <td>0.717638</td>\n",
       "      <td>0.179410</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>114.1</td>\n",
       "      <td>28.525</td>\n",
       "      <td>0.299232</td>\n",
       "      <td>0.074808</td>\n",
       "      <td>0.685956</td>\n",
       "      <td>0.171489</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sum_total  mean_total  rank_sum_total  rank_mean_total  \\\n",
       "197        32.3       8.075        0.816667         0.204167   \n",
       "273        32.1       8.025        0.397076         0.099269   \n",
       "313        35.1       8.775        0.405556         0.101389   \n",
       "42         38.2       9.550        0.346726         0.086682   \n",
       "228        37.2       9.300        0.299573         0.074893   \n",
       "147       118.9      29.725        0.118256         0.029564   \n",
       "933         8.7       2.175        3.090909         0.772727   \n",
       "484         7.4       1.850        1.500000         0.375000   \n",
       "667        18.4       4.600        1.488095         0.372024   \n",
       "376        12.0       3.000        0.933333         0.233333   \n",
       "714        80.0      20.000        0.688478         0.172120   \n",
       "650        24.2       6.050        0.494048         0.123512   \n",
       "2200       27.6       6.900        0.416667         0.104167   \n",
       "718        62.5      15.625        0.398918         0.099729   \n",
       "760        31.4       7.850        0.344600         0.086150   \n",
       "777       106.4      26.600        0.602500         0.150625   \n",
       "734        44.2      11.050        0.272870         0.068217   \n",
       "730        55.9      13.975        0.235323         0.058831   \n",
       "615        91.6      22.900        0.218135         0.054534   \n",
       "717       114.1      28.525        0.299232         0.074808   \n",
       "\n",
       "      log_rank_sum_total  log_rank_mean_total  sum_total_rank  \\\n",
       "197             1.222938             0.305735               9   \n",
       "273             0.896522             0.224131               8   \n",
       "313             0.892268             0.223067              10   \n",
       "42              0.850596             0.212649              12   \n",
       "228             0.806808             0.201702              11   \n",
       "147             0.536382             0.134096              31   \n",
       "933             2.941036             0.735259               2   \n",
       "484             1.813483             0.453371               1   \n",
       "667             1.742804             0.435701               4   \n",
       "376             1.371002             0.342750               3   \n",
       "714             1.012589             0.253147              20   \n",
       "650             0.986268             0.246567               5   \n",
       "2200            0.920824             0.230206               6   \n",
       "718             0.855809             0.213952              16   \n",
       "760             0.855459             0.213865               7   \n",
       "777             0.848630             0.212158              23   \n",
       "734             0.779848             0.194962              13   \n",
       "730             0.727259             0.181815              14   \n",
       "615             0.717638             0.179410              21   \n",
       "717             0.685956             0.171489              28   \n",
       "\n",
       "      mean_total_rank  rank_sum_total_rank  rank_mean_total_rank  \\\n",
       "197                 9                    5                     5   \n",
       "273                 8                   12                    12   \n",
       "313                10                   10                    10   \n",
       "42                 12                   13                    13   \n",
       "228                11                   16                    16   \n",
       "147                31                   37                    37   \n",
       "933                 2                    1                     1   \n",
       "484                 1                    2                     2   \n",
       "667                 4                    3                     3   \n",
       "376                 3                    4                     4   \n",
       "714                20                    6                     6   \n",
       "650                 5                    8                     8   \n",
       "2200                6                    9                     9   \n",
       "718                16                   11                    11   \n",
       "760                 7                   14                    14   \n",
       "777                23                    7                     7   \n",
       "734                13                   19                    19   \n",
       "730                14                   20                    20   \n",
       "615                21                   21                    21   \n",
       "717                28                   17                    17   \n",
       "\n",
       "      log_rank_sum_total_rank  log_rank_mean_total_rank  target  \n",
       "197                         5                         5     1.0  \n",
       "273                         9                         9     1.0  \n",
       "313                        10                        10     1.0  \n",
       "42                         13                        13     1.0  \n",
       "228                        15                        15     1.0  \n",
       "147                        34                        34     1.0  \n",
       "933                         1                         1     NaN  \n",
       "484                         2                         2     NaN  \n",
       "667                         3                         3     NaN  \n",
       "376                         4                         4     NaN  \n",
       "714                         6                         6     NaN  \n",
       "650                         7                         7     NaN  \n",
       "2200                        8                         8     NaN  \n",
       "718                        11                        11     NaN  \n",
       "760                        12                        12     NaN  \n",
       "777                        14                        14     NaN  \n",
       "734                        16                        16     NaN  \n",
       "730                        17                        17     NaN  \n",
       "615                        18                        18     NaN  \n",
       "717                        19                        19     NaN  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "def get_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / x\n",
    "\n",
    "def get_log_rank_score(x):\n",
    "    if pd.isna(x) : return x\n",
    "    else: return 1 / np.log2(x + 1)\n",
    "\n",
    "# cols : ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "# weighte : [1.0, 0.6, 0.8, 0.3]| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "\n",
    "df = weighted_ensemble_df[0].copy()\n",
    "cols = [col for col in df.columns if col in ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']]\n",
    "log_rank_score_cols = []\n",
    "rank_score_cols = []\n",
    "for col in cols:\n",
    "    if col == 'HOSLIM_rec_score':\n",
    "        w = 1.0\n",
    "    elif col == 'AdmmSlim_rec_score':\n",
    "        w = 0.6\n",
    "    elif col == 'RecVAE_rec_score':\n",
    "        w = 0.8\n",
    "    elif col == 'MultiDAE_rec_score':\n",
    "        w = 0.3\n",
    "\n",
    "    df[col] = df[col] * w\n",
    "\n",
    "    df['rank_score_'+col] = df[col].apply(lambda x : get_rank_score(x)) * w\n",
    "    rank_score_cols.append('rank_score_'+col)\n",
    "\n",
    "    df['log_rank_score_'+col] = df[col].apply(lambda x : get_log_rank_score(x)) * w\n",
    "    log_rank_score_cols.append('log_rank_score_'+col)\n",
    "\n",
    "uv = user_valid[0]\n",
    "up = df.index.tolist()\n",
    "target = list(set(uv) & set(up))\n",
    "\n",
    "rank_score_df = df[rank_score_cols]\n",
    "log_rank_score_df = df[log_rank_score_cols]\n",
    "df = df[cols]\n",
    "\n",
    "rank_score_df = rank_score_df.fillna(rank_score_df.min().min())\n",
    "rank_score_df['rank_sum_total'] = rank_score_df[rank_score_cols].sum(axis = 1)\n",
    "rank_score_df['rank_mean_total'] = rank_score_df[rank_score_cols].mean(axis = 1)\n",
    "\n",
    "log_rank_score_df = log_rank_score_df.fillna(log_rank_score_df.min().min())\n",
    "log_rank_score_df['log_rank_sum_total'] = log_rank_score_df[log_rank_score_cols].sum(axis = 1)\n",
    "log_rank_score_df['log_rank_mean_total'] = log_rank_score_df[log_rank_score_cols].mean(axis = 1)\n",
    "\n",
    "df = df.fillna(df.max().max())\n",
    "df['sum_total'] = df[cols].sum(axis = 1)\n",
    "df['mean_total'] = df[cols].mean(axis = 1)\n",
    "\n",
    "df = pd.concat([df, rank_score_df, log_rank_score_df], axis = 1)\n",
    "\n",
    "df = df[['sum_total', 'mean_total', 'rank_sum_total', 'rank_mean_total', 'log_rank_sum_total', 'log_rank_mean_total']]\n",
    "\n",
    "df = df.sort_values('sum_total', ascending = True)\n",
    "df['sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('mean_total', ascending = True)\n",
    "df['mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_sum_total', ascending = False)\n",
    "df['rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('rank_mean_total', ascending = False)\n",
    "df['rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_sum_total', ascending = False)\n",
    "df['log_rank_sum_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df = df.sort_values('log_rank_mean_total', ascending = False)\n",
    "df['log_rank_mean_total_rank'] = df.reset_index().index.values + 1\n",
    "\n",
    "df.loc[target, 'target'] = 1\n",
    "df.sort_values('target', ascending = True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-5. serch_best_combination_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "target_cols = ['HOSLIM_rec_score', 'User_EASE_rec_score', 'AdmmSlim_rec_score', 'Item_EASE_rec_score', 'RecVAE_rec_score', 'MultiVAE_rec_score', 'MultiDAE_rec_score']\n",
    "users = weighted_ensemble_df.keys()\n",
    "best_hit = 0\n",
    "\n",
    "for combination_count in tqdm(range(2, 8)):\n",
    "    cols_list = list(map(lambda x: list(x), list(combinations(target_cols, combination_count))))\n",
    "    for cols in cols_list:\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "            df = df.fillna(df[cols].min().min())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = False)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        print(f'cols : {cols}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "        if best_hit < HIT:\n",
    "            best_combinations = cols\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "    print(f'BEST cols : {best_combinations}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f}')\n",
    "\n",
    "print(f'Final BEST cols : {best_combinations}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-6. serch_best_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['MultiDAE_rec_score']\n",
    "weightes_list = [np.round(0.05 * i, 2) for i in range(20, 0, -1)]\n",
    "cols = ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score']\n",
    "weightes = [1.0, 0.6, 0.8]\n",
    "users = weighted_ensemble_df.keys()\n",
    "for target_col in target_cols:\n",
    "    cols += [target_col]\n",
    "    best_hit = 0\n",
    "    best_weightes = deepcopy(weightes)\n",
    "\n",
    "    for target_weighte in tqdm(weightes_list):\n",
    "        _weightes = [target_weighte, 0.6, 0.8, 0.3]\n",
    "\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "\n",
    "            for c, w in zip(cols, _weightes):\n",
    "                df[c] = df[c] * w\n",
    "            \n",
    "            df = df.fillna(df[cols].min().min())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = False)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        if best_hit < HIT:\n",
    "            best_weightes = deepcopy(_weightes)\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "        print(f'cols : {cols}| weighte : {_weightes}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "    weightes = deepcopy(best_weightes)\n",
    "    print(f'BEST cols : {cols}| weighte : {weightes}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f} \\n')\n",
    "\n",
    "print(f'cols : {cols}| weighte : {weightes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능이 좋아지지 않음 차라리 1/log2(rank + 1) 방법에 모델 튜닝 순서를 바꿔보는 것이 더 나은 방법일 수도 있을 것 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-7. weighted_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_evaluate(AdmmSlim, HOSLIM, RecVAE, MultiDAE, X, user_train, user_valid, candidate_cnt):\n",
    "    NDCG = 0\n",
    "    HIT = 0\n",
    "    \n",
    "    RecVAE.eval()\n",
    "    # MultiVAE.eval()\n",
    "    MultiDAE.eval()\n",
    "    # AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    # User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    # Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    # MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    # MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    # MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    # AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    # AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (HOSLIM_rec, AdmmSlim_rec, RecVAE_rec, MultiDAE_rec) in tqdm(enumerate(zip(HOSLIM_rec_list, AdmmSlim_rec_list, RecVAE_rec_list, MultiDAE_rec_list))):\n",
    "        \n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(HOSLIM_rec + AdmmSlim_rec + RecVAE_rec + MultiDAE_rec))\n",
    "\n",
    "        rec_df = pd.DataFrame(index = all_rec)\n",
    "        rec_df.loc[HOSLIM_rec, 'HOSLIM_rec_score'] = score_li * 1.0\n",
    "        # rec_df.loc[User_EASE_rec, 'User_EASE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[Item_EASE_rec, 'Item_EASE_rec_score'] = score_li * 0.3\n",
    "        rec_df.loc[AdmmSlim_rec, 'AdmmSlim_rec_score'] = score_li * 0.6\n",
    "        rec_df.loc[RecVAE_rec, 'RecVAE_rec_score'] = score_li * 0.8\n",
    "        # rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li * 0.3\n",
    "        rec_df.loc[MultiDAE_rec, 'MultiDAE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[AutoRec_rec, 'AutoRec_rec_score'] = score_li\n",
    "        rec_df = rec_df.fillna(rec_df.min().min())\n",
    "\n",
    "        rec_df['total_rec_score'] = rec_df.sum(axis = 1)\n",
    "        rec_df = rec_df.sort_values('total_rec_score', ascending = False)\n",
    "        up = rec_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(5, 11)]:\n",
    "    \n",
    "    ndcg, hit = weighted_evaluate(\n",
    "        # User_EASE = user_ease, \n",
    "        # Item_EASE = item_ease, \n",
    "        AdmmSlim = admm_slim, \n",
    "        HOSLIM = hoslim,\n",
    "        RecVAE = rec_vae, \n",
    "        # MultiVAE = multi_vae, \n",
    "        MultiDAE = multi_dae, \n",
    "        # AutoRec = auto_rec,\n",
    "        X = X.todense(), \n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid,\n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cols : ['HOSLIM_rec_score', 'User_EASE_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "weighte : [1.0, 0.3, 0.7, 1.0, 0.5, 0.3]| NDCG@10: 0.32325| HIT@10: 0.21271\n",
    "\n",
    "candidate_cnt: 25| NDCG@10: 0.32312| HIT@10: 0.21251\n",
    "candidate_cnt: 30| NDCG@10: 0.32325| HIT@10: 0.21271\n",
    "candidate_cnt: 35| NDCG@10: 0.32319| HIT@10: 0.21263\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cols : ['HOSLIM_rec_score', 'AdmmSlim_rec_score', 'RecVAE_rec_score', 'MultiDAE_rec_score']| \n",
    "weighte : [1.0, 0.6, 0.8, 0.3]| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.32052| HIT@10: 0.20994\n",
    "candidate_cnt: 15| NDCG@10: 0.32192| HIT@10: 0.21139\n",
    "candidate_cnt: 20| NDCG@10: 0.32269| HIT@10: 0.21230\n",
    "candidate_cnt: 25| NDCG@10: 0.32282| HIT@10: 0.21252\n",
    "candidate_cnt: 30| NDCG@10: 0.32295| HIT@10: 0.21271\n",
    "candidate_cnt: 35| NDCG@10: 0.32293| HIT@10: 0.21271\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "candidate_cnt: 10| NDCG@10: 0.32002| HIT@10: 0.20909\n",
    "candidate_cnt: 15| NDCG@10: 0.32166| HIT@10: 0.21102\n",
    "candidate_cnt: 20| NDCG@10: 0.32212| HIT@10: 0.21153\n",
    "candidate_cnt: 25| NDCG@10: 0.32225| HIT@10: 0.21174\n",
    "candidate_cnt: 30| NDCG@10: 0.32243| HIT@10: 0.21200\n",
    "candidate_cnt: 35| NDCG@10: 0.32231| HIT@10: 0.21187\n",
    "candidate_cnt: 40| NDCG@10: 0.32231| HIT@10: 0.21193\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:33, 204.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.32229| HIT@10: 0.21208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 30\n",
    "\n",
    "ndcg, hit = weighted_evaluate(\n",
    "    # User_EASE = user_ease, \n",
    "    # Item_EASE = item_ease, \n",
    "    AdmmSlim = admm_slim, \n",
    "    HOSLIM = hoslim,\n",
    "    RecVAE = rec_vae, \n",
    "    # MultiVAE = multi_vae, \n",
    "    MultiDAE = multi_dae, \n",
    "    # AutoRec = auto_rec,\n",
    "    X = X.todense(), \n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid,\n",
    "    candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(HOSLIM, User_EASE, AdmmSlim, RecVAE, MultiVAE, MultiDAE, X, candidate_cnt):\n",
    "    \n",
    "    user2rec = {}\n",
    "\n",
    "    RecVAE.eval()\n",
    "    MultiVAE.eval()\n",
    "    MultiDAE.eval()\n",
    "    # AutoRec.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    HOSLIM_recon_mat = HOSLIM.pred.cpu()\n",
    "    HOSLIM_recon_mat[mat == 1] = -np.inf\n",
    "    HOSLIM_rec_list = HOSLIM_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    User_EASE_recon_mat = User_EASE.pred.cpu()\n",
    "    User_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    User_EASE_rec_list = User_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    AdmmSlim_recon_mat = AdmmSlim.pred.cpu()\n",
    "    AdmmSlim_recon_mat[mat == 1] = -np.inf\n",
    "    AdmmSlim_rec_list = AdmmSlim_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # Item_EASE_recon_mat = Item_EASE.pred.T.cpu()\n",
    "    # Item_EASE_recon_mat[mat == 1] = -np.inf\n",
    "    # Item_EASE_rec_list = Item_EASE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    RecVAE_recon_mat = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    RecVAE_recon_mat[mat == 1] = -np.inf\n",
    "    RecVAE_rec_list = RecVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiVAE_recon_mat, _, _ = MultiVAE(mat.to(device))\n",
    "    MultiVAE_recon_mat = MultiVAE_recon_mat.cpu().detach()\n",
    "    MultiVAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiVAE_rec_list = MultiVAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    MultiDAE_recon_mat = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    MultiDAE_recon_mat[mat == 1] = -np.inf\n",
    "    MultiDAE_rec_list = MultiDAE_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    # AutoRec_recon_mat = AutoRec(mat.to(device)).cpu().detach()\n",
    "    # AutoRec_recon_mat[mat == 1] = -np.inf\n",
    "    # AutoRec_rec_list = AutoRec_recon_mat.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (HOSLIM_rec, User_EASE_rec, AdmmSlim_rec, RecVAE_rec, MultiVAE_rec, MultiDAE_rec) in tqdm(enumerate(zip(HOSLIM_rec_list, User_EASE_rec_list, AdmmSlim_rec_list, RecVAE_rec_list, MultiVAE_rec_list, MultiDAE_rec_list))):\n",
    "\n",
    "        # ranking\n",
    "        HOSLIM_rec = HOSLIM_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        User_EASE_rec = User_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # Item_EASE_rec = Item_EASE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        AdmmSlim_rec = AdmmSlim_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        RecVAE_rec = RecVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiVAE_rec = MultiVAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        MultiDAE_rec = MultiDAE_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        # AutoRec_rec = AutoRec_rec[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        all_rec = list(set(HOSLIM_rec + User_EASE_rec + AdmmSlim_rec + RecVAE_rec + MultiVAE_rec + MultiDAE_rec))\n",
    "\n",
    "        rec_df = pd.DataFrame(index = all_rec)\n",
    "        rec_df.loc[HOSLIM_rec, 'HOSLIM_rec_score'] = score_li * 1.0\n",
    "        rec_df.loc[User_EASE_rec, 'User_EASE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[Item_EASE_rec, 'Item_EASE_rec_score'] = score_li * 0.3\n",
    "        rec_df.loc[AdmmSlim_rec, 'AdmmSlim_rec_score'] = score_li * 0.7\n",
    "        rec_df.loc[RecVAE_rec, 'RecVAE_rec_score'] = score_li * 1.0\n",
    "        rec_df.loc[MultiVAE_rec, 'MultiVAE_rec_score'] = score_li * 0.5\n",
    "        rec_df.loc[MultiDAE_rec, 'MultiDAE_rec_score'] = score_li * 0.3\n",
    "        # rec_df.loc[AutoRec_rec, 'AutoRec_rec_score'] = score_li\n",
    "        rec_df = rec_df.fillna(min(score_li * 0.3))\n",
    "\n",
    "        rec_df['total_rec_score'] = rec_df['HOSLIM_rec_score'] + rec_df['User_EASE_rec_score'] + rec_df['AdmmSlim_rec_score'] + rec_df['RecVAE_rec_score'] + rec_df['MultiVAE_rec_score'] + rec_df['MultiDAE_rec_score']\n",
    "        rec_df = rec_df.sort_values('total_rec_score', ascending = False)\n",
    "        up = rec_df.index.tolist()[:10]\n",
    "\n",
    "        user2rec[user] = up\n",
    "\n",
    "    return user2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoslim = HOSLIM(threshold = 3500, lambdaBB = 500, lambdaCC = 15000, rho = 10000)\n",
    "hoslim.fit(X = X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "admm_slim = AdmmSlim(lambda_1 = 10, lambda_2 = 5, rho = 1000)\n",
    "admm_slim.fit(X = X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ease = EASE(X = X_test, reg = 680)\n",
    "user_ease.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ease = EASE(X = X_test.T, reg = 4400)\n",
    "item_ease.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_vae = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "rec_vae.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v7.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_rec = AutoRec(\n",
    "#     num = make_matrix_data_set.num_item, \n",
    "#     num_factor = 64).to(device)\n",
    "\n",
    "# auto_rec.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dae = MultiDAE(\n",
    "    p_dims = [200, 600] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "multi_dae.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_vae = MultiVAE(\n",
    "    p_dims = [200, 600] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.7).to(device)\n",
    "\n",
    "multi_vae.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v4.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:55, 178.44it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    User_EASE = user_ease, \n",
    "    # Item_EASE = item_ease, \n",
    "    AdmmSlim = admm_slim, \n",
    "    HOSLIM = hoslim, \n",
    "    RecVAE = rec_vae, \n",
    "    MultiVAE = multi_vae, \n",
    "    MultiDAE = multi_dae, \n",
    "    # AutoRec = auto_rec, \n",
    "    X = X_test.todense(), \n",
    "    candidate_cnt = 30)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>32587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>2762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11   4886\n",
       "2           11  40815\n",
       "3           11   8961\n",
       "4           11   7373\n",
       "...        ...    ...\n",
       "313595  138493    110\n",
       "313596  138493   5349\n",
       "313597  138493   8970\n",
       "313598  138493  32587\n",
       "313599  138493   2762\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과거-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']\n",
    "[1.0, 0.6, 0.8, 0.7, 1.0]\n",
    "```\n",
    "\n",
    "```\n",
    "['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score'] \n",
    "[1.0, 0.8, 0.9, 1.0, 1.0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model1, model2, model3, model4, RecVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    NDCG = 0.0 # NDCG@10\n",
    "    HIT = 0.0 # HIT@10\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = model3.pred.cpu()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = model4.pred.cpu()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li * 0.6\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li * 0.7\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li * 0.8\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li * 1.0\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li * 1.0\n",
    "        movie_df = movie_df.fillna(min(score_li * 0.6))\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "        HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(user_train)\n",
    "    HIT /= len(user_train)\n",
    "\n",
    "    return NDCG, HIT\n",
    "\n",
    "def predict(model1, model2, model3, model4, RecVAE, X, candidate_cnt):\n",
    "    user2rec = {}\n",
    "\n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = model3.pred.cpu()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = model4.pred.cpu()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5))):\n",
    "        \n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li * 0.6\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li * 0.7\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li * 0.8\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li * 1.0\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li * 1.0\n",
    "        movie_df = movie_df.fillna(min(score_li * 0.6))\n",
    "        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score']\n",
    "        movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "        up = movie_df.index.tolist()[:10]\n",
    "\n",
    "        user2rec[user] = up\n",
    "\n",
    "    return user2rec\n",
    "\n",
    "\n",
    "def total_evaluate(model1, model2, model3, model4, RecVAE, X, user_train, user_valid, candidate_cnt):\n",
    "    df = []\n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = model3.pred.cpu()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = model4.pred.cpu()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5))):\n",
    "        uv = user_valid[user]\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        rec12345 = list(set(rec1 + rec2 + rec3 + rec4 + rec5))\n",
    "\n",
    "        df.append(\n",
    "            {\n",
    "               'user' : user,\n",
    "               'len' : len(rec12345),\n",
    "\n",
    "               'rec1' : get_hit(pred_list = rec1, true_list = uv),\n",
    "               'rec2' : get_hit(pred_list = rec2, true_list = uv),\n",
    "               'rec3' : get_hit(pred_list = rec3, true_list = uv),\n",
    "               'rec4' : get_hit(pred_list = rec4, true_list = uv),\n",
    "               'rec5' : get_hit(pred_list = rec5, true_list = uv),\n",
    "\n",
    "               'rec12345' : get_hit(pred_list = rec12345, true_list = uv),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gupkaJHMslCi"
   },
   "source": [
    "## 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdmmSlim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000022vscode-remote?line=0'>1</a>\u001b[0m model3 \u001b[39m=\u001b[39m AdmmSlim(lambda_2 \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, rho \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000022vscode-remote?line=1'>2</a>\u001b[0m model3\u001b[39m.\u001b[39mfit(X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mtoarray())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdmmSlim' is not defined"
     ]
    }
   ],
   "source": [
    "model3 = AdmmSlim(lambda_2 = 1, rho = 1000)\n",
    "model3.fit(X = X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = HOSLIM()\n",
    "model4.fit(X = X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [00:01, 23357.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df = total_evaluate(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    model3 = model3, \n",
    "    model4 = model4, \n",
    "    RecVAE = model5,\n",
    "    X = X.todense(), \n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid, \n",
    "    candidate_cnt = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>len</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec12345</th>\n",
       "      <th>total_val</th>\n",
       "      <th>total_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rec3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>31355</td>\n",
       "      <td>14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>31356</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>31357</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>31358</td>\n",
       "      <td>19</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>31359</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  len  rec1  rec2  rec3  rec4  rec5  rec12345  total_val  \\\n",
       "0          0   19   0.3   0.3   0.3   0.3   0.2       0.5        0.3   \n",
       "1          1   16   0.1   0.1   0.1   0.1   0.2       0.2        0.2   \n",
       "2          2   14   0.3   0.3   0.3   0.3   0.3       0.3        0.3   \n",
       "3          3   15   0.3   0.3   0.4   0.3   0.2       0.4        0.4   \n",
       "4          4   20   0.4   0.3   0.5   0.4   0.4       0.6        0.5   \n",
       "...      ...  ...   ...   ...   ...   ...   ...       ...        ...   \n",
       "31355  31355   14   0.2   0.4   0.3   0.3   0.2       0.4        0.4   \n",
       "31356  31356   19   0.3   0.3   0.2   0.3   0.3       0.4        0.3   \n",
       "31357  31357   15   0.2   0.3   0.2   0.2   0.2       0.3        0.3   \n",
       "31358  31358   19   0.1   0.1   0.1   0.1   0.0       0.1        0.1   \n",
       "31359  31359   23   0.0   0.2   0.0   0.0   0.1       0.2        0.2   \n",
       "\n",
       "      total_name  \n",
       "0           rec1  \n",
       "1           rec5  \n",
       "2           rec1  \n",
       "3           rec3  \n",
       "4           rec3  \n",
       "...          ...  \n",
       "31355       rec2  \n",
       "31356       rec1  \n",
       "31357       rec2  \n",
       "31358       rec1  \n",
       "31359       rec2  \n",
       "\n",
       "[31360 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저들 마다 rec1 or rec2 or rec3 or ranking 등 맞는 방법에 따라사 추천을 해주는 것도 좋은 방법이 될 수 있음\n",
    "\n",
    "new_df = pd.DataFrame(df)\n",
    "\n",
    "def get_total_name(x):\n",
    "    val_list = [x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5']]\n",
    "    max_val = max(val_list)\n",
    "    val_idx = val_list.index(max_val)\n",
    "    if val_idx == 0 : return 'rec1'\n",
    "    elif val_idx == 1 : return 'rec2'\n",
    "    elif val_idx == 2 : return 'rec3'\n",
    "    elif val_idx == 3 : return 'rec4'\n",
    "    elif val_idx == 4 : return 'rec5'\n",
    "\n",
    "new_df['total_val'] = new_df.apply(lambda x: max(x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5']), axis = 1)\n",
    "new_df['total_name'] = new_df.apply(lambda x: get_total_name(x), axis = 1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.histplot(data = new_df[[\"rec1\", \"rec2\", \"rec3\", \"rec4\", \"rec5\", 'rec12345', 'total_val']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec1    17836\n",
       "rec2     4347\n",
       "rec5     4094\n",
       "rec3     3845\n",
       "rec4     1238\n",
       "Name: total_name, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['total_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         15679.500000\n",
       "len             18.487372\n",
       "rec1             0.203839\n",
       "rec2             0.200207\n",
       "rec3             0.200236\n",
       "rec4             0.204426\n",
       "rec5             0.192140\n",
       "rec12345         0.282586\n",
       "total_val        0.254110\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:35, 201.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 35| NDCG@10: 0.32099| HIT@10: 0.21087\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 35\n",
    "\n",
    "ndcg, hit = evaluate(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    model3 = model3, \n",
    "    model4 = model4, \n",
    "    RecVAE = model5, \n",
    "    X = X.todense(),\n",
    "    user_train = user_train, \n",
    "    user_valid = user_valid, \n",
    "    candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:34, 203.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.31945| HIT@10: 0.20952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:34, 202.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 15| NDCG@10: 0.31997| HIT@10: 0.21003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:38, 198.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 20| NDCG@10: 0.32015| HIT@10: 0.21019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:35, 202.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 25| NDCG@10: 0.32026| HIT@10: 0.21032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:37, 199.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.32039| HIT@10: 0.21046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:36, 200.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 35| NDCG@10: 0.32034| HIT@10: 0.21040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:37, 198.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 40| NDCG@10: 0.32030| HIT@10: 0.21037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:39, 196.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 45| NDCG@10: 0.32035| HIT@10: 0.21041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:40, 195.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 50| NDCG@10: 0.32036| HIT@10: 0.21044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:42, 193.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 55| NDCG@10: 0.32036| HIT@10: 0.21043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:46, 188.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 60| NDCG@10: 0.32035| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:45, 188.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 65| NDCG@10: 0.32035| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:53, 180.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 70| NDCG@10: 0.32036| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:53, 181.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 75| NDCG@10: 0.32034| HIT@10: 0.21039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:52, 181.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 80| NDCG@10: 0.32036| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:56, 178.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 85| NDCG@10: 0.32037| HIT@10: 0.21044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:58, 175.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 90| NDCG@10: 0.32036| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [03:02, 172.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 95| NDCG@10: 0.32036| HIT@10: 0.21042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:59, 174.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 100| NDCG@10: 0.32037| HIT@10: 0.21043\n"
     ]
    }
   ],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "        model1 = model1,\n",
    "        model2 = model2,\n",
    "        model3 = model3,\n",
    "        model4 = model4,\n",
    "        RecVAE = model5,\n",
    "        X = X.todense(),\n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid, \n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:33, 204.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.31989| HIT@10: 0.20949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:33, 203.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 15| NDCG@10: 0.32088| HIT@10: 0.21066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:34, 203.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 20| NDCG@10: 0.32105| HIT@10: 0.21084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:35, 202.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 25| NDCG@10: 0.32116| HIT@10: 0.21093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:36, 200.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.32117| HIT@10: 0.21099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:36, 199.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 35| NDCG@10: 0.32121| HIT@10: 0.21105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:37, 198.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 40| NDCG@10: 0.32112| HIT@10: 0.21095\n"
     ]
    }
   ],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "        model1 = model1,\n",
    "        model2 = model2,\n",
    "        model3 = model3,\n",
    "        model4 = model4,\n",
    "        RecVAE = model5,\n",
    "        X = X.todense(),\n",
    "        user_train = user_train, \n",
    "        user_valid = user_valid, \n",
    "        candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_ensemble_df(model1, model2, model3, model4, RecVAE, X, candidate_cnt):\n",
    "    weighted_ensemble_df = {}\n",
    "    \n",
    "    RecVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = model3.pred.cpu()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = model4.pred.cpu()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5))):\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li\n",
    "\n",
    "        weighted_ensemble_df[user] = movie_df\n",
    "\n",
    "    return weighted_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [01:48, 289.47it/s]\n"
     ]
    }
   ],
   "source": [
    "weighted_ensemble_df = get_weighted_ensemble_df(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    model3 = model3, \n",
    "    model4 = model4, \n",
    "    RecVAE = model5, \n",
    "    X = X.todense(),\n",
    "    candidate_cnt = 10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [02:09<40:56, 129.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 1.0]| NDCG@10: 0.31945| HIT@10: 0.20952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [04:16<38:24, 128.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 0.95]| NDCG@10: 0.31928| HIT@10: 0.20942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [06:24<36:15, 127.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 0.9]| NDCG@10: 0.31908| HIT@10: 0.20929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [08:31<34:01, 127.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 0.85]| NDCG@10: 0.31873| HIT@10: 0.20901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [10:38<31:52, 127.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols : ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score', 'rec5_score']| weighte : [1.0, 0.8, 0.9, 1.0, 0.8]| NDCG@10: 0.31839| HIT@10: 0.20870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [10:45<32:15, 129.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=26'>27</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39mtotal_score\u001b[39m\u001b[39m'\u001b[39m, ascending \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=27'>28</a>\u001b[0m     up \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mtolist()[:\u001b[39m10\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=29'>30</a>\u001b[0m     NDCG \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m get_ndcg(pred_list \u001b[39m=\u001b[39;49m up, true_list \u001b[39m=\u001b[39;49m uv)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=30'>31</a>\u001b[0m     HIT \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m get_hit(pred_list \u001b[39m=\u001b[39m up, true_list \u001b[39m=\u001b[39m uv)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000034vscode-remote?line=32'>33</a>\u001b[0m NDCG \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(users)\n",
      "\u001b[1;32m/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb Cell 16'\u001b[0m in \u001b[0;36mget_ndcg\u001b[0;34m(pred_list, true_list)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000015vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_ndcg\u001b[39m(pred_list, true_list):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000015vscode-remote?line=1'>2</a>\u001b[0m     idcg \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m((\u001b[39m1\u001b[39;49m \u001b[39m/\u001b[39;49m np\u001b[39m.\u001b[39;49mlog2(rank \u001b[39m+\u001b[39;49m \u001b[39m2\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m rank \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(pred_list))))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000015vscode-remote?line=2'>3</a>\u001b[0m     dcg \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.67/opt/ml/level2-movie-recommendation-level2-recsys-05/jupyter/Ensembel.ipynb#ch0000015vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m rank, pred \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pred_list):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target_cols = ['rec5_score']\n",
    "weightes_list = [np.round(0.05 * i, 2) for i in range(20, 0, -1)]\n",
    "cols = ['rec4_score', 'rec1_score', 'rec3_score', 'rec2_score']\n",
    "weightes = [1.0, 0.8, 0.9, 1.0]\n",
    "users = weighted_ensemble_df.keys()\n",
    "for target_col in target_cols:\n",
    "    cols += [target_col]\n",
    "    best_hit = 0\n",
    "    best_weightes = deepcopy(weightes)\n",
    "\n",
    "    for target_weighte in tqdm(weightes_list):\n",
    "        _weightes = deepcopy(weightes)\n",
    "        _weightes += [target_weighte]\n",
    "\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "\n",
    "            for c, w in zip(cols, _weightes):\n",
    "                df[c] = df[c] * w\n",
    "            \n",
    "            df = df.fillna(df[cols].min().min())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = False)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        if best_hit < HIT:\n",
    "            best_weightes = deepcopy(_weightes)\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "        print(f'cols : {cols}| weighte : {_weightes}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "    weightes = deepcopy(best_weightes)\n",
    "    print(f'BEST cols : {cols}| weighte : {weightes}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f} \\n')\n",
    "\n",
    "print(f'cols : {cols}| weighte : {weightes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X_test, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X_test.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = AdmmSlim(lambda_2 = 1, rho = 1000)\n",
    "model3.fit(X = X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = HOSLIM(threshold = 3500, lambdaBB = 500, lambdaCC = 10000, rho = 100000)\n",
    "model4.fit(X = X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:36, 200.20it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    model1 = model1, \n",
    "    model2 = model2, \n",
    "    model3 = model3, \n",
    "    model4 = model4, \n",
    "    RecVAE = model5, \n",
    "    X = X_test.todense(),\n",
    "    candidate_cnt = 35,)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>27660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11  40815\n",
       "2           11   4886\n",
       "3           11   8961\n",
       "4           11   7373\n",
       "...        ...    ...\n",
       "313595  138493  27660\n",
       "313596  138493    110\n",
       "313597  138493  53125\n",
       "313598  138493   8970\n",
       "313599  138493   1022\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nws4JO2_rgQP"
   },
   "outputs": [],
   "source": [
    "# def evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     NDCG = 0.0 # NDCG@10\n",
    "#     HIT = 0.0 # HIT@10\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "#     score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         # ranking\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[rec1, 'rec1_score'] = score_li * 1.0\n",
    "#         movie_df.loc[rec2, 'rec2_score'] = score_li * 0.4\n",
    "#         movie_df.loc[rec3, 'rec3_score'] = score_li * 0.6\n",
    "#         movie_df.loc[rec4, 'rec4_score'] = score_li * 0.1\n",
    "#         movie_df.loc[rec5, 'rec5_score'] = score_li * 0.3\n",
    "#         movie_df.loc[rec6, 'rec6_score'] = score_li * 0.2\n",
    "#         movie_df = movie_df.fillna(min(score_li) * 0.1)\n",
    "#         movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score'] + movie_df['rec6_score']\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "#         HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "#     NDCG /= len(user_train)\n",
    "#     HIT /= len(user_train)\n",
    "\n",
    "#     return NDCG, HIT\n",
    "\n",
    "# def predict(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, candidate_cnt):\n",
    "#     user2rec = {}\n",
    "\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "#     score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "        \n",
    "#         # ranking\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[rec1, 'rec1_score'] = score_li * 1.0\n",
    "#         movie_df.loc[rec2, 'rec2_score'] = score_li * 0.4\n",
    "#         movie_df.loc[rec3, 'rec3_score'] = score_li * 0.6\n",
    "#         movie_df.loc[rec4, 'rec4_score'] = score_li * 0.1\n",
    "#         movie_df.loc[rec5, 'rec5_score'] = score_li * 0.3\n",
    "#         movie_df.loc[rec6, 'rec6_score'] = score_li * 0.2\n",
    "#         movie_df = movie_df.fillna(min(score_li) * 0.1)\n",
    "#         movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score'] + movie_df['rec4_score'] + movie_df['rec5_score'] + movie_df['rec6_score']\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         user2rec[user] = up\n",
    "\n",
    "#     return user2rec\n",
    "\n",
    "\n",
    "# def total_evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     df = []\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         # ranking\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         rec123456 = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "#         df.append(\n",
    "#             {\n",
    "#                'user' : user,\n",
    "#                'len' : len(rec123456),\n",
    "\n",
    "#                'rec1' : get_hit(pred_list = rec1, true_list = uv),\n",
    "#                'rec2' : get_hit(pred_list = rec2, true_list = uv),\n",
    "#                'rec3' : get_hit(pred_list = rec3, true_list = uv),\n",
    "#                'rec4' : get_hit(pred_list = rec4, true_list = uv),\n",
    "#                'rec5' : get_hit(pred_list = rec5, true_list = uv),\n",
    "#                'rec6' : get_hit(pred_list = rec6, true_list = uv),\n",
    "\n",
    "#                'rec123456' : get_hit(pred_list = rec123456, true_list = uv),\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# def evaluate(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X_df, y_df, X, user_train, user_valid, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "#     AutoRec.eval()\n",
    "#     MultiDAE.eval()\n",
    "#     MultiVAE.eval()\n",
    "\n",
    "#     mat = torch.from_numpy(X)\n",
    "\n",
    "#     NDCG = 0.0 # NDCG@10\n",
    "#     HIT = 0.0 # HIT@10\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     copy_recon_mat1 = deepcopy(recon_mat1.sigmoid())\n",
    "#     recon_mat1[mat == 1] = -np.inf\n",
    "#     rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     copy_recon_mat2 = deepcopy(recon_mat2.sigmoid())\n",
    "#     recon_mat2[mat == 1] = -np.inf\n",
    "#     rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "#     copy_recon_mat3 = deepcopy(recon_mat3.sigmoid())\n",
    "#     recon_mat3[mat == 1] = -np.inf\n",
    "#     rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "#     copy_recon_mat4 = deepcopy(recon_mat4.sigmoid())\n",
    "#     recon_mat4[mat == 1] = -np.inf\n",
    "#     rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "#     copy_recon_mat5 = deepcopy(recon_mat5.sigmoid())\n",
    "#     recon_mat5[mat == 1] = -np.inf\n",
    "#     rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "#     recon_mat6 = recon_mat6.cpu().detach()\n",
    "#     copy_recon_mat6 = deepcopy(recon_mat6.sigmoid())\n",
    "#     recon_mat6[mat == 1] = -np.inf\n",
    "#     rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "\n",
    "#     for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "\n",
    "#         cif = DecisionTreeClassifier(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         uv = user_valid[user]\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "#         score_li = np.array([[copy_recon_mat1.numpy()[user][item], copy_recon_mat2.numpy()[user][item], copy_recon_mat3.numpy()[user][item] , copy_recon_mat4.numpy()[user][item] , copy_recon_mat5.numpy()[user][item] , copy_recon_mat6.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "\n",
    "#         NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "#         HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "#     NDCG /= len(user_train)\n",
    "#     HIT /= len(user_train)\n",
    "\n",
    "#     return NDCG, HIT\n",
    "\n",
    "\n",
    "# def predict(model1, model2, RecVAE, X_df, y_df, X, candidate_cnt):\n",
    "#     RecVAE.eval()\n",
    "\n",
    "#     user2rec = {}\n",
    "\n",
    "#     neg = torch.from_numpy(1 - X)\n",
    "#     pos = torch.from_numpy(X)\n",
    "\n",
    "#     recon_mat1 = model1.pred.cpu()\n",
    "#     score1 = recon_mat1 * neg\n",
    "#     rec_list1 = score1.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat2 = model2.pred.T.cpu()\n",
    "#     score2 = recon_mat2 * neg\n",
    "#     rec_list2 = score2.argsort(dim = 1)\n",
    "\n",
    "#     recon_mat3 = RecVAE(pos.to(device), calculate_loss = False).cpu().detach()\n",
    "#     score3 = recon_mat3 * neg\n",
    "#     rec_list3 = score3.argsort(dim = 1)\n",
    "\n",
    "#     for user, (rec1, rec2, rec3) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3))):\n",
    "\n",
    "#         cif = LogisticRegression(random_state = config.seed).fit(X_df[6807 * user : 6807 * (user + 1), 1:], y_df[6807 * user : 6807 * (user + 1)])\n",
    "\n",
    "#         rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "#         rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "#         items = list(set(rec1 + rec2 + rec3))\n",
    "#         score_li = np.array([[recon_mat1.numpy()[user][item], recon_mat2.numpy()[user][item], recon_mat3.numpy()[user][item]] for item in items])\n",
    "#         score_li = cif.predict_proba(score_li)[:, 1]\n",
    "        \n",
    "#         movie_df = pd.DataFrame(index = items)\n",
    "#         movie_df.loc[items, 'total_score'] = score_li\n",
    "#         movie_df = movie_df.sort_values('total_score', ascending = False)\n",
    "#         up = movie_df.index.tolist()[:10]\n",
    "        \n",
    "#         user2rec[user] = up\n",
    "\n",
    "#     return user2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
    "X = make_matrix_data_set.make_sparse_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "model4.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = MultiDAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = MultiVAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model6.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_ensemble_df(model1, model2, RecVAE, AutoRec, MultiDAE, MultiVAE, X, candidate_cnt):\n",
    "    weighted_ensemble_df = {}\n",
    "    \n",
    "    RecVAE.eval()\n",
    "    AutoRec.eval()\n",
    "    MultiDAE.eval()\n",
    "    MultiVAE.eval()\n",
    "\n",
    "    mat = torch.from_numpy(X)\n",
    "\n",
    "    recon_mat1 = model1.pred.cpu()\n",
    "    recon_mat1[mat == 1] = -np.inf\n",
    "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
    "\n",
    "    recon_mat2 = model2.pred.T.cpu()\n",
    "    recon_mat2[mat == 1] = -np.inf\n",
    "    rec_list2 = recon_mat2.argsort(dim = 1)\n",
    "\n",
    "    recon_mat3 = RecVAE(mat.to(device), calculate_loss = False).cpu().detach()\n",
    "    recon_mat3[mat == 1] = -np.inf\n",
    "    rec_list3 = recon_mat3.argsort(dim = 1)\n",
    "\n",
    "    recon_mat4 = AutoRec(mat.to(device)).cpu().detach()\n",
    "    recon_mat4[mat == 1] = -np.inf\n",
    "    rec_list4 = recon_mat4.argsort(dim = 1)\n",
    "\n",
    "    recon_mat5 = MultiDAE(mat.to(device)).cpu().detach()\n",
    "    recon_mat5[mat == 1] = -np.inf\n",
    "    rec_list5 = recon_mat5.argsort(dim = 1)\n",
    "\n",
    "    recon_mat6, mu, logvar = MultiVAE(mat.to(device))\n",
    "    recon_mat6 = recon_mat6.cpu().detach()\n",
    "    recon_mat6[mat == 1] = -np.inf\n",
    "    rec_list6 = recon_mat6.argsort(dim = 1)\n",
    "\n",
    "    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n",
    "\n",
    "    for user, (rec1, rec2, rec3, rec4, rec5, rec6) in tqdm(enumerate(zip(rec_list1, rec_list2, rec_list3, rec_list4, rec_list5, rec_list6))):\n",
    "\n",
    "        # ranking\n",
    "        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec4 = rec4[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec5 = rec5[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "        rec6 = rec6[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n",
    "\n",
    "        items = list(set(rec1 + rec2 + rec3 + rec4 + rec5 + rec6))\n",
    "\n",
    "        movie_df = pd.DataFrame(index = items)\n",
    "        movie_df.loc[rec1, 'rec1_score'] = score_li\n",
    "        movie_df.loc[rec2, 'rec2_score'] = score_li\n",
    "        movie_df.loc[rec3, 'rec3_score'] = score_li\n",
    "        movie_df.loc[rec4, 'rec4_score'] = score_li\n",
    "        movie_df.loc[rec5, 'rec5_score'] = score_li\n",
    "        movie_df.loc[rec6, 'rec6_score'] = score_li\n",
    "\n",
    "        weighted_ensemble_df[user] = movie_df\n",
    "\n",
    "    return weighted_ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:11, 237.93it/s]\n"
     ]
    }
   ],
   "source": [
    "weighted_ensemble_df = get_weighted_ensemble_df(\n",
    "    model1 = model1,\n",
    "    model2 = model2,\n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4,\n",
    "    MultiDAE = model5,\n",
    "    MultiVAE = model6,\n",
    "    X = X.todense(),\n",
    "    candidate_cnt = 30,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['rec5_score']\n",
    "weightes_list = [np.round(0.05 * i, 2) for i in range(6, 0, -1)]\n",
    "cols = ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']\n",
    "weightes = [1.0, 0.45, 0.85, 0.25]\n",
    "users = weighted_ensemble_df.keys()\n",
    "for target_col in target_cols:\n",
    "    cols += [target_col]\n",
    "    best_hit = 0\n",
    "    best_weightes = deepcopy(weightes)\n",
    "\n",
    "    for target_weighte in tqdm(weightes_list):\n",
    "        _weightes = deepcopy(weightes)\n",
    "        _weightes += [target_weighte]\n",
    "\n",
    "        NDCG = 0\n",
    "        HIT = 0\n",
    "\n",
    "        for user in users:\n",
    "            uv = user_valid[user]\n",
    "            df = weighted_ensemble_df[user].copy()\n",
    "\n",
    "            for c, w in zip(cols, _weightes):\n",
    "                df[c] = df[c] * w\n",
    "            \n",
    "            df = df.fillna(df[cols].min().min())\n",
    "            df['total_score'] = df[cols].sum(axis = 1)\n",
    "            df = df.sort_values('total_score', ascending = False)\n",
    "            up = df.index.tolist()[:10]\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "        NDCG /= len(users)\n",
    "        HIT /= len(users)\n",
    "        \n",
    "        if best_hit < HIT:\n",
    "            best_weightes = deepcopy(_weightes)\n",
    "            best_hit = HIT\n",
    "            best_ndcg = NDCG\n",
    "\n",
    "        print(f'cols : {cols}| weighte : {_weightes}| NDCG@10: {NDCG:.5f}| HIT@10: {HIT:.5f}')\n",
    "\n",
    "    weightes = deepcopy(best_weightes)\n",
    "    print(f'BEST cols : {cols}| weighte : {weightes}| NDCG@10: {best_ndcg:.5f}| HIT@10: {best_hit:.5f} \\n')\n",
    "\n",
    "print(f'cols : {cols}| weighte : {weightes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 1.0]| NDCG@10: 0.31060| HIT@10: 0.20423\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.95]| NDCG@10: 0.31082| HIT@10: 0.20423\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.9]| NDCG@10: 0.31086| HIT@10: 0.20416\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.85]| NDCG@10: 0.31099| HIT@10: 0.20427\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.8]| NDCG@10: 0.31102| HIT@10: 0.20427\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.75]| NDCG@10: 0.31105| HIT@10: 0.20429\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.7]| NDCG@10: 0.31112| HIT@10: 0.20438\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.65]| NDCG@10: 0.31119| HIT@10: 0.20445\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.6]| NDCG@10: 0.31103| HIT@10: 0.20430\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.55]| NDCG@10: 0.31109| HIT@10: 0.20425\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.5]| NDCG@10: 0.31124| HIT@10: 0.20434\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.45]| NDCG@10: 0.31135| HIT@10: 0.20441\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.4]| NDCG@10: 0.31130| HIT@10: 0.20438\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.35]| NDCG@10: 0.31131| HIT@10: 0.20437\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.3]| NDCG@10: 0.31121| HIT@10: 0.20433\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.25]| NDCG@10: 0.31123| HIT@10: 0.20437\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.2]| NDCG@10: 0.31117| HIT@10: 0.20435\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.15]| NDCG@10: 0.31094| HIT@10: 0.20416\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.1]| NDCG@10: 0.31076| HIT@10: 0.20401\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.05]| NDCG@10: 0.31059| HIT@10: 0.20387\n",
    "BEST cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.65]| NDCG@10: 0.31119| HIT@10: 0.20445\n",
    "BEST cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.45]| NDCG@10: 0.31135| HIT@10: 0.20441\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 1.0]| NDCG@10: 0.31727| HIT@10: 0.20922\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.95]| NDCG@10: 0.31758| HIT@10: 0.20937\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.9]| NDCG@10: 0.31786| HIT@10: 0.20948\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.85]| NDCG@10: 0.31807| HIT@10: 0.20968\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.8]| NDCG@10: 0.31808| HIT@10: 0.20967\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.75]| NDCG@10: 0.31800| HIT@10: 0.20960\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.45, 0.7]| NDCG@10: 0.31790| HIT@10: 0.20943\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 1.0]| NDCG@10: 0.31444| HIT@10: 0.20739\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.95]| NDCG@10: 0.31503| HIT@10: 0.20768\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.9]| NDCG@10: 0.31536| HIT@10: 0.20784\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.85]| NDCG@10: 0.31568| HIT@10: 0.20799\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.8]| NDCG@10: 0.31625| HIT@10: 0.20818\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.75]| NDCG@10: 0.31661| HIT@10: 0.20837\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.7]| NDCG@10: 0.31705| HIT@10: 0.20858\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.65]| NDCG@10: 0.31733| HIT@10: 0.20866\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.6]| NDCG@10: 0.31769| HIT@10: 0.20884\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.55]| NDCG@10: 0.31801| HIT@10: 0.20918\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.5]| NDCG@10: 0.31837| HIT@10: 0.20943\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.45]| NDCG@10: 0.31860| HIT@10: 0.20962\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.4]| NDCG@10: 0.31874| HIT@10: 0.20975\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.35]| NDCG@10: 0.31895| HIT@10: 0.20997\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.3]| NDCG@10: 0.31918| HIT@10: 0.21020\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.25]| NDCG@10: 0.31922| HIT@10: 0.21031\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.2]| NDCG@10: 0.31918| HIT@10: 0.21026\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.15]| NDCG@10: 0.31910| HIT@10: 0.21023\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.1]| NDCG@10: 0.31883| HIT@10: 0.21006\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.05]| NDCG@10: 0.31852| HIT@10: 0.20981\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score']| weighte : [1.0, 0.45, 0.85, 0.25]| NDCG@10: 0.31922| HIT@10: 0.21031 \n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 1.0]| NDCG@10: 0.31214| HIT@10: 0.20505\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.95]| NDCG@10: 0.31263| HIT@10: 0.20535\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.9]| NDCG@10: 0.31307| HIT@10: 0.20561\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.85]| NDCG@10: 0.31359| HIT@10: 0.20593\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.8]| NDCG@10: 0.31416| HIT@10: 0.20633\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.75]| NDCG@10: 0.31459| HIT@10: 0.20653\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.7]| NDCG@10: 0.31515| HIT@10: 0.20689\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.65]| NDCG@10: 0.31555| HIT@10: 0.20718\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.6]| NDCG@10: 0.31596| HIT@10: 0.20744\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.55]| NDCG@10: 0.31644| HIT@10: 0.20779\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.5]| NDCG@10: 0.31685| HIT@10: 0.20804\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.45]| NDCG@10: 0.31724| HIT@10: 0.20838\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.4]| NDCG@10: 0.31755| HIT@10: 0.20857\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.35]| NDCG@10: 0.31794| HIT@10: 0.20890\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.3]| NDCG@10: 0.31841| HIT@10: 0.20929\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.25]| NDCG@10: 0.31871| HIT@10: 0.20968\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.2]| NDCG@10: 0.31887| HIT@10: 0.20982\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.15]| NDCG@10: 0.31908| HIT@10: 0.20995\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.1]| NDCG@10: 0.31922| HIT@10: 0.21012\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05]| NDCG@10: 0.31937| HIT@10: 0.21024\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05]| NDCG@10: 0.31937| HIT@10: 0.21024 \n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 1.0]| NDCG@10: 0.31592| HIT@10: 0.20776\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.95]| NDCG@10: 0.31633| HIT@10: 0.20791\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.9]| NDCG@10: 0.31676| HIT@10: 0.20817\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.85]| NDCG@10: 0.31703| HIT@10: 0.20831\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.8]| NDCG@10: 0.31741| HIT@10: 0.20852\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.75]| NDCG@10: 0.31757| HIT@10: 0.20862\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.7]| NDCG@10: 0.31794| HIT@10: 0.20886\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.65]| NDCG@10: 0.31836| HIT@10: 0.20919\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.6]| NDCG@10: 0.31866| HIT@10: 0.20938\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.55]| NDCG@10: 0.31895| HIT@10: 0.20964\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.5]| NDCG@10: 0.31923| HIT@10: 0.20987\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.45]| NDCG@10: 0.31925| HIT@10: 0.20986\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.4]| NDCG@10: 0.31953| HIT@10: 0.21014\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.35]| NDCG@10: 0.31970| HIT@10: 0.21031\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.3]| NDCG@10: 0.31977| HIT@10: 0.21032\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.25]| NDCG@10: 0.31984| HIT@10: 0.21032\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec6_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.45, 0.85, 0.25, 0.05, 0.2]| NDCG@10: 0.31984| HIT@10: 0.21028\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 1.0, 0.1, 0.3, 0.2]| NDCG@10: 0.31908| HIT@10: 0.21014\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.9, 0.1, 0.3, 0.2]| NDCG@10: 0.31957| HIT@10: 0.21027\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.2]| NDCG@10: 0.31995| HIT@10: 0.21040\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.7, 0.1, 0.3, 0.2]| NDCG@10: 0.31992| HIT@10: 0.21022\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.6, 0.1, 0.3, 0.2]| NDCG@10: 0.32010| HIT@10: 0.21036\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.5, 0.1, 0.3, 0.2]| NDCG@10: 0.31996| HIT@10: 0.21033\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.4, 0.1, 0.3, 0.2]| NDCG@10: 0.31992| HIT@10: 0.21044\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.3, 0.1, 0.3, 0.2]| NDCG@10: 0.31947| HIT@10: 0.21024\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.2, 0.1, 0.3, 0.2]| NDCG@10: 0.31892| HIT@10: 0.20997\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.1, 0.1, 0.3, 0.2]| NDCG@10: 0.31806| HIT@10: 0.20938\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.4, 0.1, 0.3, 0.2]| NDCG@10: 0.31992| HIT@10: 0.21044\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 1.0]| NDCG@10: 0.31060| HIT@10: 0.20423\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.9]| NDCG@10: 0.31086| HIT@10: 0.20416\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.8]| NDCG@10: 0.31102| HIT@10: 0.20427\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.7]| NDCG@10: 0.31112| HIT@10: 0.20438\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.6]| NDCG@10: 0.31103| HIT@10: 0.20430\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.5]| NDCG@10: 0.31124| HIT@10: 0.20434\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.4]| NDCG@10: 0.31130| HIT@10: 0.20438\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.3]| NDCG@10: 0.31121| HIT@10: 0.20433\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.2]| NDCG@10: 0.31117| HIT@10: 0.20435\n",
    "cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.1]| NDCG@10: 0.31076| HIT@10: 0.20401\n",
    "BEST cols : ['rec1_score', 'rec2_score']| weighte : [1.0, 0.4]| NDCG@10: 0.31130| HIT@10: 0.20438\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 1.0]| NDCG@10: 0.31716| HIT@10: 0.20921\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.9]| NDCG@10: 0.31770| HIT@10: 0.20940\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.8]| NDCG@10: 0.31789| HIT@10: 0.20956\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.7]| NDCG@10: 0.31788| HIT@10: 0.20950\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.6]| NDCG@10: 0.31790| HIT@10: 0.20939\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.5]| NDCG@10: 0.31738| HIT@10: 0.20897\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.4]| NDCG@10: 0.31655| HIT@10: 0.20827\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.3]| NDCG@10: 0.31571| HIT@10: 0.20768\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.2]| NDCG@10: 0.31464| HIT@10: 0.20701\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.1]| NDCG@10: 0.31317| HIT@10: 0.20593\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score']| weighte : [1.0, 0.4, 0.8]| NDCG@10: 0.31789| HIT@10: 0.20956\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 1.0]| NDCG@10: 0.31056| HIT@10: 0.20408\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.9]| NDCG@10: 0.31171| HIT@10: 0.20482\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.8]| NDCG@10: 0.31265| HIT@10: 0.20543\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.7]| NDCG@10: 0.31363| HIT@10: 0.20602\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.6]| NDCG@10: 0.31465| HIT@10: 0.20672\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.5]| NDCG@10: 0.31570| HIT@10: 0.20752\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.4]| NDCG@10: 0.31650| HIT@10: 0.20812\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.3]| NDCG@10: 0.31727| HIT@10: 0.20872\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.2]| NDCG@10: 0.31779| HIT@10: 0.20912\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.1]| NDCG@10: 0.31793| HIT@10: 0.20937\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score']| weighte : [1.0, 0.4, 0.8, 0.1]| NDCG@10: 0.31793| HIT@10: 0.20937\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 1.0]| NDCG@10: 0.31535| HIT@10: 0.20741\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.9]| NDCG@10: 0.31616| HIT@10: 0.20772\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.8]| NDCG@10: 0.31695| HIT@10: 0.20824\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.7]| NDCG@10: 0.31779| HIT@10: 0.20880\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.6]| NDCG@10: 0.31865| HIT@10: 0.20948\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.5]| NDCG@10: 0.31901| HIT@10: 0.20959\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.4]| NDCG@10: 0.31922| HIT@10: 0.20979\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3]| NDCG@10: 0.31934| HIT@10: 0.21005\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.2]| NDCG@10: 0.31904| HIT@10: 0.20992\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.1]| NDCG@10: 0.31868| HIT@10: 0.20984\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3]| NDCG@10: 0.31934| HIT@10: 0.21005\n",
    "\n",
    "\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 1.0]| NDCG@10: 0.31550| HIT@10: 0.20783\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.9]| NDCG@10: 0.31628| HIT@10: 0.20822\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.8]| NDCG@10: 0.31712| HIT@10: 0.20865\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.7]| NDCG@10: 0.31775| HIT@10: 0.20901\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.6]| NDCG@10: 0.31852| HIT@10: 0.20945\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.5]| NDCG@10: 0.31896| HIT@10: 0.20970\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.4]| NDCG@10: 0.31941| HIT@10: 0.20996\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.3]| NDCG@10: 0.31973| HIT@10: 0.21019\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.2]| NDCG@10: 0.31995| HIT@10: 0.21040\n",
    "cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.1]| NDCG@10: 0.31965| HIT@10: 0.21022\n",
    "BEST cols : ['rec1_score', 'rec2_score', 'rec3_score', 'rec4_score', 'rec5_score', 'rec6_score']| weighte : [1.0, 0.4, 0.8, 0.1, 0.3, 0.2]| NDCG@10: 0.31995| HIT@10: 0.21040\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_evaluate(\n",
    "    model1 = model1,\n",
    "    model2 = model2,\n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4,\n",
    "    MultiDAE = model5,\n",
    "    MultiVAE = model6,\n",
    "    X = X.todense(),\n",
    "    user_train = user_train,\n",
    "    user_valid = user_valid,\n",
    "    candidate_cnt = 10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>len</th>\n",
       "      <th>rec1</th>\n",
       "      <th>rec2</th>\n",
       "      <th>rec3</th>\n",
       "      <th>rec4</th>\n",
       "      <th>rec5</th>\n",
       "      <th>rec6</th>\n",
       "      <th>rec123456</th>\n",
       "      <th>total_val</th>\n",
       "      <th>total_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>31355</td>\n",
       "      <td>17</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>31356</td>\n",
       "      <td>26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rec5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>31357</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>31358</td>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>31359</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rec2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  len  rec1  rec2  rec3  rec4  rec5  rec6  rec123456  total_val  \\\n",
       "0          0   27   0.3   0.3   0.2   0.2   0.2   0.2        0.5        0.3   \n",
       "1          1   23   0.1   0.1   0.2   0.1   0.1   0.1        0.2        0.2   \n",
       "2          2   22   0.3   0.3   0.3   0.3   0.2   0.1        0.3        0.3   \n",
       "3          3   19   0.3   0.3   0.2   0.2   0.2   0.2        0.4        0.3   \n",
       "4          4   23   0.4   0.3   0.4   0.3   0.5   0.4        0.5        0.5   \n",
       "...      ...  ...   ...   ...   ...   ...   ...   ...        ...        ...   \n",
       "31355  31355   17   0.2   0.4   0.2   0.2   0.2   0.2        0.4        0.4   \n",
       "31356  31356   26   0.3   0.3   0.3   0.2   0.5   0.0        0.5        0.5   \n",
       "31357  31357   21   0.2   0.3   0.2   0.1   0.1   0.1        0.3        0.3   \n",
       "31358  31358   23   0.1   0.1   0.0   0.0   0.0   0.0        0.1        0.1   \n",
       "31359  31359   35   0.0   0.2   0.1   0.0   0.1   0.0        0.2        0.2   \n",
       "\n",
       "      total_name  \n",
       "0           rec1  \n",
       "1           rec3  \n",
       "2           rec1  \n",
       "3           rec1  \n",
       "4           rec5  \n",
       "...          ...  \n",
       "31355       rec2  \n",
       "31356       rec5  \n",
       "31357       rec2  \n",
       "31358       rec1  \n",
       "31359       rec2  \n",
       "\n",
       "[31360 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저들 마다 rec1 or rec2 or rec3 or ranking 등 맞는 방법에 따라사 추천을 해주는 것도 좋은 방법이 될 수 있음\n",
    "\n",
    "new_df = pd.DataFrame(df)\n",
    "\n",
    "def get_total_name(x):\n",
    "    val_list = [x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5'] , x['rec6']]\n",
    "    max_val = max(val_list)\n",
    "    val_idx = val_list.index(max_val)\n",
    "    if val_idx == 0 : return 'rec1'\n",
    "    elif val_idx == 1 : return 'rec2'\n",
    "    elif val_idx == 2 : return 'rec3'\n",
    "    elif val_idx == 3 : return 'rec4'\n",
    "    elif val_idx == 4 : return 'rec5'\n",
    "    elif val_idx == 5 : return 'rec6'\n",
    "\n",
    "new_df['total_val'] = new_df.apply(lambda x: max(x['rec1'], x['rec2'], x['rec3'], x['rec4'], x['rec5'] , x['rec6']), axis = 1)\n",
    "new_df['total_name'] = new_df.apply(lambda x: get_total_name(x), axis = 1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "sns.histplot(data = new_df[[\"rec1\", \"rec2\", \"rec3\", \"rec4\", \"rec5\", \"rec6\", 'rec123456', 'total_val']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec1    16391\n",
       "rec3     4737\n",
       "rec2     3913\n",
       "rec5     2433\n",
       "rec4     2162\n",
       "rec6     1724\n",
       "Name: total_name, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['total_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         15679.500000\n",
       "len             24.823884\n",
       "rec1             0.203839\n",
       "rec2             0.200207\n",
       "rec3             0.192140\n",
       "rec4             0.174758\n",
       "rec5             0.172388\n",
       "rec6             0.174767\n",
       "rec123456        0.313935\n",
       "total_val        0.263115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = np.concatenate([np.repeat(i, 6807) for i in range(31360)])\n",
    "\n",
    "# model1_score = model1.pred.sigmoid().cpu().numpy().reshape(-1)\n",
    "\n",
    "# model2_score = model2.pred.T.sigmoid().cpu().numpy().reshape(-1)\n",
    "\n",
    "# model3_score = model3(torch.from_numpy(X.todense()).to(device), calculate_loss = False).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model4_score = model4(torch.from_numpy(X.todense()).to(device)).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model5_score = model5(torch.from_numpy(X.todense()).to(device)).sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# model6_score, _, _ = model6(torch.from_numpy(X.todense()).to(device))\n",
    "# model6_score = model6_score.sigmoid().cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# X_df = np.concatenate([\n",
    "#     users.reshape(-1, 1), \n",
    "#     model1_score.reshape(-1, 1), \n",
    "#     model2_score.reshape(-1, 1), \n",
    "#     model3_score.reshape(-1, 1), \n",
    "#     model4_score.reshape(-1, 1), \n",
    "#     model5_score.reshape(-1, 1),\n",
    "#     model6_score.reshape(-1, 1)], axis = 1)\n",
    "\n",
    "# y_df = X.toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre = pd.read_csv(os.path.join(config.data_path, 'genres.tsv'), sep='\\t')\n",
    "# genre['genres'] = 1\n",
    "# genre['item_idx'] = genre['item'].apply(lambda x : make_matrix_data_set.item_encoder[x])\n",
    "# genre = pd.pivot_table(genre, values='genres', index=['item_idx'], columns=['genre'], aggfunc=np.sum, fill_value=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [16:22, 31.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 10| NDCG@10: 0.17573| HIT@10: 0.13605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# candidate_cnt = 10\n",
    "\n",
    "# ndcg, hit = evaluate(\n",
    "#             model1 = model1, \n",
    "#             model2 = model2, \n",
    "#             RecVAE = model3,\n",
    "#             AutoRec = model4,\n",
    "#             MultiDAE = model5,\n",
    "#             MultiVAE = model6,\n",
    "#             X_df = X_df, \n",
    "#             y_df = y_df,\n",
    "#             X = X.todense(),\n",
    "#             user_train = user_train, \n",
    "#             user_valid = user_valid, \n",
    "#             candidate_cnt = candidate_cnt)\n",
    "\n",
    "# print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for candidate_cnt in [5 * i for i in range(3, 21)]:\n",
    "#     ndcg, hit = evaluate(\n",
    "#             model1 = model1, \n",
    "#             model2 = model2, \n",
    "#             RecVAE = model3,\n",
    "#             X_df = X_df,\n",
    "#             y_df = y_df,\n",
    "#             X = X.todense(),\n",
    "#             user_train = user_train, \n",
    "#             user_valid = user_valid, \n",
    "#             candidate_cnt = candidate_cnt)\n",
    "\n",
    "#     print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:56, 177.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_cnt: 30| NDCG@10: 0.32010| HIT@10: 0.21036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_cnt = 30\n",
    "\n",
    "ndcg, hit = evaluate(\n",
    "            model1 = model1, \n",
    "            model2 = model2, \n",
    "            RecVAE = model3,\n",
    "            AutoRec = model4,\n",
    "            MultiDAE = model5,\n",
    "            MultiVAE = model6,\n",
    "            X = X.todense(),\n",
    "            user_train = user_train, \n",
    "            user_valid = user_valid, \n",
    "            candidate_cnt = candidate_cnt)\n",
    "\n",
    "print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "NDCG@10: 0.32010| HIT@10: 0.21036\n",
    "NDCG@10: 0.31992| HIT@10: 0.21044\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_cnt in [5 * i for i in range(2, 21)]:\n",
    "    \n",
    "    ndcg, hit = evaluate(\n",
    "                model1 = model1,\n",
    "                model2 = model2, \n",
    "                RecVAE = model3,\n",
    "                AutoRec = model4,\n",
    "                MultiDAE = model5,\n",
    "                MultiVAE = model6,\n",
    "                X = X.todense(),\n",
    "                user_train = user_train, \n",
    "                user_valid = user_valid, \n",
    "                candidate_cnt = candidate_cnt)\n",
    "\n",
    "    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델+ log2(rank + 1) + weighted Ensemble [1.0, 0.4, 0.4, 0.1, 0.3, 0.2]\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31722| HIT@10: 0.20723\n",
    "candidate_cnt: 15| NDCG@10: 0.31909| HIT@10: 0.20935\n",
    "candidate_cnt: 20| NDCG@10: 0.31977| HIT@10: 0.21020\n",
    "candidate_cnt: 25| NDCG@10: 0.31992| HIT@10: 0.21041\n",
    "candidate_cnt: 30| NDCG@10: 0.31992| HIT@10: 0.21044\n",
    "candidate_cnt: 35| NDCG@10: 0.31977| HIT@10: 0.21030\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델+ log2(rank + 1) + weighted Ensemble (0.25, 0.25, 0.2, 0.1, 0.1, 0.1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31753| HIT@10: 0.20782\n",
    "candidate_cnt: 15| NDCG@10: 0.31839| HIT@10: 0.20871\n",
    "candidate_cnt: 20| NDCG@10: 0.31884| HIT@10: 0.20924\n",
    "candidate_cnt: 25| NDCG@10: 0.31889| HIT@10: 0.20930\n",
    "candidate_cnt: 30| NDCG@10: 0.31911| HIT@10: 0.20956\n",
    "candidate_cnt: 35| NDCG@10: 0.31907| HIT@10: 0.20955\n",
    "candidate_cnt: 40| NDCG@10: 0.31901| HIT@10: 0.20949\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델 + voting\n",
    "candidate_cnt: 10| NDCG@10: 0.29867| HIT@10: 0.20497\n",
    "candidate_cnt: 15| NDCG@10: 0.28563| HIT@10: 0.20339\n",
    "candidate_cnt: 20| NDCG@10: 0.27253| HIT@10: 0.19996\n",
    "candidate_cnt: 25| NDCG@10: 0.25738| HIT@10: 0.19344\n",
    "candidate_cnt: 30| NDCG@10: 0.24171| HIT@10: 0.18377\n",
    "candidate_cnt: 35| NDCG@10: 0.22492| HIT@10: 0.17286\n",
    "candidate_cnt: 40| NDCG@10: 0.20953| HIT@10: 0.16214\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "6개 모델 + log2(rank + 1)\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.30926| HIT@10: 0.20194\n",
    "candidate_cnt: 15| NDCG@10: 0.31167| HIT@10: 0.20401\n",
    "candidate_cnt: 20| NDCG@10: 0.31282| HIT@10: 0.20501\n",
    "candidate_cnt: 25| NDCG@10: 0.31330| HIT@10: 0.20542\n",
    "candidate_cnt: 30| NDCG@10: 0.31366| HIT@10: 0.20572\n",
    "candidate_cnt: 35| NDCG@10: 0.31382| HIT@10: 0.20584\n",
    "candidate_cnt: 40| NDCG@10: 0.31397| HIT@10: 0.20594\n",
    "candidate_cnt: 45| NDCG@10: 0.31408| HIT@10: 0.20603\n",
    "candidate_cnt: 50| NDCG@10: 0.31416| HIT@10: 0.20611\n",
    "candidate_cnt: 55| NDCG@10: 0.31422| HIT@10: 0.20613\n",
    "candidate_cnt: 60| NDCG@10: 0.31427| HIT@10: 0.20618\n",
    "candidate_cnt: 65| NDCG@10: 0.31430| HIT@10: 0.20620\n",
    "candidate_cnt: 70| NDCG@10: 0.31435| HIT@10: 0.20623\n",
    "candidate_cnt: 75| NDCG@10: 0.31435| HIT@10: 0.20624\n",
    "candidate_cnt: 80| NDCG@10: 0.31438| HIT@10: 0.20627\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "EASE2개 + RecVAE-v3 + log2(rank + 1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31412| HIT@10: 0.20595\n",
    "candidate_cnt: 15| NDCG@10: 0.31573| HIT@10: 0.20745\n",
    "candidate_cnt: 20| NDCG@10: 0.31644| HIT@10: 0.20807\n",
    "candidate_cnt: 25| NDCG@10: 0.31687| HIT@10: 0.20851\n",
    "candidate_cnt: 30| NDCG@10: 0.31696| HIT@10: 0.20863\n",
    "candidate_cnt: 35| NDCG@10: 0.31708| HIT@10: 0.20872\n",
    "candidate_cnt: 40| NDCG@10: 0.31712| HIT@10: 0.20878\n",
    "candidate_cnt: 45| NDCG@10: 0.31717| HIT@10: 0.20882\n",
    "candidate_cnt: 50| NDCG@10: 0.31723| HIT@10: 0.20886\n",
    "candidate_cnt: 55| NDCG@10: 0.31723| HIT@10: 0.20884\n",
    "candidate_cnt: 60| NDCG@10: 0.31726| HIT@10: 0.20887\n",
    "candidate_cnt: 65| NDCG@10: 0.31729| HIT@10: 0.20888\n",
    "candidate_cnt: 70| NDCG@10: 0.31727| HIT@10: 0.20887\n",
    "candidate_cnt: 75| NDCG@10: 0.31730| HIT@10: 0.20889\n",
    "candidate_cnt: 80| NDCG@10: 0.31730| HIT@10: 0.20890\n",
    "candidate_cnt: 85| NDCG@10: 0.31733| HIT@10: 0.20888\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "EASE2개 + RecVAE-v5 + log2(rank + 1)\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "candidate_cnt: 15| NDCG@10: 0.31518| HIT@10: 0.20735\n",
    "candidate_cnt: 20| NDCG@10: 0.31569| HIT@10: 0.20779\n",
    "candidate_cnt: 25| NDCG@10: 0.31605| HIT@10: 0.20812\n",
    "candidate_cnt: 30| NDCG@10: 0.31616| HIT@10: 0.20822\n",
    "candidate_cnt: 35| NDCG@10: 0.31627| HIT@10: 0.20833\n",
    "candidate_cnt: 40| NDCG@10: 0.31636| HIT@10: 0.20843\n",
    "candidate_cnt: 45| NDCG@10: 0.31643| HIT@10: 0.20846\n",
    "candidate_cnt: 50| NDCG@10: 0.31644| HIT@10: 0.20848\n",
    "candidate_cnt: 55| NDCG@10: 0.31653| HIT@10: 0.20854\n",
    "candidate_cnt: 60| NDCG@10: 0.31657| HIT@10: 0.20857\n",
    "candidate_cnt: 65| NDCG@10: 0.31652| HIT@10: 0.20856\n",
    "candidate_cnt: 70| NDCG@10: 0.31653| HIT@10: 0.20856\n",
    "candidate_cnt: 75| NDCG@10: 0.31651| HIT@10: 0.20855\n",
    "candidate_cnt: 80| NDCG@10: 0.31658| HIT@10: 0.20858\n",
    "candidate_cnt: 85| NDCG@10: 0.31660| HIT@10: 0.20859\n",
    "candidate_cnt: 90| NDCG@10: 0.31658| HIT@10: 0.20860\n",
    "candidate_cnt: 95| NDCG@10: 0.31662| HIT@10: 0.20862\n",
    "candidate_cnt: 100| NDCG@10: 0.31658| HIT@10: 0.20861\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "candidate_cnt: 10| NDCG@10: 0.31372| HIT@10: 0.20602\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "none + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31411| HIT@10: 0.20686\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31568| HIT@10: 0.20702\n",
    "```\n",
    "\n",
    "```\n",
    "softmax + logistic\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.28598| HIT@10: 0.19227\n",
    "```\n",
    "\n",
    "```\n",
    "none + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31381| HIT@10: 0.20633\n",
    "```\n",
    "\n",
    "```\n",
    "sigmoid + sum\n",
    "\n",
    "candidate_cnt: 10| NDCG@10: 0.31469| HIT@10: 0.20636\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[147, 197, 188, 313, 228, 273, 189, 114, 42, 242]\n",
    "\n",
    "```\n",
    "non softmax\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.902873     0.411256     1.314129\n",
    "42    0.815624     0.411256     1.226880\n",
    "933   0.981398     0.172427     1.153824\n",
    "718   0.671753     0.402721     1.074474\n",
    "484   0.923667     0.149443     1.073110\n",
    "376   0.883676     0.173539     1.057215\n",
    "667   0.919388     0.097644     1.017032\n",
    "650   0.855481     0.151946     1.007427\n",
    "2200  0.878635     0.125442     1.004077\n",
    "714   0.719053     0.210817     0.929870\n",
    "1844  0.698690     0.226953     0.925643\n",
    "273   0.810516     0.097710     0.908226\n",
    "760   0.763495     0.036601     0.800096\n",
    "313   0.766302     0.027069     0.793371\n",
    "777   0.641927     0.142652     0.784579\n",
    "228   0.733693     0.044058     0.777750\n",
    "734   0.738835     0.031143     0.769978\n",
    "1354  0.438386     0.122450     0.560836\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "softmax\n",
    "\n",
    "\n",
    "score  genre_score  total_score\n",
    "197   0.053804     0.411256     0.465060\n",
    "42    0.053799     0.411256     0.465055\n",
    "718   0.053844     0.402721     0.456565\n",
    "1844  0.053790     0.226953     0.280743\n",
    "714   0.053817     0.210817     0.264634\n",
    "376   0.053824     0.173539     0.227363\n",
    "933   0.053912     0.172427     0.226339\n",
    "650   0.053820     0.151946     0.205766\n",
    "484   0.053827     0.149443     0.203270\n",
    "777   0.053828     0.142652     0.196481\n",
    "2200  0.053810     0.125442     0.179252\n",
    "1354  0.053825     0.122450     0.176275\n",
    "273   0.053800     0.097710     0.151510\n",
    "667   0.053807     0.097644     0.151450\n",
    "228   0.053814     0.044058     0.097871\n",
    "760   0.053811     0.036601     0.090412\n",
    "734   0.053804     0.031143     0.084947\n",
    "313   0.053817     0.027069     0.080885\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
    "X_test = make_matrix_data_set.make_sparse_matrix(test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = EASE(X = X_test, reg = 750)\n",
    "model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EASE(X = X_test.T, reg = 4400)\n",
    "model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RecVAE(\n",
    "    input_dim = make_matrix_data_set.num_item,).to(device)\n",
    "\n",
    "model3.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = AutoRec(\n",
    "    num = make_matrix_data_set.num_item, \n",
    "    num_factor = 64).to(device)\n",
    "\n",
    "model4.load_state_dict(torch.load(os.path.join(config.model_path, 'AutoRec_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = MultiDAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model5.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-DAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = MultiVAE(\n",
    "    p_dims = [100, 200, 400] + [make_matrix_data_set.num_item], \n",
    "    dropout_rate = 0.5).to(device)\n",
    "\n",
    "model6.load_state_dict(torch.load(os.path.join(config.model_path, 'Multi-VAE_v1.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [02:56, 177.81it/s]\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(\n",
    "    model1 = model1, \n",
    "    model2 = model2,\n",
    "    RecVAE = model3,\n",
    "    AutoRec = model4,\n",
    "    MultiDAE = model5,\n",
    "    MultiVAE = model6,\n",
    "    X = X_test.todense(),\n",
    "    candidate_cnt = 30,)\n",
    "\n",
    "submision = []\n",
    "users = [i for i in range(0, make_matrix_data_set.num_user)]\n",
    "for user in users:\n",
    "    rec_item_list = user2rec_list[user]\n",
    "    for item in rec_item_list:\n",
    "        submision.append(\n",
    "            {   \n",
    "                'user' : make_matrix_data_set.user_decoder[user],\n",
    "                'item' : make_matrix_data_set.item_decoder[item],\n",
    "            }\n",
    "        )\n",
    "\n",
    "submision = pd.DataFrame(submision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313595</th>\n",
       "      <td>138493</td>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313596</th>\n",
       "      <td>138493</td>\n",
       "      <td>27660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313597</th>\n",
       "      <td>138493</td>\n",
       "      <td>8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313598</th>\n",
       "      <td>138493</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313599</th>\n",
       "      <td>138493</td>\n",
       "      <td>5349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item\n",
       "0           11   4370\n",
       "1           11   4886\n",
       "2           11  40815\n",
       "3           11   8961\n",
       "4           11   7373\n",
       "...        ...    ...\n",
       "313595  138493   8970\n",
       "313596  138493  27660\n",
       "313597  138493   8961\n",
       "313598  138493    589\n",
       "313599  138493   5349\n",
       "\n",
       "[313600 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
