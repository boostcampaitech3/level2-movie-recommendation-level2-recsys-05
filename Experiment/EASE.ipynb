{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ug-br-pPu9vZ"},"outputs":[],"source":["import math\n","import numpy as np\n","import scipy.sparse as sp\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import defaultdict\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from box import Box\n","\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","torch.set_printoptions(sci_mode=True)"]},{"cell_type":"markdown","metadata":{"id":"pbRKDSg4u9vc"},"source":["# 1. 학습 설정"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"MEhK_fLIu9vd"},"outputs":[],"source":["config = {\n","    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n","    'model_path' : \"../model\",\n","    \n","    'submission_path' : \"../submission\",\n","    'submission_name' : 'EASE_v8_submission.csv',\n","\n","    'candidate_item_num' : 5,\n","    'valid_samples' : 10, # 검증에 사용할 sample 수\n","    'seed' : 22,\n","    'reg' : 750,\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","config = Box(config)"]},{"cell_type":"markdown","metadata":{"id":"wjDxy0fJu9vf"},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"W64BYWl0u9vg"},"outputs":[],"source":["class MakeMatrixDataSet():\n","    \"\"\"\n","    MatrixDataSet 생성\n","    \"\"\"\n","    def __init__(self, config):\n","        self.config = config\n","        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n","        \n","        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n","        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n","        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n","\n","        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n","        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n","\n","        self.user_train, self.user_valid = self.generate_sequence_data()\n","\n","    def generate_encoder_decoder(self, col : str) -> dict:\n","        \"\"\"\n","        encoder, decoder 생성\n","\n","        Args:\n","            col (str): 생성할 columns 명\n","        Returns:\n","            dict: 생성된 user encoder, decoder\n","        \"\"\"\n","\n","        encoder = {}\n","        decoder = {}\n","        ids = self.df[col].unique()\n","\n","        for idx, _id in enumerate(ids):\n","            encoder[_id] = idx\n","            decoder[idx] = _id\n","\n","        return encoder, decoder\n","    \n","    def generate_sequence_data(self) -> dict:\n","        \"\"\"\n","        sequence_data 생성\n","\n","        Returns:\n","            dict: train user sequence / valid user sequence\n","        \"\"\"\n","        users = defaultdict(list)\n","        user_train = {}\n","        user_valid = {}\n","        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n","            users[user].append(item)\n","        \n","        for user in users:\n","            np.random.seed(self.config.seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            user_train[user] = train\n","            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n","\n","        return user_train, user_valid\n","    \n","    def get_train_valid_data(self):\n","        return self.user_train, self.user_valid\n","\n","    def make_matrix(self, user_list, train = True):\n","        \"\"\"\n","        user_item_dict를 바탕으로 행렬 생성\n","        \"\"\"\n","        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n","        for idx, user in enumerate(user_list):\n","            if train:\n","                mat[idx, self.user_train[user.item()]] = 1\n","            else:\n","                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n","        return mat\n","\n","    def make_sparse_matrix(self, test = False):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        \n","        for user in self.user_train.keys():\n","            item_list = self.user_train[user]\n","            X[user, item_list] = 1.0\n","        \n","        if test:\n","            for user in self.user_valid.keys():\n","                item_list = self.user_valid[user]\n","                X[user, item_list] = 1.0\n","\n","        return X.tocsr()\n","    \n","    def pseudo_make_sparse_matrix(self, user2rec):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        \n","        for user in self.user_train.keys():\n","            item_list = self.user_train[user] + user2rec[user]\n","            X[user, item_list] = 1.0\n","\n","        return X.tocsr()\n","\n","\n","    def make_year_candidate_item(self, train = True):\n","        user_pro_df = pd.read_csv(os.path.join(self.config.data_path, 'user_pro.csv'))\n","        item_pro_df = pd.read_csv(os.path.join(self.config.data_path, 'item_pro.csv'))\n","\n","        item_pro_df['item'] = item_pro_df['item'].apply(lambda x : self.item_encoder[x])\n","        item_pro_df['year'] = item_pro_df['year'].astype(int)\n","\n","        user_pro_df['user'] = user_pro_df['user'].apply(lambda x : self.user_encoder[x])\n","        user_pro_df['max_year'] = user_pro_df['max_year'].astype(int)\n","        \n","        year2item_list = {}\n","        year_list = user_pro_df['max_year'].unique().tolist()\n","        for year in year_list:\n","            item_list = item_pro_df[item_pro_df['year'] <= year + 1]['item'].tolist()\n","            year2item_list[year + 1] = item_list\n","\n","        all_item_list = [i for i in range(self.num_item)]\n","        group_df = user_pro_df.groupby('user')\n","        candidate = {}\n","        if train:\n","            for user, df in group_df:\n","                max_year = df['max_year'].values[0]\n","                candidate_item_list = year2item_list[max_year + 1]\n","                candidate_item_list = set(all_item_list) - set(candidate_item_list)\n","                candidate_item_list = list(candidate_item_list | set(self.user_train[user]))\n","                candidate[user] = candidate_item_list\n","        else:\n","            for user, df in group_df:\n","                max_year = df['max_year'].values[0]\n","                candidate_item_list = year2item_list[max_year + 1]\n","                candidate_item_list = set(all_item_list) - set(candidate_item_list)\n","                candidate_item_list = candidate_item_list | set(self.user_train[user])\n","                candidate_item_list = list(candidate_item_list | set(self.user_valid[user]))\n","                candidate[user] = candidate_item_list\n","\n","        return candidate\n","\n","    def make_cos_candidate_item(self, candidate_item_num, train = True):\n","        gmf = GMF(\n","            num_user = self.num_user, \n","            num_item = self.num_item, \n","            num_factor = 512).to(device)\n","\n","        gmf.load_state_dict(torch.load(os.path.join(self.config.model_path, 'GMF_v1.pt')))\n","        movie_emb = gmf.item_emb.weight.data.cpu()\n","        \n","        cos_mm = torch.nn.CosineSimilarity(dim=1)\n","        cos_sim_list = []\n","        for target_item in range(len(movie_emb)):\n","            cos_sim_score = cos_mm(movie_emb[target_item], movie_emb)\n","            cos_sim_index = cos_sim_score.argsort()\n","            cos_sim_list.append(cos_sim_index.numpy()[::-1][:candidate_item_num + 1].tolist())\n","        \n","        cos_sim_list = np.array(cos_sim_list)\n","\n","        candidate = {}\n","        if train:\n","            for user in self.user_train.keys():\n","                candidate_item_list = set(cos_sim_list[self.user_train[user], :].reshape(-1).tolist())\n","                candidate_item_list = list(candidate_item_list - set(self.user_train[user]))\n","                candidate[user] = candidate_item_list\n","        else:\n","            for user in self.user_train.keys():\n","                candidate_item_list = set(cos_sim_list[self.user_train[user] + self.user_valid[user], :].reshape(-1).tolist())\n","                candidate_item_list = candidate_item_list - set(self.user_train[user])\n","                candidate_item_list = list(candidate_item_list - set(self.user_valid[user]))\n","                candidate[user] = candidate_item_list\n","        \n","        return candidate\n","\n","    def m_s_m(self, candidate):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        for user in candidate.keys():\n","            item_list = candidate[user]\n","            X[user, item_list] = 1.0\n","\n","        return X.tocsr()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IldCGmY8u9vh"},"outputs":[],"source":["class AEDataSet(Dataset):\n","    def __init__(self, num_user):\n","        self.num_user = num_user\n","        self.users = [i for i in range(num_user)]\n","\n","    def __len__(self):\n","        return self.num_user\n","\n","    def __getitem__(self, idx): \n","        user = self.users[idx]\n","        return torch.LongTensor([user])"]},{"cell_type":"markdown","metadata":{"id":"ysia457Su9vi"},"source":["# 3. 모델"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TVXWUTLpSh8_"},"outputs":[],"source":["class EASE():\n","    def __init__(self, X, reg):\n","        self.X = self._convert_sp_mat_to_sp_tensor(X)\n","        self.reg = reg\n","    \n","    def _convert_sp_mat_to_sp_tensor(self, X):\n","        \"\"\"\n","        Convert scipy sparse matrix to PyTorch sparse matrix\n","\n","        Arguments:\n","        ----------\n","        X = Adjacency matrix, scipy sparse matrix\n","        \"\"\"\n","        coo = X.tocoo().astype(np.float32)\n","        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n","        v = torch.FloatTensor(coo.data)\n","        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n","        return res\n","    \n","    def fit(self):\n","        '''\n","\n","        진짜 정말 간단한 식으로 모델을 만듬\n","\n","        '''\n","        G = self.X.to_dense().t() @ self.X.to_dense()\n","        diagIndices = torch.eye(G.shape[0]) == 1\n","        G[diagIndices] += self.reg\n","\n","        P = G.inverse()\n","        B = P / (-1 * P.diag())\n","        B[diagIndices] = 0\n","        \n","        self.B = B\n","        self.pred = self.X.to_dense() @ B"]},{"cell_type":"markdown","metadata":{"id":"GwSexh43u9vk"},"source":["# 4. 학습 함수"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"nws4JO2_rgQP"},"outputs":[],"source":["def get_ndcg(pred_list, true_list):\n","    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n","    dcg = 0\n","    for rank, pred in enumerate(pred_list):\n","        if pred in true_list:\n","            dcg += 1 / np.log2(rank + 2)\n","    ndcg = dcg / idcg\n","    return ndcg\n","\n","# hit == recall == precision\n","def get_hit(pred_list, true_list):\n","    hit_list = set(true_list) & set(pred_list)\n","    hit = len(hit_list) / len(true_list)\n","    return hit\n","\n","def evaluate(model, X, user_train, user_valid, user_list):\n","\n","    mat = torch.from_numpy(X)\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat = model.pred.cpu()\n","    recon_mat[mat == 1] = -np.inf\n","    rec_list = recon_mat.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        if user in user_list:\n","            uv = user_valid[user]\n","            up = rec[-10:].cpu().numpy().tolist()[::-1]\n","            NDCG += get_ndcg(pred_list = up, true_list = uv)\n","            HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(user_list)\n","    HIT /= len(user_list)\n","\n","    return NDCG, HIT\n","\n","\n","def predict(model, X):\n","    user2rec = {}\n","\n","    recon_mat = model.pred.cpu()\n","    score = recon_mat * torch.from_numpy(1 - X)\n","    rec_list = score.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        up = rec[-10:].cpu().numpy().tolist()\n","        user2rec[user] = up\n","    \n","    return user2rec"]},{"cell_type":"markdown","metadata":{"id":"gupkaJHMslCi"},"source":["# 5. 학습"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"HFOr6Wmbq9pW"},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n","X = make_matrix_data_set.make_sparse_matrix()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = EASE(X = X, reg = 680) # 아이템 유사도 기반\n","# model = EASE(X = X.T, reg = 4400) # 유저 유사도 기반\n","model.fit()\n","ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["# 6. 예측"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","X_test = make_matrix_data_set.make_sparse_matrix(test = True)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["model = EASE(X = X_test, reg = config.reg)\n","model.fit()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["user2rec_list = predict(\n","    model = model, \n","    X = X_test.todense(),\n","    )\n","\n","submision = []\n","users = [i for i in range(0, make_matrix_data_set.num_user)]\n","for user in users:\n","    rec_item_list = user2rec_list[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMB0K8DmOwclQIFyyBerAFJ","collapsed_sections":[],"mount_file_id":"1C1AHkN-z-DCxUIAjFfd7K56P-8-YrAJO","name":"EASE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
