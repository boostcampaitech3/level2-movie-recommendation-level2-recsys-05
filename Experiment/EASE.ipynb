{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ug-br-pPu9vZ"},"outputs":[],"source":["import math\n","import numpy as np\n","import scipy.sparse as sp\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import defaultdict\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from box import Box\n","\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","torch.set_printoptions(sci_mode=True)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class GMF(nn.Module):\n","    def __init__(self, num_user, num_item, num_factor):\n","        super(GMF, self).__init__()\n","        self.user_emb = nn.Embedding(num_user, num_factor)\n","        self.item_emb = nn.Embedding(num_item, num_factor)\n","        \n","        self.predict_layer = nn.Sequential(\n","            nn.Linear(num_factor, 1, bias = False)\n","        )\n","\n","        self._init_weight_()\n","    \n","    def _init_weight_(self):\n","        nn.init.normal_(self.user_emb.weight, std=0.01)\n","        nn.init.normal_(self.item_emb.weight, std=0.01)\n","        for m in self.predict_layer:\n","            if isinstance(m, nn.Linear):\n","                nn.init.kaiming_uniform_(m.weight, a=1)\n","    \n","    def forward(self, user, item):\n","        user_emb = self.user_emb(user)\n","        item_emb = self.item_emb(item)\n","\n","        output = self.predict_layer(user_emb * item_emb)\n","\n","        return output.view(-1)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def swish(x):\n","    return x.mul(torch.sigmoid(x))\n","\n","def log_norm_pdf(x, mu, logvar):\n","    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n","\n","class CompositePrior(nn.Module):\n","    def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n","        super(CompositePrior, self).__init__()\n","        \n","        self.mixture_weights = mixture_weights\n","        \n","        self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n","        self.mu_prior.data.fill_(0)\n","        \n","        self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n","        self.logvar_prior.data.fill_(0)\n","        \n","        self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n","        self.logvar_uniform_prior.data.fill_(10)\n","        \n","        self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n","        self.encoder_old.requires_grad_(False)\n","        \n","    def forward(self, x, z):\n","\n","        post_mu, post_logvar = self.encoder_old(x, dropout_rate = 0)\n","\n","        stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n","        post_prior = log_norm_pdf(z, post_mu, post_logvar)\n","        unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n","        \n","        gaussians = [stnd_prior, post_prior, unif_prior]\n","        gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n","\n","        density_per_gaussian = torch.stack(gaussians, dim=-1)\n","\n","        return torch.logsumexp(density_per_gaussian, dim=-1)\n","\n","    \n","class Encoder(nn.Module):\n","    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n","        super(Encoder, self).__init__()\n","        \n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n","        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n","        \n","    def forward(self, x, dropout_rate):\n","        norm = x.pow(2).sum(dim=-1).sqrt()\n","        x = x / norm[:, None]\n","    \n","        x = F.dropout(x, p=dropout_rate, training=self.training)\n","        \n","        h1 = self.ln1(swish(self.fc1(x)))\n","        h2 = self.ln2(swish(self.fc2(h1) + h1))\n","        h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n","        h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n","        h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n","        return self.fc_mu(h5), self.fc_logvar(h5)\n","\n","\n","class RecVAE(nn.Module):\n","    def __init__(self, input_dim, hidden_dim = 600, latent_dim = 200):\n","        super(RecVAE, self).__init__()\n","\n","        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n","        self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n","        self.decoder = nn.Linear(latent_dim, input_dim)\n","        \n","    def reparameterize(self, mu, logvar):\n","        if self.training:\n","            std = torch.exp(0.5*logvar)\n","            eps = torch.randn_like(std)\n","            return eps.mul(std).add_(mu)\n","        else:\n","            return mu\n","\n","    def forward(self, user_ratings, beta=None, gamma=0.005, dropout_rate=0.5, calculate_loss=True):\n","        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)    \n","        z = self.reparameterize(mu, logvar)\n","        x_pred = self.decoder(z)\n","\n","        if calculate_loss:\n","            if gamma:\n","                norm = user_ratings.sum(dim=-1)\n","                kl_weight = gamma * norm\n","            elif beta:\n","                kl_weight = beta\n","\n","            mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n","            kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n","            negative_elbo = -(mll - kld)\n","            \n","            return (mll, kld), negative_elbo\n","            \n","        else:\n","            return x_pred\n","\n","    def update_prior(self):\n","        self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))"]},{"cell_type":"markdown","metadata":{"id":"pbRKDSg4u9vc"},"source":["# 1. 학습 설정"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"MEhK_fLIu9vd"},"outputs":[],"source":["config = {\n","    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n","    'model_path' : \"../model\",\n","    \n","    'submission_path' : \"../submission\",\n","    'submission_name' : 'EASE_v8_submission.csv',\n","\n","    'candidate_item_num' : 5,\n","    'valid_samples' : 10, # 검증에 사용할 sample 수\n","    'seed' : 22,\n","    'reg' : 750,\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","config = Box(config)"]},{"cell_type":"markdown","metadata":{"id":"wjDxy0fJu9vf"},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"W64BYWl0u9vg"},"outputs":[],"source":["class MakeMatrixDataSet():\n","    \"\"\"\n","    MatrixDataSet 생성\n","    \"\"\"\n","    def __init__(self, config):\n","        self.config = config\n","        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n","        \n","        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n","        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n","        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n","\n","        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n","        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n","\n","        self.user_train, self.user_valid = self.generate_sequence_data()\n","\n","    def generate_encoder_decoder(self, col : str) -> dict:\n","        \"\"\"\n","        encoder, decoder 생성\n","\n","        Args:\n","            col (str): 생성할 columns 명\n","        Returns:\n","            dict: 생성된 user encoder, decoder\n","        \"\"\"\n","\n","        encoder = {}\n","        decoder = {}\n","        ids = self.df[col].unique()\n","\n","        for idx, _id in enumerate(ids):\n","            encoder[_id] = idx\n","            decoder[idx] = _id\n","\n","        return encoder, decoder\n","    \n","    def generate_sequence_data(self) -> dict:\n","        \"\"\"\n","        sequence_data 생성\n","\n","        Returns:\n","            dict: train user sequence / valid user sequence\n","        \"\"\"\n","        users = defaultdict(list)\n","        user_train = {}\n","        user_valid = {}\n","        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n","            users[user].append(item)\n","        \n","        for user in users:\n","            np.random.seed(self.config.seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            user_train[user] = train\n","            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n","\n","        return user_train, user_valid\n","    \n","    def get_train_valid_data(self):\n","        return self.user_train, self.user_valid\n","\n","    def make_matrix(self, user_list, train = True):\n","        \"\"\"\n","        user_item_dict를 바탕으로 행렬 생성\n","        \"\"\"\n","        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n","        for idx, user in enumerate(user_list):\n","            if train:\n","                mat[idx, self.user_train[user.item()]] = 1\n","            else:\n","                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n","        return mat\n","\n","    def make_sparse_matrix(self, test = False):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        \n","        for user in self.user_train.keys():\n","            item_list = self.user_train[user]\n","            X[user, item_list] = 1.0\n","        \n","        if test:\n","            for user in self.user_valid.keys():\n","                item_list = self.user_valid[user]\n","                X[user, item_list] = 1.0\n","\n","        return X.tocsr()\n","    \n","    def pseudo_make_sparse_matrix(self, user2rec):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        \n","        for user in self.user_train.keys():\n","            item_list = self.user_train[user] + user2rec[user]\n","            X[user, item_list] = 1.0\n","\n","        return X.tocsr()\n","\n","\n","    def make_year_candidate_item(self, train = True):\n","        user_pro_df = pd.read_csv(os.path.join(self.config.data_path, 'user_pro.csv'))\n","        item_pro_df = pd.read_csv(os.path.join(self.config.data_path, 'item_pro.csv'))\n","\n","        item_pro_df['item'] = item_pro_df['item'].apply(lambda x : self.item_encoder[x])\n","        item_pro_df['year'] = item_pro_df['year'].astype(int)\n","\n","        user_pro_df['user'] = user_pro_df['user'].apply(lambda x : self.user_encoder[x])\n","        user_pro_df['max_year'] = user_pro_df['max_year'].astype(int)\n","        \n","        year2item_list = {}\n","        year_list = user_pro_df['max_year'].unique().tolist()\n","        for year in year_list:\n","            item_list = item_pro_df[item_pro_df['year'] <= year + 1]['item'].tolist()\n","            year2item_list[year + 1] = item_list\n","\n","        all_item_list = [i for i in range(self.num_item)]\n","        group_df = user_pro_df.groupby('user')\n","        candidate = {}\n","        if train:\n","            for user, df in group_df:\n","                max_year = df['max_year'].values[0]\n","                candidate_item_list = year2item_list[max_year + 1]\n","                candidate_item_list = set(all_item_list) - set(candidate_item_list)\n","                candidate_item_list = list(candidate_item_list | set(self.user_train[user]))\n","                candidate[user] = candidate_item_list\n","        else:\n","            for user, df in group_df:\n","                max_year = df['max_year'].values[0]\n","                candidate_item_list = year2item_list[max_year + 1]\n","                candidate_item_list = set(all_item_list) - set(candidate_item_list)\n","                candidate_item_list = candidate_item_list | set(self.user_train[user])\n","                candidate_item_list = list(candidate_item_list | set(self.user_valid[user]))\n","                candidate[user] = candidate_item_list\n","\n","        return candidate\n","\n","    def make_cos_candidate_item(self, candidate_item_num, train = True):\n","        gmf = GMF(\n","            num_user = self.num_user, \n","            num_item = self.num_item, \n","            num_factor = 512).to(device)\n","\n","        gmf.load_state_dict(torch.load(os.path.join(self.config.model_path, 'GMF_v1.pt')))\n","        movie_emb = gmf.item_emb.weight.data.cpu()\n","        \n","        cos_mm = torch.nn.CosineSimilarity(dim=1)\n","        cos_sim_list = []\n","        for target_item in range(len(movie_emb)):\n","            cos_sim_score = cos_mm(movie_emb[target_item], movie_emb)\n","            cos_sim_index = cos_sim_score.argsort()\n","            cos_sim_list.append(cos_sim_index.numpy()[::-1][:candidate_item_num + 1].tolist())\n","        \n","        cos_sim_list = np.array(cos_sim_list)\n","\n","        candidate = {}\n","        if train:\n","            for user in self.user_train.keys():\n","                candidate_item_list = set(cos_sim_list[self.user_train[user], :].reshape(-1).tolist())\n","                candidate_item_list = list(candidate_item_list - set(self.user_train[user]))\n","                candidate[user] = candidate_item_list\n","        else:\n","            for user in self.user_train.keys():\n","                candidate_item_list = set(cos_sim_list[self.user_train[user] + self.user_valid[user], :].reshape(-1).tolist())\n","                candidate_item_list = candidate_item_list - set(self.user_train[user])\n","                candidate_item_list = list(candidate_item_list - set(self.user_valid[user]))\n","                candidate[user] = candidate_item_list\n","        \n","        return candidate\n","\n","    def m_s_m(self, candidate):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        for user in candidate.keys():\n","            item_list = candidate[user]\n","            X[user, item_list] = 1.0\n","\n","        return X.tocsr()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IldCGmY8u9vh"},"outputs":[],"source":["class AEDataSet(Dataset):\n","    def __init__(self, num_user):\n","        self.num_user = num_user\n","        self.users = [i for i in range(num_user)]\n","\n","    def __len__(self):\n","        return self.num_user\n","\n","    def __getitem__(self, idx): \n","        user = self.users[idx]\n","        return torch.LongTensor([user])"]},{"cell_type":"markdown","metadata":{"id":"ysia457Su9vi"},"source":["# 3. 모델"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TVXWUTLpSh8_"},"outputs":[],"source":["class EASE():\n","    def __init__(self, X, reg):\n","        self.X = self._convert_sp_mat_to_sp_tensor(X)\n","        self.reg = reg\n","    \n","    def _convert_sp_mat_to_sp_tensor(self, X):\n","        \"\"\"\n","        Convert scipy sparse matrix to PyTorch sparse matrix\n","\n","        Arguments:\n","        ----------\n","        X = Adjacency matrix, scipy sparse matrix\n","        \"\"\"\n","        coo = X.tocoo().astype(np.float32)\n","        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n","        v = torch.FloatTensor(coo.data)\n","        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n","        return res\n","    \n","    def fit(self):\n","        '''\n","\n","        진짜 정말 간단한 식으로 모델을 만듬\n","\n","        '''\n","        G = self.X.to_dense().t() @ self.X.to_dense()\n","        diagIndices = torch.eye(G.shape[0]) == 1\n","        G[diagIndices] += self.reg\n","\n","        P = G.inverse()\n","        B = P / (-1 * P.diag())\n","        B[diagIndices] = 0\n","        \n","        self.B = B\n","        self.pred = self.X.to_dense() @ B"]},{"cell_type":"markdown","metadata":{"id":"GwSexh43u9vk"},"source":["# 4. 학습 함수"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"nws4JO2_rgQP"},"outputs":[],"source":["def get_ndcg(pred_list, true_list):\n","    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n","    dcg = 0\n","    for rank, pred in enumerate(pred_list):\n","        if pred in true_list:\n","            dcg += 1 / np.log2(rank + 2)\n","    ndcg = dcg / idcg\n","    return ndcg\n","\n","# hit == recall == precision\n","def get_hit(pred_list, true_list):\n","    hit_list = set(true_list) & set(pred_list)\n","    hit = len(hit_list) / len(true_list)\n","    return hit\n","\n","def evaluate(model, X, user_train, user_valid, user_list):\n","\n","    mat = torch.from_numpy(X)\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat = model.pred.cpu()\n","    recon_mat[mat == 1] = -np.inf\n","    rec_list = recon_mat.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        if user in user_list:\n","            uv = user_valid[user]\n","            up = rec[-10:].cpu().numpy().tolist()[::-1]\n","            NDCG += get_ndcg(pred_list = up, true_list = uv)\n","            HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(user_list)\n","    HIT /= len(user_list)\n","\n","    return NDCG, HIT\n","\n","\n","def predict(model, X):\n","    user2rec = {}\n","\n","    recon_mat = model.pred.cpu()\n","    score = recon_mat * torch.from_numpy(1 - X)\n","    rec_list = score.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        up = rec[-10:].cpu().numpy().tolist()\n","        user2rec[user] = up\n","    \n","    return user2rec"]},{"cell_type":"markdown","metadata":{"id":"gupkaJHMslCi"},"source":["# 5. 학습"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"HFOr6Wmbq9pW"},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n","X = make_matrix_data_set.make_sparse_matrix()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["zero_df = pd.read_csv('zero_df.csv')\n","user_list = zero_df['user'].tolist()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["new_X = X[user_list, :]"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reg: 680| NDCG@10: 0.20609| HIT@10: 0.13156\n","reg: 700| NDCG@10: 0.20616| HIT@10: 0.13152\n","reg: 650| NDCG@10: 0.20599| HIT@10: 0.13147\n","reg: 600| NDCG@10: 0.20585| HIT@10: 0.13142\n"]}],"source":["for reg in [680, 700, 650, 600]:\n","    model = EASE(X = X, reg = reg)\n","    model.fit()\n","    ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid, user_list = user_list)\n","    print(f'reg: {reg}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["X_test = make_matrix_data_set.make_sparse_matrix(test = True)\n","model = EASE(X = X_test, reg = 100000000)\n","model.fit()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def predict(model, X, user_list):\n","    user2rec = {}\n","\n","    mat = torch.from_numpy(X)\n","\n","    recon_mat = model.pred.cpu()\n","    recon_mat[mat == 1] = -np.inf\n","    rec_list = recon_mat.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        if user in user_list:\n","            up = rec[-10:].cpu().numpy().tolist()[::-1]\n","            user2rec[user] = up\n","    \n","    return user2rec"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["user2rec = predict(model = model, X = X_test.todense(), user_list = user_list)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["submision = []\n","users = user2rec.keys()\n","for user in users:\n","    rec_item_list = user2rec[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["output = pd.read_csv('output.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["submision['user'].unique().tolist()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["want_user_list = list(set(output['user'].unique().tolist()) - set(submision['user'].unique().tolist()))"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["final_df = pd.concat([output.set_index('user').loc[want_user_list, :].reset_index(), submision]).sort_values('user').reset_index(drop = True)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["final_df.to_csv('fina.csv', index = False)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["candidate = make_matrix_data_set.make_year_candidate_item(train = True)\n","# candidate = make_matrix_data_set.make_cos_candidate_item(candidate_item_num = config.candidate_item_num, train = True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["new_X = make_matrix_data_set.m_s_m(candidate)\n","# new_X = 1 - new_X.todense() # make_cos_candidate_item 사용할 때"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1103,"status":"ok","timestamp":1648373220204,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"D1yj8M7bsp6X","outputId":"20892967-6ca0-41b3-fa29-56ab76c92c0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.22955| HIT@10: 0.20386\n"]}],"source":["ndcg, hit = evaluate(model = model, X = new_X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.22952| HIT@10: 0.20384\n"]}],"source":["ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.22594| HIT@10: 0.20021\n"]}],"source":["model = EASE(X = X.T, reg = 4400)\n","model.fit()\n","ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["```\n","\n","연도 필터링 NDCG@10: 0.81342| HIT@10: 0.20386\n","\n","reg: 750| NDCG@10: 0.81333| HIT@10: 0.20384\n","```\n","\n","```\n","reg: 4400| NDCG@10: 0.80065| HIT@10: 0.20021\n","```"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reg: 4800| NDCG@10: 0.79857| HIT@10: 0.20000\n","reg: 4700| NDCG@10: 0.79786| HIT@10: 0.19994\n","reg: 4600| NDCG@10: 0.79932| HIT@10: 0.20013\n","reg: 4500| NDCG@10: 0.80055| HIT@10: 0.20017\n","reg: 4400| NDCG@10: 0.80065| HIT@10: 0.20021\n","reg: 4300| NDCG@10: 0.80003| HIT@10: 0.20011\n","reg: 4200| NDCG@10: 0.79924| HIT@10: 0.19998\n"]}],"source":["for reg in [4800, 4700, 4600, 4500, 4400, 4300, 4200, 4100, 4000]:\n","    model = EASE(X = X.T, reg = reg)\n","    model.fit()\n","    ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","    print(f'reg: {reg}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for candidate_item_num in range(1, 20):\n","    candidate = make_matrix_data_set.make_cos_candidate_item(candidate_item_num = candidate_item_num, train = True)\n","    new_X = make_matrix_data_set.m_s_m(candidate)\n","    new_X = 1 - new_X.todense()\n","\n","    ndcg, hit = evaluate(model = model, X = new_X, user_train = user_train, user_valid = user_valid)\n","    print(f'candidate_item_num: {candidate_item_num}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["reg = 1000\n","\n","규제가 높아지면 후보 집단 생성이 더 좋은 성능을 가져다 주지는 않음\n","\n","이 이유는 현재 후보 집단 임베딩의 낮은 성능 때문인 것으로 생각됨\n","\n","```\n","candidate_item_num: 1| NDCG@10: 0.61763| HIT@10: 0.16217\n","candidate_item_num: 2| NDCG@10: 0.74284| HIT@10: 0.18944\n","candidate_item_num: 3| NDCG@10: 0.77578| HIT@10: 0.19632\n","candidate_item_num: 4| NDCG@10: 0.79034| HIT@10: 0.19934\n","candidate_item_num: 5| NDCG@10: 0.79921| HIT@10: 0.20084\n","candidate_item_num: 6| NDCG@10: 0.80333| HIT@10: 0.20157\n","candidate_item_num: 7| NDCG@10: 0.80574| HIT@10: 0.20211\n","candidate_item_num: 8| NDCG@10: 0.80748| HIT@10: 0.20246\n","candidate_item_num: 9| NDCG@10: 0.80879| HIT@10: 0.20280\n","\n","all = NDCG@10: 0.81406| HIT@10: 0.20379\n","\n","year = NDCG@10: 0.81417| HIT@10: 0.20382\n","\n","```"]},{"cell_type":"markdown","metadata":{},"source":["reg = 0.001\n","```\n","candidate_item_num: 1| NDCG@10: 0.58045| HIT@10: 0.14915\n","candidate_item_num: 2| NDCG@10: 0.67349| HIT@10: 0.16913\n","candidate_item_num: 3| NDCG@10: 0.69687| HIT@10: 0.17347\n","candidate_item_num: 4| NDCG@10: 0.70453| HIT@10: 0.17469\n","candidate_item_num: 5| NDCG@10: 0.70501| HIT@10: 0.17461\n","candidate_item_num: 6| NDCG@10: 0.70404| HIT@10: 0.17441\n","candidate_item_num: 7| NDCG@10: 0.70468| HIT@10: 0.17448\n","candidate_item_num: 8| NDCG@10: 0.70447| HIT@10: 0.17434\n","\n","```"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n","X = make_matrix_data_set.make_sparse_matrix()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reg: 4380| NDCG@10: 0.22584| HIT@10: 0.20019\n","reg: 4370| NDCG@10: 0.22578| HIT@10: 0.20017\n"]}],"source":["for reg in [4380, 4370]:\n","    model = EASE(X = X.T, reg = reg)\n","    model.fit()\n","    model.pred = model.pred.T\n","    ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","    print(f'reg: {reg}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reg: 700| NDCG@10: 0.22988| HIT@10: 0.20394\n","reg: 690| NDCG@10: 0.23000| HIT@10: 0.20399\n","reg: 680| NDCG@10: 0.23002| HIT@10: 0.20400\n","reg: 670| NDCG@10: 0.22999| HIT@10: 0.20399\n","reg: 660| NDCG@10: 0.22989| HIT@10: 0.20393\n","reg: 650| NDCG@10: 0.22988| HIT@10: 0.20393\n"]}],"source":["for reg in [700, 690, 680, 670, 660, 650]:\n","    model = EASE(X = X, reg = reg)\n","    model.fit()\n","    ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","    print(f'reg: {reg}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["```\n","reg: 700| NDCG@10: 0.22988| HIT@10: 0.20394\n","reg: 690| NDCG@10: 0.23000| HIT@10: 0.20399\n","reg: 680| NDCG@10: 0.23002| HIT@10: 0.20400\n","reg: 670| NDCG@10: 0.22999| HIT@10: 0.20399\n","reg: 660| NDCG@10: 0.22989| HIT@10: 0.20393\n","reg: 650| NDCG@10: 0.22988| HIT@10: 0.20393\n","\n","```\n","\n","\n","```\n","reg: 2000| NDCG@10: 0.80268| HIT@10: 0.20152\n","reg: 1750| NDCG@10: 0.80528| HIT@10: 0.20213\n","reg: 1500| NDCG@10: 0.80705| HIT@10: 0.20266\n","reg: 1250| NDCG@10: 0.81055| HIT@10: 0.20325\n","reg: 1000| NDCG@10: 0.81406| HIT@10: 0.20379\n","reg: 750| NDCG@10: 0.81333| HIT@10: 0.20384\n","reg: 500| NDCG@10: 0.81348| HIT@10: 0.20368\n","reg: 250| NDCG@10: 0.80783| HIT@10: 0.20184\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```\n","reg: 1000000| NDCG@10: 0.42655| HIT@10: 0.10462\n","reg: 500000| NDCG@10: 0.45418| HIT@10: 0.11143\n","reg: 100000| NDCG@10: 0.56748| HIT@10: 0.14133\n","reg: 50000| NDCG@10: 0.62661| HIT@10: 0.15648\n","reg: 10000| NDCG@10: 0.74031| HIT@10: 0.18604\n","reg: 5000| NDCG@10: 0.77833| HIT@10: 0.19488\n","reg: 1000| NDCG@10: 0.81406| HIT@10: 0.20379\n","reg: 500| NDCG@10: 0.81348| HIT@10: 0.20368\n","reg: 100| NDCG@10: 0.79378| HIT@10: 0.19739\n","reg: 50| NDCG@10: 0.77457| HIT@10: 0.19264\n","\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```\n","reg: 1000000| NDCG@10: 0.46015| HIT@10: 0.11131\n","reg: 100000| NDCG@10: 0.57234| HIT@10: 0.14224\n","reg: 10000| NDCG@10: 0.72272| HIT@10: 0.18252\n","reg: 1000| NDCG@10: 0.79034| HIT@10: 0.19934\n","reg: 100| NDCG@10: 0.77785| HIT@10: 0.19445\n","reg: 10| NDCG@10: 0.73045| HIT@10: 0.18189\n","reg: 1| NDCG@10: 0.70640| HIT@10: 0.17564\n","reg: 0.1| NDCG@10: 0.70441| HIT@10: 0.17476\n","reg: 0.01| NDCG@10: 0.70451| HIT@10: 0.17470\n","reg: 0.001| NDCG@10: 0.70453| HIT@10: 0.17469\n","reg: 0.0001| NDCG@10: 0.70453| HIT@10: 0.17469\n","reg: 1e-05| NDCG@10: 0.70453| HIT@10: 0.17469\n","\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 6. 예측"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_test = make_matrix_data_set.make_sparse_matrix(test = True)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["model = EASE(X = X_test, reg = config.reg)\n","model.fit()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["candidate = make_matrix_data_set.make_year_candidate_item(train = False)\n","new_X = make_matrix_data_set.m_s_m(candidate)\n","# new_X = 1 - new_X.todense()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["user2rec_list = predict(\n","    model = model, \n","    X = new_X.todense(),\n","    )\n","\n","submision = []\n","users = [i for i in range(0, make_matrix_data_set.num_user)]\n","for user in users:\n","    rec_item_list = user2rec_list[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# 유저 기반 / 아이템 기반 앙상블"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n","X = make_matrix_data_set.make_sparse_matrix()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["model1 = EASE(X = X, reg = 750)\n","model1.fit()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model2 = EASE(X = X.T, reg = 4400)\n","model2.fit()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def evaluate6(model1, model2, RecVAE, X, user_train, user_valid, candidate_cnt):\n","    RecVAE.eval()\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat1 = model1.pred.cpu()\n","    score1 = recon_mat1 * torch.from_numpy(1 - X)\n","    rec_list1 = score1.argsort(dim = 1)\n","\n","    recon_mat2 = model2.pred.T.cpu()\n","    score2 = recon_mat2 * torch.from_numpy(1 - X)\n","    rec_list2 = score2.argsort(dim = 1)\n","\n","    recon_mat3 = RecVAE(torch.from_numpy(X).to(device), calculate_loss = False).cpu()\n","    score3 = recon_mat3 * torch.from_numpy(1 - X)\n","    rec_list3 = score3.argsort(dim = 1)\n","\n","    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n","\n","    for user, (rec1, rec2, rec3) in enumerate(zip(rec_list1, rec_list2, rec_list3)):\n","        uv = user_valid[user]\n","\n","        # ranking\n","        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","\n","        items = list(set(rec1 + rec2 + rec3))\n","\n","        movie_df = pd.DataFrame(index = items)\n","        movie_df.loc[rec1, 'rec1_score'] = score_li\n","        movie_df.loc[rec2, 'rec2_score'] = score_li\n","        movie_df.loc[rec3, 'rec3_score'] = score_li\n","        movie_df = movie_df.fillna(min(score_li))\n","        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score']\n","        movie_df = movie_df.sort_values('total_score', ascending = False)\n","        up = movie_df.index.tolist()[:10]\n","\n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(user_train)\n","    HIT /= len(user_train)\n","\n","    return NDCG, HIT"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["model = RecVAE(\n","    input_dim = make_matrix_data_set.num_item,).to(device)\n","\n","model.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_X = X.todense()\n","\n","for candidate_cnt in [3] + [5 * i for i in range(1, 21)]:\n","    ndcg, hit = evaluate6(model1 = model1, model2 = model2, RecVAE = model, X = new_X, user_train = user_train, user_valid = user_valid, candidate_cnt = candidate_cnt)\n","    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["```\n","candidate_cnt: 3| NDCG@10: 0.46175| HIT@10: 0.13643\n","candidate_cnt: 5| NDCG@10: 0.35405| HIT@10: 0.18237\n","candidate_cnt: 10| NDCG@10: 0.31403| HIT@10: 0.20607\n","candidate_cnt: 15| NDCG@10: 0.31528| HIT@10: 0.20717\n","candidate_cnt: 20| NDCG@10: 0.31590| HIT@10: 0.20775\n","candidate_cnt: 25| NDCG@10: 0.31634| HIT@10: 0.20822\n","candidate_cnt: 30| NDCG@10: 0.31650| HIT@10: 0.20833\n","candidate_cnt: 35| NDCG@10: 0.31657| HIT@10: 0.20840\n","candidate_cnt: 40| NDCG@10: 0.31667| HIT@10: 0.20850\n","candidate_cnt: 45| NDCG@10: 0.31669| HIT@10: 0.20852\n","candidate_cnt: 50| NDCG@10: 0.31672| HIT@10: 0.20852\n","candidate_cnt: 55| NDCG@10: 0.31676| HIT@10: 0.20859\n","candidate_cnt: 60| NDCG@10: 0.31678| HIT@10: 0.20856\n","candidate_cnt: 65| NDCG@10: 0.31674| HIT@10: 0.20855\n","candidate_cnt: 70| NDCG@10: 0.31675| HIT@10: 0.20855\n","candidate_cnt: 75| NDCG@10: 0.31673| HIT@10: 0.20856\n","candidate_cnt: 80| NDCG@10: 0.31677| HIT@10: 0.20855\n","candidate_cnt: 85| NDCG@10: 0.31676| HIT@10: 0.20856\n","candidate_cnt: 90| NDCG@10: 0.31679| HIT@10: 0.20856\n","candidate_cnt: 95| NDCG@10: 0.31678| HIT@10: 0.20857\n","candidate_cnt: 100| NDCG@10: 0.31677| HIT@10: 0.20856\n","```"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def evaluate5(model1, model2, GMF, X, user_train, user_valid):\n","    GMF.eval()\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat1 = model1.pred.cpu()\n","    score1 = recon_mat1 * torch.from_numpy(1 - X)\n","    rec_list1 = score1.argsort(dim = 1)\n","\n","    recon_mat2 = model2.pred.T.cpu()\n","    score2 = recon_mat2 * torch.from_numpy(1 - X)\n","    rec_list2 = score2.argsort(dim = 1)\n","\n","    for user, (rec1, rec2) in enumerate(zip(rec_list1, rec_list2)):\n","        uv = user_valid[user]\n","\n","        # ranking\n","        rec1 = rec1[-10:].cpu().numpy().tolist()[::-1]\n","        rec2 = rec2[-10:].cpu().numpy().tolist()[::-1]\n","\n","        items = list(set(rec1 + rec2))\n","        users = [user] * len(items)\n","\n","        items = torch.LongTensor(items).to(device)\n","        users = torch.LongTensor(users).to(device)\n","\n","        output = GMF(users, items).sigmoid()\n","        up = items[output.argsort()]\n","        up = up[-10:].cpu().numpy().tolist()\n","\n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(rec_list1)\n","    HIT /= len(rec_list1)\n","\n","    return NDCG, HIT"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["gmf = GMF(\n","        num_user = make_matrix_data_set.num_user, \n","        num_item = make_matrix_data_set.num_item, \n","        num_factor = 512).to(device)\n","\n","gmf.load_state_dict(torch.load(os.path.join(config.model_path, 'GMF_v2.pt')))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.23772| HIT@10: 0.19756\n"]}],"source":["ndcg, hit = evaluate5(model1 = model1, model2 = model2, GMF = gmf, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.23708| HIT@10: 0.19643\n"]}],"source":["ndcg, hit = evaluate5(model1 = model1, model2 = model2, GMF = gmf, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["def evaluate4(model1, model2, X, user_train, user_valid):\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat1 = model1.pred.cpu()\n","    score1 = recon_mat1 * torch.from_numpy(1 - X)\n","\n","    recon_mat2 = model2.pred.T.cpu()\n","    score2 = recon_mat2 * torch.from_numpy(1 - X)\n","\n","    score = score1 + score2\n","    rec_list = score.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        uv = user_valid[user]\n","        up = rec[-10:].cpu().numpy().tolist()\n","\n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(rec_list)\n","    HIT /= len(rec_list)\n","\n","    return NDCG, HIT"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.23001| HIT@10: 0.20454\n"]}],"source":["ndcg, hit = evaluate4(model1 = model1, model2 = model2, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["def evaluate1(model1, model2, X, user_train, user_valid):\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat1 = model1.pred.cpu()\n","    score1 = recon_mat1 * torch.from_numpy(1 - X)\n","    rec_list1 = score1.argsort(dim = 1)\n","\n","    recon_mat2 = model2.pred.T.cpu()\n","    score2 = recon_mat2 * torch.from_numpy(1 - X)\n","    rec_list2 = score2.argsort(dim = 1)\n","\n","    # score = score1 + score2\n","    # rec_list = score.argsort(dim = 1)\n","\n","    for user, (rec1, rec2) in enumerate(zip(rec_list1, rec_list2)):\n","        uv = user_valid[user]\n","\n","        rec1 = rec1[-10:].cpu().numpy().tolist()\n","        rec2 = rec2[-10:].cpu().numpy().tolist()\n","        \n","        left_rec1 = torch.zeros((score1.size()[1],)).float()\n","        left_rec1.scatter_(dim=0, index=torch.LongTensor(rec1), src=score1[user, rec1])\n","\n","        right_rec2 = torch.zeros((score1.size()[1],)).float()\n","        right_rec2.scatter_(dim=0, index=torch.LongTensor(rec2), src=score2[user, rec2])\n","        \n","        lett_rec = left_rec1 + right_rec2\n","        \n","        left_rec1 = torch.zeros((score1.size()[1],)).float()\n","        left_rec1.scatter_(dim=0, index=torch.LongTensor(rec2), src=score1[user, rec2])\n","\n","        right_rec2 = torch.zeros((score1.size()[1],)).float()\n","        right_rec2.scatter_(dim=0, index=torch.LongTensor(rec1), src=score2[user, rec1])\n","\n","        right_rec = left_rec1 + right_rec2\n","\n","        rec = lett_rec + right_rec\n","        rec = rec.argsort(dim = 0)\n","        up = rec[-10:].cpu().numpy().tolist()\n","\n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(rec_list1)\n","    HIT /= len(rec_list1)\n","\n","    return NDCG, HIT"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.23064| HIT@10: 0.20454\n"]}],"source":["ndcg, hit = evaluate1(model1 = model1, model2 = model2, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def evaluate3(model, model2, X, user_train, user_valid):\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat = model.pred.cpu()\n","    score = recon_mat * torch.from_numpy(1 - X)\n","    rec_list = score.argsort(dim = 1)\n","\n","    recon_mat2 = model2.pred.T.cpu()\n","    score2 = recon_mat2 * torch.from_numpy(1 - X)\n","    rec_list2 = score2.argsort(dim = 1)\n","\n","    for user, (rec1, rec2) in enumerate(zip(rec_list, rec_list2)):\n","        uv = user_valid[user]\n","\n","        # ranking\n","        rec1 = rec1[-10:].cpu().numpy().tolist()[::-1]\n","        rec2 = rec2[-10:].cpu().numpy().tolist()[::-1]\n","\n","        up = list(set(rec1 + rec2))\n","        \n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(rec_list)\n","    HIT /= len(rec_list)\n","\n","    return NDCG, HIT"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NDCG@10: 0.23462| HIT@10: 0.22666\n"]}],"source":["ndcg, hit = evaluate3(model = model1, model2 = model2, X = X.todense(), user_train = user_train, user_valid = user_valid)\n","print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["랭킹만 잘 하면 0.18 까지 성능이 오를 수 있을 거 같음"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def evaluate2(model1, model2, X, user_train, user_valid, candidate_cnt):\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat1 = model1.pred.cpu()\n","    score1 = recon_mat1 * torch.from_numpy(1 - X)\n","    rec_list1 = score1.argsort(dim = 1)\n","\n","    recon_mat2 = model2.pred.T.cpu()\n","    score2 = recon_mat2 * torch.from_numpy(1 - X)\n","    rec_list2 = score2.argsort(dim = 1)\n","\n","    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n","\n","    for user, (rec1, rec2) in enumerate(zip(rec_list1, rec_list2)):\n","        uv = user_valid[user]\n","\n","        # ranking\n","        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","\n","        total_movie_list = list(set(rec1 + rec2))\n","        \n","        movie_df = pd.DataFrame(index = total_movie_list)\n","        movie_df.loc[rec1, 'rec1_score'] = score_li\n","        movie_df.loc[rec2, 'rec2_score'] = score_li\n","        movie_df = movie_df.fillna(min(score_li))\n","        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score']\n","        movie_df = movie_df.sort_values('total_score', ascending = False)\n","        up = movie_df.index.tolist()[:10]\n","\n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(rec_list)\n","    HIT /= len(rec_list)\n","\n","    return NDCG, HIT"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["candidate_cnt: 5| NDCG@10: 0.40381| HIT@10: 0.15412\n","candidate_cnt: 10| NDCG@10: 0.31017| HIT@10: 0.20377\n","candidate_cnt: 15| NDCG@10: 0.31043| HIT@10: 0.20400\n","candidate_cnt: 20| NDCG@10: 0.31048| HIT@10: 0.20407\n","candidate_cnt: 25| NDCG@10: 0.31066| HIT@10: 0.20422\n","candidate_cnt: 30| NDCG@10: 0.31063| HIT@10: 0.20423\n","candidate_cnt: 35| NDCG@10: 0.31052| HIT@10: 0.20417\n"]}],"source":["for candidate_cnt in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]:\n","    ndcg, hit = evaluate2(model = model, model2 = model2, X = X.todense(), user_train = user_train, user_valid = user_valid, candidate_cnt = candidate_cnt)\n","    print(f'candidate_cnt: {candidate_cnt}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["```\n","1 / rank\n","\n","candidate_cnt: 5| NDCG@10: 0.94358| HIT@10: 0.15412\n","candidate_cnt: 10| NDCG@10: 1.09908| HIT@10: 0.20377\n","candidate_cnt: 15| NDCG@10: 1.09999| HIT@10: 0.20402\n","candidate_cnt: 20| NDCG@10: 1.09996| HIT@10: 0.20398\n","candidate_cnt: 25| NDCG@10: 1.10004| HIT@10: 0.20403\n","candidate_cnt: 30| NDCG@10: 1.10003| HIT@10: 0.20404\n","candidate_cnt: 35| NDCG@10: 1.10004| HIT@10: 0.20401\n","\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```\n","1 / log2(rank)\n","\n","candidate_cnt: 5| NDCG@10: 0.40381| HIT@10: 0.15412\n","candidate_cnt: 10| NDCG@10: 0.31017| HIT@10: 0.20377\n","candidate_cnt: 15| NDCG@10: 0.31043| HIT@10: 0.20400\n","candidate_cnt: 20| NDCG@10: 0.31048| HIT@10: 0.20407\n","candidate_cnt: 25| NDCG@10: 0.31066| HIT@10: 0.20422\n","candidate_cnt: 30| NDCG@10: 0.31063| HIT@10: 0.20423\n","candidate_cnt: 35| NDCG@10: 0.31052| HIT@10: 0.20417\n","\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## 예측"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","make_matrix_data_set = MakeMatrixDataSet(config = config)\n","X_test = make_matrix_data_set.make_sparse_matrix(test = True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["model1 = EASE(X = X_test, reg = 750)\n","model1.fit()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model2 = EASE(X = X_test.T, reg = 4400)\n","model2.fit()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model = RecVAE(\n","    input_dim = make_matrix_data_set.num_item,).to(device)\n","\n","model.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v3.pt')))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def predict1(model1, model2, RecVAE, X, candidate_cnt):\n","    RecVAE.eval()\n","\n","    recon_mat1 = model1.pred.cpu()\n","    score1 = recon_mat1 * torch.from_numpy(1 - X)\n","    rec_list1 = score1.argsort(dim = 1)\n","\n","    recon_mat2 = model2.pred.T.cpu()\n","    score2 = recon_mat2 * torch.from_numpy(1 - X)\n","    rec_list2 = score2.argsort(dim = 1)\n","\n","    recon_mat3 = RecVAE(torch.from_numpy(X).to(device), calculate_loss = False).cpu()\n","    score3 = recon_mat3 * torch.from_numpy(1 - X)\n","    rec_list3 = score3.argsort(dim = 1)\n","\n","    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n","\n","    user2rec = {}\n","\n","    for user, (rec1, rec2, rec3) in enumerate(zip(rec_list1, rec_list2, rec_list3)):\n","        # ranking\n","        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","        rec3 = rec3[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","\n","        items = list(set(rec1 + rec2 + rec3))\n","\n","        movie_df = pd.DataFrame(index = items)\n","        movie_df.loc[rec1, 'rec1_score'] = score_li\n","        movie_df.loc[rec2, 'rec2_score'] = score_li\n","        movie_df.loc[rec3, 'rec3_score'] = score_li\n","        movie_df = movie_df.fillna(min(score_li))\n","        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score'] + movie_df['rec3_score']\n","        movie_df = movie_df.sort_values('total_score', ascending = False)\n","        up = movie_df.index.tolist()[:10]\n","\n","        user2rec[user] = up\n","\n","    return user2rec"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def predict2(model1, model2, X, candidate_cnt):\n","    user2rec = {}\n","\n","    recon_mat1 = model1.pred.cpu()\n","    score1 = recon_mat1 * torch.from_numpy(1 - X)\n","    rec_list1 = score1.argsort(dim = 1)\n","\n","    recon_mat2 = model2.pred.T.cpu()\n","    score2 = recon_mat2 * torch.from_numpy(1 - X)\n","    rec_list2 = score2.argsort(dim = 1)\n","\n","    score_li = np.array([1 / np.log2(rank + 2) for rank in range(0, candidate_cnt)])\n","\n","    for user, (rec1, rec2) in enumerate(zip(rec_list1, rec_list2)):\n","        # ranking\n","        rec1 = rec1[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","        rec2 = rec2[-candidate_cnt:].cpu().numpy().tolist()[::-1]\n","\n","        total_movie_list = list(set(rec1 + rec2))\n","        \n","        movie_df = pd.DataFrame(index = total_movie_list)\n","        movie_df.loc[rec1, 'rec1_score'] = score_li\n","        movie_df.loc[rec2, 'rec2_score'] = score_li\n","        movie_df = movie_df.fillna(min(score_li))\n","        movie_df['total_score'] = movie_df['rec1_score'] + movie_df['rec2_score']\n","        movie_df = movie_df.sort_values('total_score', ascending = False)\n","        up = movie_df.index.tolist()[:10]\n","\n","        user2rec[user] = up\n","    \n","    return user2rec"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["user2rec_list = predict1(\n","    model1 = model1, \n","    model2 = model2, \n","    RecVAE = model, \n","    X = X_test.todense(),\n","    candidate_cnt = 50)\n","\n","submision = []\n","users = [i for i in range(0, make_matrix_data_set.num_user)]\n","for user in users:\n","    rec_item_list = user2rec_list[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>4370</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>4886</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>40815</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>7373</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>8961</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>313595</th>\n","      <td>138493</td>\n","      <td>8961</td>\n","    </tr>\n","    <tr>\n","      <th>313596</th>\n","      <td>138493</td>\n","      <td>110</td>\n","    </tr>\n","    <tr>\n","      <th>313597</th>\n","      <td>138493</td>\n","      <td>5349</td>\n","    </tr>\n","    <tr>\n","      <th>313598</th>\n","      <td>138493</td>\n","      <td>1022</td>\n","    </tr>\n","    <tr>\n","      <th>313599</th>\n","      <td>138493</td>\n","      <td>8970</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>313600 rows × 2 columns</p>\n","</div>"],"text/plain":["          user   item\n","0           11   4370\n","1           11   4886\n","2           11  40815\n","3           11   7373\n","4           11   8961\n","...        ...    ...\n","313595  138493   8961\n","313596  138493    110\n","313597  138493   5349\n","313598  138493   1022\n","313599  138493   8970\n","\n","[313600 rows x 2 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["submision"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm3klEQVR4nO3deZwcdZ3/8den7zkzycwkkzvBhBwGEIiAZEUi+CMgx6Ii4rErKPxWZT3Wh4qrsq7rY3cV9ScquIuusuguIIKYVYRlOWS5JAnhSsIRAiSTczJJJnP39f39UdUznclM0pPMTE91v5+PRz+q6lvf7voWHd71nW9VV5lzDhERCb5QsRsgIiIjQ4EuIlIiFOgiIiVCgS4iUiIU6CIiJSJSrA03NDS4OXPmFGvzIiKBtGbNmt3OucbB1hUt0OfMmcPq1auLtXkRkUAyszeGWqchFxGREqFAFxEpEQp0EZESUbQxdBGRQqVSKZqbm+np6Sl2U8ZMIpFgxowZRKPRgt+jQBeRca+5uZmamhrmzJmDmRW7OaPOOUdrayvNzc3MnTu34PcddsjFzH5mZrvM7IUh1puZ/cDMNprZc2Z20jDaLSJyWD09PdTX15dFmAOYGfX19cP+i6SQMfSbgRWHWH8uMN9/XQX8eFgtEBEpQLmEec6R7O9hA9059wiw5xBVLgJucZ4ngTozmzrslhRow5/u44mffJZMOjVamxARCaSRuMplOrAlb7nZLzuImV1lZqvNbHVLS8sRbaztlSd429af09XZfkTvFxEpVWN62aJz7ibn3FLn3NLGxkF/uXpYoWgCgJ7urpFsmojIIVVXVxe7CYc1EoG+FZiZtzzDLxsVYT/Qe3u7R2sTIiKBNBKXLa4Erjaz24BTgTbn3PYR+NxBReIVgHroIuXq7/9rHeu37R/Rz1w8rZa/u+DNBdV1zvHFL36RP/zhD5gZX/3qV7n00kvJZrNcffXVPPjgg8ycOZNoNMoVV1zB+973voM+48EHH+QHP/gBd999NwD3338/N954I7/5zW+Oaj8OG+hmditwJtBgZs3A3wFRf8f+BbgHOA/YCHQBlx9Viw4jHPN76D3qoYvI2Lvrrrt45plnePbZZ9m9ezdvfetbOeOMM3jsscd4/fXXWb9+Pbt27WLRokVcccUVg37G8uXL+eQnP0lLSwuNjY38/Oc/H7LucBw20J1zlx1mvQM+ddQtKVDU76Gne9VDFylHhfakR8ujjz7KZZddRjgcZsqUKbzjHe9g1apVPProo1xyySWEQiGamppYvnz5kJ9hZnzkIx/hl7/8JZdffjlPPPEEt9xyy1G3LXC/FI3FvEBPqocuIgF2+eWXc8EFF5BIJLjkkkuIRI4+jgN3c65owgv0lHroIlIEb3/727n99tvJZDK0tLTwyCOPcMopp7Bs2TLuvPNOstksO3fu5OGHHz7k50ybNo1p06bxzW9+k8svH5mR6uD10BOVAKST5XOTHhEZPy6++GKeeOIJTjjhBMyMb3/72zQ1NfHe976XBx54gMWLFzNz5kxOOukkJkyYcMjP+tCHPkRLSwuLFi0akbYFLtDjfYGuIRcRGTsdHR2AN/593XXXcd111x2wPhQK8Z3vfIfq6mpaW1s55ZRTOO644w75mY8++ihXXnnliLUxcIGeqPACPaMeuoiMM+effz779u0jmUzyta99jaampiHrnnzyyVRVVfHd7353xLYfuECP+Ve5ZFMKdBEZXwYbN7/44ot57bXXDij71re+xZo1a0Z8+4ELdIsq0EUkOI72x0LDEbirXIjEAQW6iMhAAQx075eipHuL2w4RkXEmeIEeipDFIK0euohIvuAFuhkpYgp0EZEBghfoQMqimIZcREQOEMhAT4fihLIKdBEZG9deey3f//73+5a/8pWvcP311xevQUMI3GWLAOlQjFAmWexmiEgx/OEa2PH8yH5m03Fw7j8PufqKK67gPe95D5/97GfJZrPcdtttPPXUUyPbhhEQyEDPhGKEUgp0ERkbc+bMob6+nrVr17Jz505OPPFE6uvri92sgwQ00ONENOQiUp4O0ZMeTR//+Me5+eab2bFjx4g8jGI0BHIMPRuOE8mqhy4iY+fiiy/m3nvvZdWqVZxzzjnFbs6gAtlDd+EYUTpJZ7JEwoE8JolIwMRiMZYvX05dXR3hcLjYzRlUIAOdcJw4e+lOZahRoIvIGMhmszz55JPccccdxW7KkAKZhi6SIE6K7mSm2E0RkTKwfv165s2bx1lnncX8+fOL3ZwhBbKHbpE4cVJ0KdBFZAwsXryYTZs2FbsZhxXIHrpFE8QtRXdKgS5SLpxzxW7CmDqS/Q1soMfUQxcpG4lEgtbW1rIJdeccra2tJBKJYb0vkEMu4WiFxtBFysiMGTNobm6mpaWl2E0ZM4lEghkzZgzrPYEM9FDMPymqIReRshCNRpk7d26xmzHuBXLIJRyrIG5punr14yIRkZxABno05o0rJXu6i9wSEZHxI5CBHskFeq8CXUQkJ5CBHo1XApDs6SpyS0RExo9ABnok7vXQ0+qhi4j0CWSgW8QL9FSvnisqIpJTUKCb2Qoze8nMNprZNYOsn2VmD5nZWjN7zszOG/mm5vEDPZ1SoIuI5Bw20M0sDNwAnAssBi4zs8UDqn0V+JVz7kTgA8CNI93QA/iBnklqDF1EJKeQHvopwEbn3CbnXBK4DbhoQB0H1PrzE4BtI9fEQUTiAGSS6qGLiOQUEujTgS15y81+Wb6vAx82s2bgHuCvB/sgM7vKzFab2eqj+gmvH+hZDbmIiPQZqZOilwE3O+dmAOcBvzCzgz7bOXeTc26pc25pY2PjkW/ND3SnQBcR6VNIoG8FZuYtz/DL8n0M+BWAc+4JIAE0jEQDB+WPobu0Al1EJKeQQF8FzDezuWYWwzvpuXJAnc3AWQBmtggv0Efvtmh+D93SvaO2CRGRoDlsoDvn0sDVwH3ABryrWdaZ2TfM7EK/2ueBK83sWeBW4KNuNG9c7PfQUaCLiPQp6Pa5zrl78E525pddmze/Hlg2sk07hFwPPaMhFxGRnED+UjTXQ7eMbp8rIpITzEAPez30SDZJOpMtcmNERMaHYAZ6KETGosQtRZeeWiQiAgQ10IFMKEacFD16rqiICBDgQM+G48RJ0qVAFxEBAhzoLhwnTkqBLiLiC26gR+LELUW3xtBFRIAABzoRr4ferR66iAgQ6EBPECNFVzJd7JaIiIwLgQ10iyS8HrqGXEREgCAHejThjaFryEVEBAhwoIejuspFRCRfYAM9FNOQi4hIvuAGejRB3JIachER8QU20C2SIEFaQy4iIr7ABjoR/6RoSpctiohAoAPdu5eLhlxERDwBDvQEUdJ09aqHLiICgQ70OGGyJFN6apGICAQ60L3H0KV7u4vcEBGR8SG4ge4/hi6d1IOiRUQgyIEe8QI9m1IPXUQEAh3o3pCLS6mHLiICgQ70XA9dgS4iAoEOdL+Hnlagi4hAoAPd66GHM0lSmWyRGyMiUnwBDnSvhx7Tc0VFRIBAB7rXQ9dzRUVEPCUR6Ls7eovcGBGR4gtwoHtDLnFSbNunE6MiIgEOdL+Hbim27u0qcmNERIqvoEA3sxVm9pKZbTSza4ao834zW29m68zsP0e2mYPwe+hVoRTb2tRDFxGJHK6CmYWBG4B3Ac3AKjNb6Zxbn1dnPvBlYJlzbq+ZTR6tBvfxe+iNFfDCPv38X0SkkB76KcBG59wm51wSuA24aECdK4EbnHN7AZxzu0a2mYPwe+gNCcc2BbqISEGBPh3Ykrfc7JflOxY41sweM7MnzWzFYB9kZleZ2WozW93S0nJkLc4JRcBCTIxlFegiIozcSdEIMB84E7gM+ImZ1Q2s5Jy7yTm31Dm3tLGx8ei2aAaRBHUxx672XpJp/VpURMpbIYG+FZiZtzzDL8vXDKx0zqWcc68BL+MF/OiKxJkQzeIc7NyvE6MiUt4KCfRVwHwzm2tmMeADwMoBde7G651jZg14QzCbRq6ZQwjHqYl4zxTdqmEXESlzhw1051wauBq4D9gA/Mo5t87MvmFmF/rV7gNazWw98BDwBedc62g1uk8kTlXYC3SNo4tIuTvsZYsAzrl7gHsGlF2bN++Av/FfYyeSoDKkQBcRgSD/UhQgEiecTdJQHdOQi4iUvYAHegLSPUyrq2Cr7uciImUu4IEeh3Qv0yZUaMhFRMpewAO9v4e+bV833lC+iEh5CnigxyGdZFpdgq5khrbuVLFbJCJSNCUQ6D1Mr6sAdC26iJS3gAd6whtD9wNdD7oQkXIW8ECP942hg65FF5HyFvBA93ro9VUxYpGQAl1EylrAA93roYdCxrQJCZoV6CJSxgIe6AnIpiCb6bt0UUSkXAU80L3H0OVOjCrQRaScBTzQvcfQkfECXQ+6EJFyFvBA7++hT69L4BzsaNOliyJSnoId6LEab9rTxpsaqwF4aWd7ERskIlI8wQ706snetGMXS6ZPIBIynt68t7htEhEpkoAH+hRv2rGTRDTM4mm1PP2GAl1EylPAA72/hw5w0qyJPNfcRjqjE6MiUn6CHeiJOghFodML9BNn1dGdyvDiDo2ji0j5CXagh0JeLz2vhw6wVuPoIlKGgh3oAFWN0LETgBkTK2isifP05n3FbZOISBEEP9Crp/T10M2Mk2bV6UoXESlLJRDo/UMu4A27vNHaxe6O3iI2SkRk7JVGoHe2QNa7suWk2d44+jMadhGRMlMCgT4FXAa69wBwnH5gJCJlKviBXtXoTf0To30/MFKgi0iZCX6g5/1aNOekWRN5dot+YCQi5aWEAr2lr0g/MBKRclQCgX7gkAvA6W9qIGRw37odRWqUiMjYC36gx2u9B13kBXpjTZxl8xr47TPbcM4VsXEiImMn+IFu1n/pYp4LT5jG5j1dPLNlX3HaJSIyxgoKdDNbYWYvmdlGM7vmEPXea2bOzJaOXBMLUDX5gB46wDlLmohFQvz2mW1j2hQRkWI5bKCbWRi4ATgXWAxcZmaLB6lXA3wG+NNIN/Kw8n7+n1ObiHLWwsn87rntutpFRMpCIT30U4CNzrlNzrkkcBtw0SD1/gH4FjD2D/Uc8PP/nIveMo3dHb08sal1zJskIjLWCgn06cCWvOVmv6yPmZ0EzHTO/f5QH2RmV5nZajNb3dLScqiqw1M9GbpaIZM6oPjMBZOpiUc07CIiZeGoT4qaWQj4HvD5w9V1zt3knFvqnFva2Nh4tJvuVz0ZcNC5+4DiRDTMiiVN3PvCDnpSmZHbnojIOFRIoG8FZuYtz/DLcmqAJcDDZvY6cBqwckxPjOZ+XNQ52LDLdDp609z7gq5JF5HSVkigrwLmm9lcM4sBHwBW5lY659qccw3OuTnOuTnAk8CFzrnVo9LiwVQd+GzRfKe/qZ5jp1Tzo4c2ksnqmnQRKV2HDXTnXBq4GrgP2AD8yjm3zsy+YWYXjnYDC9L3sOidB60KhYzPnHUsG3d18LvnNJYuIqUrUkgl59w9wD0Dyq4dou6ZR9+sYaoeuocOcO6SJhZMqeEHD7zC+cdPIxyyMWyciMjYCP4vRQFiVRCrHjLQQyHjM2fP59WWTvXSRaRklUagg38t+sFDLjkr3tzEwqYarn/gFY2li0hJKqFAn3LQ/VzyhULGZ8+ez6aWTn69ZsuQ9UREgqp0Ar2q8ZA9dID/s7iJU+ZO4pu/38D2tu4xapiIyNgonUCvnnLYQA+FjOvedzzpjONLdz6vW+uKSEkprUDvaYN07yGrza6v4svnLeSRl1u4fZWGXkSkdJRQoOeeXDT4lS75PnzqbN52TD3f/P0Gmvd2jXLDRETGRukEes00b9p2+F53KGR8+33HA/B/f7GGzt70aLZMRGRMlE6gT/Fv0b5zXUHVZ06q5IcfPJEXd7Tz17eu1aWMIhJ4pRPotdMhUQc7ni/4LcsXTObrF76ZB1/cxTf+a51OkopIoBX00/9AMIOm42DnC8N620dOm83m1k5+8r+vMbk2waeWzxulBoqIjK7SCXTwAn31zyGbgVC44Ld9+dxF7Grv5br7XqKzN80XzlmAme73IiLBUlqBPmUJpLuh9VVoPLbgt4VCxvfe/xYqYxFufPhV9vek+MaFSwjpJl4iEiClFehNS7zpzueHFegA4ZDxjxcvoTYR4V8f2cTu9iTfef8JVMdL6z+RiJSu0jkpCtC4EEIR2DG8cfQcM+Oacxfy1Xcv4v4NO7nwR4/yys72EW6kiMjoKK1Aj8ShYcGwrnQZyMz4+NuP4T8+fir7u1NcdMNj/GZts66AEZFxr7QCHbxhl2Fe6TKY046p5/effjtvnlbL525/litvWcPO/T0j0EARkdFReoE+ZQm0b4fO3Uf/UbUJbrvqbXz13Yv431daOPt7f+Q//7RZP0ISkXGp9AK96ThvehTDLvnCIW8I5t7PnsGiqbX87W+e5/wfPsrjrx79AUNEZCSVbqCPwLBLvrkNVdx+1Wn88LIT2d+d4oM/+RMfu3kVzze3jeh2RESOVOkFelUDVDcd8ZUuh2JmXHDCNB74/Dv44ooFrH5jLxf86FGuuHkVT2/eO+LbExEZjtILdDiiWwAMRyIa5pNnzuPRLy3nC+csYO3mvbznxse5+MbHWPnsNlKZ7KhtW0RkKKX5q5mmJbDpIe9hF5H4qG2mJhHlU8vn8dHT53DH6i3c/PjrfPrWtUyuiXPJ0hm8f+lMZtdXjdr2RUTylWagT1kC2TS0vAhTTxj1zVXFI3x02Vz+4m1zePjlXfzyyc38+OFXueGhVzl17iT+/MTpnLukibrK2Ki3RUTKV2kG+sxTvemmh8ck0HNCIeOdC6fwzoVT2NHWw51PN3Pnmma+fNfzfO3uFzjj2EZWvLmJsxZNpr569P5yEJHyZMX6BeTSpUvd6tWrR28D//JnEK2Cj903etsogHOOddv2s/LZbfz+ue1s3ddNyGDpnEm8c+FkzlzQyIIpNbq7o4gUxMzWOOeWDrquZAP9oX+CP34LvrDRu/JlHMiF+3+v28F/r9/Jizu8+8RMnZBg2bwGls2rZ9mbGphcmyhyS0VkvCrPQN/+LPzrGXDRDXDih0dvO0dhR1sPf3x5F398uYXHX21lX1cK8K55P2XOJN46dxJLZ09kdn2levAiApRroDsH3z8Omo6Hy/5z9LYzQrJZx/rt+3n81d089dpeVr2+h7ZuL+Drq2KcOKuOt8ys4/gZdRw/Y4JOsIqUqUMFemmeFAXvkXQLzoWnfwHJLohVFrtFhxQKGUumT2DJ9AlcdYYX8K/s6mDNG3t5erP3+p8Nu/rqz5xUweKptbx52gQWT61l4dQaptdVqCcvUsZKN9ABFpwHT93kXe2y8Lxit2ZYQiFjQVMNC5pq+OCpswDY35PiheY2nm1u44Vtbazftp/71u3se09NIsKCKTXMn1LDginVzJ9Sw7zJ1UyuiSvoRcpAQYFuZiuA64Ew8FPn3D8PWP83wMeBNNACXOGce2OE2zp8s5dBvBZe+n3gAn0wtYkop89r4PR5/Sd523tSvLyznQ3b29mwfT8v72znnue3c+tTqb46NfEIxzRWMbehimMaq5nTUMXc+ipmN1RSm4gWY1dEZBQcNtDNLAzcALwLaAZWmdlK59z6vGprgaXOuS4z+wTwbeDS0WjwsERiMP9d8NK9w35wdFDUJKKcPHsSJ8+e1FfmnKOlvZeNuzrY2NLBq7s6eLWlk1Wv7+XuZ7Yd8P6JlVFm1Vcxc2IFsyZVMnNSJTMmVjBzYiVT6xLEI6X330ykVBXSQz8F2Oic2wRgZrcBFwF9ge6ceyiv/pPA+LmsZMF58MKdsOUpmP22YrdmTJgZk2sTTK5NHNCbB+hJZXi9tZM3Wrt4o7WT13Z30by3i+e3tnHvCztID7jXe2NNnOl1FUyrSzB1QgXT6iqYOiFB04QEUyckaKyOEwmX5i2BRIKmkECfDmzJW24GTj1E/Y8BfxhshZldBVwFMGvWrAKbeJSOPccbdnnqprIJ9ENJRMMsbKplYVPtQevSmSw723vZsqeL5r3dbN3bzbZ93Wzd182LO9p56MUWulOZA95jBg3VcZpqE0ypjdNY400n1ySYXBOnsSZOQ02chuqYevsio2xET4qa2YeBpcA7BlvvnLsJuAm8yxZHcttDitfA0svh8R/Cnmth0twx2WwQRcIhptdVML2uYtD1zjn2daXYsb+HHW09bG/rYcf+Hnb60637eli7eR+tnclB31+biHjhXhWnoSZGfVWc+uoY9dVx6qtiTMp71VVE1fMXGaZCAn0rMDNveYZfdgAzOxv4CvAO51zvyDRvhJz6CXjyx/DEDfDu7xS7NYFlZkysijGxKsaiqQf38HOS6Sytnb20tPeya38vLR297G73pq0dSVo6enlxRzt7Ovt/TDWYCRVRJlZGvW1WxqirjHrTiih1fujXVUapq/DW1VZEqYlHCIV0RY+Up0ICfRUw38zm4gX5B4AP5lcwsxOBfwVWOOd2HfwRRVY7FY6/FNb+Es68ZtzcCqBUxSIhpk6oYOqEwXv6+VKZLHu7kuzpTLKnI0lrpze/tyvJ3k5veV9Xip37e3hpRzv7upJ0JjNDfl7IvBPFEyr6X7UVEWoT/YFfWxGlJuGV1SQi1CT6l6sTEcI6IEhAHTbQnXNpM7sauA/vssWfOefWmdk3gNXOuZXAdUA1cId/vfNm59yFo9ju4Tv907D2F95Y+vK/LXZrxBcNh/zx9sLvX9ObztDWlaKtO8W+7hR7O5O0dacOeO3PTXvS7NjfQ1t3ivaeFD2pwz98pDIWpjoeoSYRoTrhHQSq4mGq417w5+ar42Gq4hHvFcuVR6iMR6iORaiMh4lq2EjGUOn+9H8wt34QNj8On1sHMT14ohz1pjO096Rp70mzvzvlz6do7033zXf46zt607T3punoSdHRm6azN0N7T4rOZIZMtrD/b2KREFWxMJV+4FfEIv6yV1YZC1MRC1MVi1DRV+7Vq4iG+9ZXxsJURL35iqj30jmG8lSeP/0fzLLPeD8yevJGOOMLxW6NFEE8EiZeHabhKO5H75yjN52lvSdNZ2/aD/s0nUkv9LuSaTp6M3T1pulMZujsTdOV9Mo7kxm6k2m27UvRlcyVe+sKPEb0iYatL+QTfsj3T0N95flliUiuLETcX5eIhPrqJaLefDxXFgkTj4aIR0L6tXEAlFegzzoVFl0If7wOFv85NMwvdoskgMysLwAba0bmQSW5g0R3MkNnMk1PKtMX9t2pDD15893+fE/am8/V7Un5dVMZdnek++r2+vW6U5lhHzTyxSIhEpHcgSDkHRwjIf8VJpabj/aXxyL99frWD6gfy1uORULEwqED1uWWY5EQkZDpwHII5RXoAOd9B177I6z8NHz09xDSn61SfPkHiYlVo3cnzVQm2xf8vSlvvieVpSedt5z2y1IZetNZev3lXr9ObzpXnqU3VyflndxOprMk0957k5msXz9LcoQenG7GAYEf9eej4QODPxYOEQ3bQesOrG9EwyGieeV9ZeFc2YHL0QPWDz1frINO+QV6zRQ45x/ht5+CNT+Dt3682C0SGTO50KkZ43v4ZLOOZCbbF/Le1DsYJNP55RmS/sEiV547SOQv5w4SqbyyVCZLMuNIpr0DVlt3fnn/fCrj+j5rtERCRmRAyEdC/X9lfObs+Zx//LSR3+6If2IQvOVD8PwdcP/X4dgVMGFGsVskUtJCISMR8v4CYZw8kMs5RzrrhXs64x1wUn7wp7NZkmmvLO0fEFIZR9qv0+u/J5XpP0jkz6ezA8rSjlS2/z2jdVO88gx0M7jgerjxdLj9I97Qyzi/X7qIjCwz6xsqKRWlsyfDNXEOvPcnsG0t3HWldzdGEZEAK99AB1j4bljxT/Di7+D+a4vdGhGRo1KeQy75TvsE7HkNnvgRVE+BZZ8udotERI6IAh28XnrHTrj/a9C1G87+e2+cXUQkQBTo4D3J6H0/g3vq4bHroWMXXPhDCOvxbCISHAr0nFAY3v1dqJkKD30T9m2B99wEE6YXu2UiIgUp75OiA5nBO74AF9/kXf3y49Nhw38Vu1UiIgVRoA/mhEvhr/7Xu7Tx9g/D3Z+EjpZit0pE5JAU6EOpfxN87H74s8/Bc7fDD0+GJ/8FMulit0xEZFAK9EOJxODsr8MnHofpJ8G9X4IbT4PnfqVgF5FxR4FeiMYF8JHfwKX/4V35cteVcMMp8PQtkOoudutERAAFeuHMYNH58FePwaW/9O79svKv4bsL4b6vQOurxW6hiJS58noE3UhyDl5/FFb91LsSxmVgxlvhuPfDkvfoQdQiMioO9Qg6BfpI2L/dO3H63K9g1zqwEMx6Gyw4DxaeB5OOKXYLRaREKNDH0s51sO438OI9XriDd/njMcvhTcth9jL13kXkiCnQi2Xv6/Dyf8Omh+C1RyDZ4ZU3HOv14Ge8Faaf7J10DYWL2lQRCQYF+niQScHWp2Hz4/DGE7DlSehp89ZFq6DpOO819XiY/GYv5OPVxW2ziIw7CvTxKJuFPZtg6xrvteM52PECJNv769TNgoYFXo++Yb73Y6dJx0DNND3cWqRMHSrQdXOuYgmFoGGe9zrhUq8sm4V9r8OuDbBrvTfd/bJ3NU0673r3SMIL+7rZMHG2Nz9hBkyYCbXTvfu6h/XVipQb/V8/noRCXg980jHe05RyslnY3+z16Pds8q553/cG7H0Dmp/qH7rJsZAX6jVT/VeT96pq9MqrJ3snZqsaIVY1tvsoIqNGgR4EoZDfI58Fx5x58Pqe/dDWDG1bYP9W7zLK/dugfZt3YnbzE9C9Z/DPjlZCZQNUToLKem9aMcmfTux/Jeqgos6bJmohEh+13RWRI6NALwWJWkgshimLh66TTkJni/dkpo5d3pOZOlugc7f36mr1Xnteha690Ns29GeBN+yTmADxWm/78VqI1+RNqyFW7U9zy1VeWf40WukdHPSEKJGjpkAvF5GY97COQh/YkUl7Qznde71Xzz7o3udNe/Z5fxX0tEHvfm++dz+0b4fe9v4XBZ5wt5B3pU+sEqIV3ny0wn9V5k0TEKkYME146yO5+UT/fCQO4bg3zb1yy7pMVEqQAl0GF45AVb33OhLOQbLTu/a+t8ObJjsg2eVPO71XqtMv64RUl/dKdnkngVPd3kEi3ePNp7og1eOtc9mj279QxA/32IBp3LsBWzg3jeWVxSAU7Z8Px/z53LrIgWW5uqHIEMsRvyySty7szffVCfv1/DqhsP6akSEp0GV0mHnDLPFqqBnhz3bOu64/3Q3pXi/s073+QaAHMr3+co8/9delk3nreiGT9Opkkv3rMil/2Z9P7etfn0352+3159P97yn0r5GRYPkhHxkQ+gOXw/5B4FBl+cv55aH+slDEm7fQgeUHTAcrD/W/BtY3y5sPHVz/gLK8daH8OoNtw4Zeb6H+9fnbwwapE7wDZ0GBbmYrgOuBMPBT59w/D1gfB24BTgZagUudc6+PbFNFfGZejzoSK3ZL+mUzXvBnUv0HhdwBIJv2p/5BoK885b8vf52/PpvOW5fOe2Xy6mTyynLLmYPXucyA92e8g5LL9C+7gfWz3nJfnbR3IHX59f1pyRoY8gNfHFx2wHus/+Ax8LPO/BIsee+It/iwgW5mYeAG4F1AM7DKzFY659bnVfsYsNc5N8/MPgB8C7h0xFsrMl6FwhDyx/3LTTY7eNA7588Ptj7/4JAdUO4vu6z3yubN578OKM97bzYDuAPb0VdviM/H+evcgPcMNp9XJ7cdBm7DXz6o3J9P1I3KV1FID/0UYKNzbhOAmd0GXATkB/pFwNf9+V8DPzIzc8X6GaqIjJ1QCAh5Y/5SVIX8fnw6sCVvudkvG7SOcy4NtAEHnU0zs6vMbLWZrW5p0UOXRURG0pjeEMQ5d5NzbqlzbmljY+NYblpEpOQVEuhbgZl5yzP8skHrmFkEmIB3clRERMZIIYG+CphvZnPNLAZ8AFg5oM5K4C/9+fcBD2r8XERkbB32pKhzLm1mVwP34V22+DPn3Doz+waw2jm3Evg34BdmthHYgxf6IiIyhgq6Dt05dw9wz4Cya/Pme4BLRrZpIiIyHHpKgohIiVCgi4iUiKI9gs7MWoA3hvGWBmD3KDVnPCvH/S7HfYby3O9y3Gc4uv2e7Zwb9LrvogX6cJnZ6qGeo1fKynG/y3GfoTz3uxz3GUZvvzXkIiJSIhToIiIlIkiBflOxG1Ak5bjf5bjPUJ77XY77DKO034EZQxcRkUMLUg9dREQOQYEuIlIiAhHoZrbCzF4ys41mdk2x2zMazGymmT1kZuvNbJ2ZfcYvn2Rm95vZK/50YrHbOtLMLGxma83sd/7yXDP7k/993+7fFK6kmFmdmf3azF40sw1m9rYy+a4/5//7fsHMbjWzRKl932b2MzPbZWYv5JUN+t2a5wf+vj9nZicdzbbHfaDnPQLvXGAxcJmZLS5uq0ZFGvi8c24xcBrwKX8/rwEecM7NBx7wl0vNZ4ANecvfAv6fc24esBfvEYel5nrgXufcQuAEvP0v6e/azKYDnwaWOueW4N3sL/fIylL6vm8GVgwoG+q7PReY77+uAn58NBse94FO3iPwnHNJIPcIvJLinNvunHvan2/H+x98Ot6+/rtf7d+BPy9KA0eJmc0A3g381F824J14jzKE0tznCcAZeHcpxTmXdM7to8S/a18EqPCfm1AJbKfEvm/n3CN4d53NN9R3exFwi/M8CdSZ2dQj3XYQAr2QR+CVFDObA5wI/AmY4pzb7q/aAUwpVrtGyfeBLwJZf7ke2Oc/yhBK8/ueC7QAP/eHmn5qZlWU+HftnNsKfAfYjBfkbcAaSv/7hqG/2xHNtyAEelkxs2rgTuCzzrn9+ev8h4aUzHWmZnY+sMs5t6bYbRljEeAk4MfOuROBTgYMr5Tadw3gjxtfhHdAmwZUcfDQRMkbze82CIFeyCPwSoKZRfHC/D+cc3f5xTtzf4L5013Fat8oWAZcaGav4w2lvRNvbLnO/5McSvP7bgaanXN/8pd/jRfwpfxdA5wNvOaca3HOpYC78P4NlPr3DUN/tyOab0EI9EIegRd4/tjxvwEbnHPfy1uV/3i/vwR+O9ZtGy3OuS8752Y45+bgfa8POuc+BDyE9yhDKLF9BnDO7QC2mNkCv+gsYD0l/F37NgOnmVml/+89t98l/X37hvpuVwJ/4V/tchrQljc0M3zOuXH/As4DXgZeBb5S7PaM0j7+Gd6fYc8Bz/iv8/DGlB8AXgH+B5hU7LaO0v6fCfzOnz8GeArYCNwBxIvdvlHY37cAq/3v+25gYjl818DfAy8CLwC/AOKl9n0Dt+KdI0jh/TX2saG+W8DwruJ7FXge7wqgI962fvovIlIigjDkIiIiBVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlAgFuohIifj/gBJ4Kf58eT4AAAAASUVORK5CYII=","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","x = [i for i in range(1, 101)]\n","log_y = [1 / np.log2(i + 1)for i in x]\n","y = [1 / i for i in x]\n","\n","plt.plot(x, log_y, label = 'log_y')\n","plt.plot(x, y, label = 'y')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMB0K8DmOwclQIFyyBerAFJ","collapsed_sections":[],"mount_file_id":"1C1AHkN-z-DCxUIAjFfd7K56P-8-YrAJO","name":"EASE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
