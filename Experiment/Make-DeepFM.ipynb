{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from box import Box\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n",
    "    \n",
    "    'submission_path' : \"../submission\",\n",
    "    'submission_name' : 'DeepFM_v1_submission.csv', \n",
    "\n",
    "    'model_path' : \"../model\", # 모델 저장 경로\n",
    "    'model_name' : 'DeepFM_v1.pt',\n",
    "\n",
    "    'num_epochs' : 15,\n",
    "    'lr' : 0.005,\n",
    "    'batch_size' : 2048,\n",
    "\n",
    "    \"num_factor\" : 128,\n",
    "    \"num_layers\" : 3,\n",
    "    \"dropout\" : 0.5,\n",
    "\n",
    "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
    "    'seed' : 22,\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(config.model_path):\n",
    "    os.mkdir(config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(config.submission_path):\n",
    "    os.mkdir(config.submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeFMDataSet():\n",
    "    \"\"\"\n",
    "    FMDataSet 생성\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n",
    "        self.genre_df = pd.read_csv(os.path.join(self.config.data_path, 'genres.tsv'), sep='\\t')\n",
    "\n",
    "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder(col = 'item', df = self.df)\n",
    "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder(col = 'user', df = self.df)\n",
    "        self.genre_encoder, self.genre_decoder = self.generate_encoder_decoder(col = 'genre', df = self.genre_df)\n",
    "\n",
    "        self.num_item, self.num_user, self.num_genre = len(self.item_encoder), len(self.user_encoder), len(self.genre_encoder)\n",
    "\n",
    "        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n",
    "        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n",
    "        \n",
    "        self.genre_df['item_idx'] = self.genre_df['item'].apply(lambda x : self.item_encoder[x])\n",
    "        self.genre_df['genre_idx'] = self.genre_df['genre'].apply(lambda x : self.genre_encoder[x] + 1)\n",
    "\n",
    "        self.exist_users = [i for i in range(self.num_user)]\n",
    "        self.exist_items = [i for i in range(self.num_item)]\n",
    "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
    "        self.item_idx2genre_list = self.generate_genre_data()\n",
    "\n",
    "    def make_item2genre(self, items):\n",
    "        genre_list = []\n",
    "        for item in items:\n",
    "            genre_list.append(self.item_idx2genre_list[item])\n",
    "        return genre_list\n",
    "\n",
    "    def generate_genre_data(self):\n",
    "        max_len = 10\n",
    "        item_idx2genre_list = {}\n",
    "        group_df = self.genre_df.groupby('item_idx')\n",
    "        for item_idx, df in group_df:\n",
    "            genre_list = df['genre_idx'].tolist()\n",
    "            padding_list = [0] * (max_len - len(genre_list))\n",
    "            genre_list = genre_list + padding_list\n",
    "            item_idx2genre_list[item_idx] = genre_list\n",
    "        \n",
    "        return item_idx2genre_list\n",
    "\n",
    "    def generate_encoder_decoder(self, col : str, df) -> dict:\n",
    "        \"\"\"\n",
    "        encoder, decoder 생성\n",
    "\n",
    "        Args:\n",
    "            col (str): 생성할 columns 명\n",
    "        Returns:\n",
    "            dict: 생성된 user encoder, decoder\n",
    "        \"\"\"\n",
    "\n",
    "        encoder = {}\n",
    "        decoder = {}\n",
    "        ids = df[col].unique()\n",
    "\n",
    "        for idx, _id in enumerate(ids):\n",
    "            encoder[_id] = idx\n",
    "            decoder[idx] = _id\n",
    "\n",
    "        return encoder, decoder\n",
    "    \n",
    "    def generate_sequence_data(self) -> dict:\n",
    "        \"\"\"\n",
    "        sequence_data 생성\n",
    "\n",
    "        Returns:\n",
    "            dict: train user sequence / valid user sequence\n",
    "        \"\"\"\n",
    "        users = defaultdict(list)\n",
    "        user_train = {}\n",
    "        user_valid = {}\n",
    "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n",
    "            users[user].append(item)\n",
    "        \n",
    "        for user in users:\n",
    "            np.random.seed(self.config.seed)\n",
    "\n",
    "            user_total = users[user]\n",
    "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
    "            train = list(set(user_total) - set(valid))\n",
    "\n",
    "            user_train[user] = train\n",
    "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
    "\n",
    "        return user_train, user_valid\n",
    "\n",
    "    def neg_sampling(self, users):\n",
    "        \n",
    "        neg_sampling_cnt = 3\n",
    "        \n",
    "        def sample_neg_items_for_u(u, num):\n",
    "            neg_items = list(set(self.exist_items) - set(self.user_train[u]))\n",
    "            neg_batch = random.sample(neg_items, num)\n",
    "            return neg_batch\n",
    "        \n",
    "        _users, neg_items = [], []\n",
    "        for user in users:\n",
    "            neg_items += sample_neg_items_for_u(user, neg_sampling_cnt)\n",
    "            _users += [user] * neg_sampling_cnt\n",
    "\n",
    "        return _users, neg_items\n",
    "\n",
    "    def get_train_valid_data(self):\n",
    "        return self.user_train, self.user_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CFDataset(Dataset):\n",
    "    def __init__(self, user_train):\n",
    "        self.users = []\n",
    "        self.items = []\n",
    "        for user in user_train.keys():\n",
    "            self.items += user_train[user]\n",
    "            self.users += [user] * len(user_train[user])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        item = self.items[idx]\n",
    "\n",
    "        return user, item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, num_user, num_item, num_genre, num_factor, num_layers, dropout):\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.user_emb = nn.Embedding(num_user, num_factor)\n",
    "        self.item_emb = nn.Embedding(num_item, num_factor)\n",
    "        self.genre_emb = nn.Embedding(num_genre + 1, 20, padding_idx = 0)\n",
    "        input_size = num_factor * 2 + 20\n",
    "\n",
    "        # MLP_modules = []\n",
    "        # for i in range(num_layers):\n",
    "        #     if i != 0:\n",
    "        #         MLP_modules.append(nn.Dropout(p = self.dropout))\n",
    "        #         MLP_modules.append(nn.Linear(input_size, input_size // 2))\n",
    "        #         MLP_modules.append(nn.ReLU())\n",
    "        #     else:\n",
    "        #         MLP_modules.append(nn.Linear(input_size, input_size // 2))\n",
    "        #         MLP_modules.append(nn.ReLU())\n",
    "        #     input_size = input_size // 2\n",
    "        # self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "\n",
    "        self.predict_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, 1, bias = True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self._init_weight_()\n",
    "    \n",
    "    def _init_weight_(self):\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.genre_emb.weight[1:], std=0.01)\n",
    "        \n",
    "        # for m in self.MLP_layers:\n",
    "        #     if isinstance(m, nn.Linear):\n",
    "        #         nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "        for m in self.predict_layer:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, user, item, genre):\n",
    "        user_emb = self.user_emb(user)\n",
    "        item_emb = self.item_emb(item)\n",
    "        genre_emb = self.genre_emb(genre).sum(dim = 1)\n",
    "        \n",
    "        cat_emb = torch.cat((user_emb, item_emb, genre_emb), -1)\n",
    "\n",
    "        # output = self.MLP_layers(cat_emb)\n",
    "\n",
    "        output = self.predict_layer(cat_emb)\n",
    "\n",
    "        return output.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, make_data_set):\n",
    "    model.train()\n",
    "    loss_val = 0\n",
    "\n",
    "    for users, items in data_loader:\n",
    "        neg_users, neg_items = make_data_set.neg_sampling(users.numpy().tolist())\n",
    "\n",
    "        all_users = torch.concat([users, torch.tensor(neg_users)]).to(device)\n",
    "        all_items = torch.concat([items, torch.tensor(neg_items)]).to(device)\n",
    "\n",
    "        all_genres = make_data_set.make_item2genre(all_items.cpu().numpy().tolist())\n",
    "        all_genres = torch.LongTensor(all_genres).to(device)\n",
    "\n",
    "        pos_target = [1] * len(items)\n",
    "        neg_target = [0] * len(neg_items)\n",
    "\n",
    "        target = torch.FloatTensor(pos_target + neg_target).to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(all_users, all_items, all_genres)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val += loss.item()\n",
    "\n",
    "    loss_val /= len(data_loader)\n",
    "\n",
    "    return loss_val\n",
    "\n",
    "\n",
    "def get_ndcg(pred_list, true_list):\n",
    "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
    "    dcg = 0\n",
    "    for rank, pred in enumerate(pred_list):\n",
    "        if pred in true_list:\n",
    "            dcg += 1 / np.log2(rank + 2)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "# hit == recall == precision\n",
    "def get_hit(pred_list, true_list):\n",
    "    hit_list = set(true_list) & set(pred_list)\n",
    "    hit = len(hit_list) / len(true_list)\n",
    "    return hit\n",
    "\n",
    "def evaluate(model, user_train, user_valid, make_data_set):\n",
    "    model.eval()\n",
    "\n",
    "    NDCG = 0.0 # NDCG@10\n",
    "    HIT = 0.0 # HIT@10\n",
    "\n",
    "    all_users = make_data_set.exist_users\n",
    "    all_items = make_data_set.exist_items\n",
    "    all_genres = make_data_set.make_item2genre(all_items)\n",
    "    with torch.no_grad():\n",
    "        for user in all_users:\n",
    "            users = [user] * len(all_items)\n",
    "            users, items, genres = torch.tensor(users).to(device), torch.tensor(all_items).to(device), torch.tensor(all_genres).to(device)\n",
    "\n",
    "            output = model(users, items, genres)\n",
    "            output = output.softmax(dim = 0)\n",
    "            output[user_train[user]] = -1.\n",
    "\n",
    "            uv = user_valid[user]\n",
    "            up = output.argsort()[-10:].cpu().numpy().tolist()\n",
    "\n",
    "            NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
    "            HIT += get_hit(pred_list = up, true_list = uv)\n",
    "\n",
    "    NDCG /= len(all_users)\n",
    "    HIT /= len(all_users)\n",
    "\n",
    "    return NDCG, HIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_fm_data_set = MakeFMDataSet(config = config)\n",
    "user_train, user_valid = make_fm_data_set.get_train_valid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_dataset = CFDataset(user_train = user_train)\n",
    "data_loader = DataLoader(\n",
    "    cf_dataset, \n",
    "    batch_size = config.batch_size, \n",
    "    shuffle = True, \n",
    "    drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(\n",
    "    num_user = make_fm_data_set.num_user, \n",
    "    num_item = make_fm_data_set.num_item, \n",
    "    num_genre = make_fm_data_set.num_genre,\n",
    "    num_factor = config.num_factor,\n",
    "    num_layers = config.num_layers,\n",
    "    dropout = config.dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = config.lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hit = 0\n",
    "for epoch in range(1, config.num_epochs + 1):\n",
    "    tbar = tqdm(range(1))\n",
    "    for _ in tbar:\n",
    "        train_loss = train(\n",
    "            model = model, \n",
    "            data_loader = data_loader, \n",
    "            criterion = criterion, \n",
    "            optimizer = optimizer, \n",
    "            make_data_set = make_fm_data_set\n",
    "            )\n",
    "        \n",
    "        ndcg, hit = evaluate(model, user_train, user_valid, make_fm_data_set)\n",
    "        \n",
    "        if best_hit < hit:\n",
    "            best_hit = hit\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_path, config.model_name))\n",
    "\n",
    "        tbar.set_description(f'Epoch: {epoch:3d}| Train loss: {train_loss:.5f}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
