{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ug-br-pPu9vZ"},"outputs":[],"source":["import math\n","import numpy as np\n","import scipy.sparse as sp\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import defaultdict\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from box import Box\n","\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","torch.set_printoptions(sci_mode=True)"]},{"cell_type":"markdown","metadata":{"id":"pbRKDSg4u9vc"},"source":["# 1. 학습 설정"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"MEhK_fLIu9vd"},"outputs":[],"source":["config = {\n","    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n","    'model_path' : \"../model\",\n","    \n","    'submission_path' : \"../submission\",\n","    'submission_name' : 'oof_EASE_v2_submission.csv',\n","\n","    'candidate_item_num' : 5,\n","    'valid_samples' : 10, # 검증에 사용할 sample 수\n","    'seed' : 22,\n","    'reg' : 750,\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","config = Box(config)"]},{"cell_type":"markdown","metadata":{"id":"wjDxy0fJu9vf"},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"W64BYWl0u9vg"},"outputs":[],"source":["class MakeMatrixDataSet():\n","    \"\"\"\n","    MatrixDataSet 생성\n","    \"\"\"\n","    def __init__(self, config):\n","        self.config = config\n","        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n","        \n","        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n","        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n","        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n","\n","        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n","        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n","\n","        self.user_train, self.user_valid = self.generate_sequence_data()\n","\n","    def generate_encoder_decoder(self, col : str) -> dict:\n","        \"\"\"\n","        encoder, decoder 생성\n","\n","        Args:\n","            col (str): 생성할 columns 명\n","        Returns:\n","            dict: 생성된 user encoder, decoder\n","        \"\"\"\n","\n","        encoder = {}\n","        decoder = {}\n","        ids = self.df[col].unique()\n","\n","        for idx, _id in enumerate(ids):\n","            encoder[_id] = idx\n","            decoder[idx] = _id\n","\n","        return encoder, decoder\n","    \n","    def generate_sequence_data(self) -> dict:\n","        \"\"\"\n","        sequence_data 생성\n","\n","        Returns:\n","            dict: train user sequence / valid user sequence\n","        \"\"\"\n","        users = defaultdict(list)\n","        user_train = {}\n","        user_valid = {}\n","        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n","            users[user].append(item)\n","        \n","        for user in users:\n","            np.random.seed(self.config.seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            user_train[user] = train\n","            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n","\n","        return user_train, user_valid\n","    \n","    def get_train_valid_data(self):\n","        return self.user_train, self.user_valid\n","\n","    def make_matrix(self, user_list, train = True):\n","        \"\"\"\n","        user_item_dict를 바탕으로 행렬 생성\n","        \"\"\"\n","        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n","        for idx, user in enumerate(user_list):\n","            if train:\n","                mat[idx, self.user_train[user.item()]] = 1\n","            else:\n","                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n","        return mat\n","\n","    def make_sparse_matrix(self, test = False):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        \n","        for user in self.user_train.keys():\n","            item_list = self.user_train[user]\n","            X[user, item_list] = 1.0\n","        \n","        if test:\n","            for user in self.user_valid.keys():\n","                item_list = self.user_valid[user]\n","                X[user, item_list] = 1.0\n","\n","        return X.tocsr()\n","\n","    def oof_make_sparse_matrix(self, seed):\n","        train_X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        user_valid = {}\n","\n","        users = defaultdict(list)\n","        group_df = self.df.groupby('user_idx')\n","        for user, items in group_df:\n","            users[user].extend(items['item_idx'].tolist())\n","        \n","        for user in users:\n","            np.random.seed(seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            train_X[user, train] = 1.0\n","            user_valid[user] = valid\n","\n","        return train_X.tocsr(), user_valid"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"IldCGmY8u9vh"},"outputs":[],"source":["class AEDataSet(Dataset):\n","    def __init__(self, num_user):\n","        self.num_user = num_user\n","        self.users = [i for i in range(num_user)]\n","\n","    def __len__(self):\n","        return self.num_user\n","\n","    def __getitem__(self, idx): \n","        user = self.users[idx]\n","        return torch.LongTensor([user])"]},{"cell_type":"markdown","metadata":{"id":"ysia457Su9vi"},"source":["# 3. 모델"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"TVXWUTLpSh8_"},"outputs":[],"source":["class EASE():\n","    def __init__(self, X, reg):\n","        self.X = self._convert_sp_mat_to_sp_tensor(X)\n","        self.reg = reg\n","    \n","    def _convert_sp_mat_to_sp_tensor(self, X):\n","        \"\"\"\n","        Convert scipy sparse matrix to PyTorch sparse matrix\n","\n","        Arguments:\n","        ----------\n","        X = Adjacency matrix, scipy sparse matrix\n","        \"\"\"\n","        coo = X.tocoo().astype(np.float32)\n","        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n","        v = torch.FloatTensor(coo.data)\n","        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n","        return res\n","    \n","    def fit(self):\n","        '''\n","\n","        진짜 정말 간단한 식으로 모델을 만듬\n","\n","        '''\n","        G = self.X.to_dense().t() @ self.X.to_dense()\n","        diagIndices = torch.eye(G.shape[0]) == 1\n","        G[diagIndices] += self.reg\n","\n","        P = G.inverse()\n","        B = P / (-1 * P.diag())\n","        B[diagIndices] = 0\n","    \n","        self.B = B\n","    \n","    def predict(self, X):\n","        X = self._convert_sp_mat_to_sp_tensor(X)\n","        self.pred = X.to_dense() @ self.B"]},{"cell_type":"markdown","metadata":{"id":"GwSexh43u9vk"},"source":["# 4. 학습 함수"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"nws4JO2_rgQP"},"outputs":[],"source":["def get_ndcg(pred_list, true_list):\n","    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n","    dcg = 0\n","    for rank, pred in enumerate(pred_list):\n","        if pred in true_list:\n","            dcg += 1 / np.log2(rank + 2)\n","    ndcg = dcg / idcg\n","    return ndcg\n","\n","# hit == recall == precision\n","def get_hit(pred_list, true_list):\n","    hit_list = set(true_list) & set(pred_list)\n","    hit = len(hit_list) / len(true_list)\n","    return hit\n","\n","def evaluate(model, X, user_valid):\n","\n","    mat = torch.from_numpy(X)\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    recon_mat = model.pred.cpu()\n","    recon_mat[mat == 1] = -np.inf\n","    rec_list = recon_mat.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        uv = user_valid[user]\n","        up = rec[-10:].cpu().numpy().tolist()[::-1]\n","        NDCG += get_ndcg(pred_list = up, true_list = uv)\n","        HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(rec_list)\n","    HIT /= len(rec_list)\n","\n","    return NDCG, HIT\n","\n","\n","def predict(model, X):\n","    user2rec = {}\n","\n","    mat = torch.from_numpy(X)\n","\n","    recon_mat = model.pred.cpu()\n","    recon_mat[mat == 1] = -np.inf\n","    rec_list = recon_mat.argsort(dim = 1)\n","\n","    for user, rec in enumerate(rec_list):\n","        up = rec[-10:].cpu().numpy().tolist()[::-1]\n","        user2rec[user] = up\n","    \n","    return user2rec\n","\n","def ensemble(oof2user2rec, users):\n","    ensemble_user2rec = {}\n","\n","    score_li = np.array([1/np.log2(rank + 2) for rank in range(0, 10)])\n","\n","    for user in users:\n","\n","        user2rec_list = []\n","        all_user_rec = []\n","        \n","        for oof in oof2user2rec.keys():\n","            user2rec = oof2user2rec[oof]\n","            user2rec_list.append(user2rec[user])\n","            all_user_rec += user2rec[user]\n","        \n","        all_user_rec = list(set(all_user_rec))\n","\n","        rec_df = pd.DataFrame(index = all_user_rec)\n","\n","        for oof in oof2user2rec.keys():\n","            rec_df.loc[user2rec_list[oof - 1], f'oof{oof}_rec_score'] = score_li\n","        \n","        rec_df = rec_df.fillna(min(score_li))\n","        rec_df['total_rec_score'] = rec_df.sum(axis = 1)\n","\n","        rec_df = rec_df.sort_values('total_rec_score', ascending = False)\n","        up = rec_df.index.tolist()[:10]\n","\n","        ensemble_user2rec[user] = up\n","\n","    return ensemble_user2rec"]},{"cell_type":"markdown","metadata":{"id":"gupkaJHMslCi"},"source":["# 5. 학습"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"HFOr6Wmbq9pW"},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","X_test = make_matrix_data_set.make_sparse_matrix(test = True)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["oof-1 NDCG@10: 0.31055| HIT@10: 0.20384\n","oof-2 NDCG@10: 0.32204| HIT@10: 0.21099\n","oof-3 NDCG@10: 0.33080| HIT@10: 0.21594\n","oof-4 NDCG@10: 0.30952| HIT@10: 0.20276\n","oof-5 NDCG@10: 0.30010| HIT@10: 0.19581\n"]}],"source":["users = [user for user in range(make_matrix_data_set.num_user)]\n","seed = config.seed\n","oof = 1\n","oof2user2rec = {}\n","\n","for _ in range(5):\n","\n","    train_X, user_valid = make_matrix_data_set.oof_make_sparse_matrix(seed = seed)\n","    model = EASE(X = train_X, reg = 750)\n","    model.fit()\n","    model.predict(X = train_X)\n","\n","    ndcg, hit = evaluate(model = model, X = train_X.todense(), user_valid = user_valid)\n","    print(f'oof-{oof} NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')\n","    \n","    model.predict(X = X_test)\n","    user2rec = predict(\n","        model = model, \n","        X = X_test.todense(),\n","    )\n","\n","    oof2user2rec[oof] = user2rec\n","\n","    oof += 1\n","    seed += 1"]},{"cell_type":"markdown","metadata":{},"source":["```\n","아이템 스플릿\n","\n","oof-1 NDCG@10: 0.31055| HIT@10: 0.20384\n","oof-2 NDCG@10: 0.32204| HIT@10: 0.21099\n","oof-3 NDCG@10: 0.33080| HIT@10: 0.21594\n","oof-4 NDCG@10: 0.30952| HIT@10: 0.20276\n","oof-5 NDCG@10: 0.30010| HIT@10: 0.19581\n","```\n","\n","```\n","유저 스플릿\n","\n","NDCG@10: 0.23292| HIT@10: 0.20569\n","NDCG@10: 0.23085| HIT@10: 0.20391\n","NDCG@10: 0.22740| HIT@10: 0.20234\n","NDCG@10: 0.22795| HIT@10: 0.20214\n","NDCG@10: 0.23052| HIT@10: 0.20450\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 6. 예측"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["user2rec_list = ensemble(oof2user2rec = oof2user2rec, users = users)\n","\n","submision = []\n","users = [i for i in range(0, make_matrix_data_set.num_user)]\n","for user in users:\n","    rec_item_list = user2rec_list[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>4370</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>4886</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>8961</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>40815</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>313595</th>\n","      <td>138493</td>\n","      <td>1270</td>\n","    </tr>\n","    <tr>\n","      <th>313596</th>\n","      <td>138493</td>\n","      <td>32587</td>\n","    </tr>\n","    <tr>\n","      <th>313597</th>\n","      <td>138493</td>\n","      <td>2762</td>\n","    </tr>\n","    <tr>\n","      <th>313598</th>\n","      <td>138493</td>\n","      <td>8970</td>\n","    </tr>\n","    <tr>\n","      <th>313599</th>\n","      <td>138493</td>\n","      <td>589</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>313600 rows × 2 columns</p>\n","</div>"],"text/plain":["          user   item\n","0           11   4370\n","1           11   4886\n","2           11   8961\n","3           11  40815\n","4           11     47\n","...        ...    ...\n","313595  138493   1270\n","313596  138493  32587\n","313597  138493   2762\n","313598  138493   8970\n","313599  138493    589\n","\n","[313600 rows x 2 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["submision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMB0K8DmOwclQIFyyBerAFJ","collapsed_sections":[],"mount_file_id":"1C1AHkN-z-DCxUIAjFfd7K56P-8-YrAJO","name":"EASE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
