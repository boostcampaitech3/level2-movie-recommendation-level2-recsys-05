{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":8008,"status":"ok","timestamp":1648373521235,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"Ug-br-pPu9vZ"},"outputs":[],"source":["import math\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import defaultdict\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from box import Box\n","from copy import deepcopy\n","\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","torch.set_printoptions(sci_mode=True)"]},{"cell_type":"markdown","metadata":{"id":"pbRKDSg4u9vc"},"source":["# 1. 학습 설정"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1648373521235,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"mlm1UrKvoC_O"},"outputs":[],"source":["config = {\n","    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n","    \n","    'submission_path' : \"../submission\",\n","    'submission_name' : 'RecVAE_v1_submission.csv', \n","\n","    'model_path' : \"../model\", # 모델 저장 경로\n","    'model_name' : 'ex-RecVAE_v10.pt',\n","\n","    'weight_decay' : 0.01,\n","    'hidden_dim': 600,\n","    'latent_dim' : 200,\n","    'dropout_rate' : 0.6,\n","    'gamma' : 0.0005,\n","    'beta' : None,\n","    'not_alternating' : True,\n","    'e_num_epochs' : 2,\n","    'd_num_epochs' : 1,\n","\n","    'lr' : 0.0005,\n","    'batch_size' : 500,\n","    'num_epochs' : 200,\n","    'num_workers' : 2,\n","\n","    'valid_samples' : 10,\n","    'seed' : 22,\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","config = Box(config)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def seed_everything(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","seed_everything(config.seed)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1648373521235,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"iqVUlLd9u9ve"},"outputs":[],"source":["if not os.path.isdir(config.model_path):\n","    os.mkdir(config.model_path)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["if not os.path.isdir(config.submission_path):\n","    os.mkdir(config.submission_path)"]},{"cell_type":"markdown","metadata":{"id":"wjDxy0fJu9vf"},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1648373521236,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"W64BYWl0u9vg"},"outputs":[],"source":["class MakeMatrixDataSet():\n","    \"\"\"\n","    MatrixDataSet 생성\n","    \"\"\"\n","    def __init__(self, config):\n","        self.config = config\n","        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n","\n","        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n","        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n","        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n","\n","        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n","        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n","\n","        self.user_train, self.user_valid = self.generate_sequence_data()\n","\n","    def generate_encoder_decoder(self, col : str) -> dict:\n","        \"\"\"\n","        encoder, decoder 생성\n","\n","        Args:\n","            col (str): 생성할 columns 명\n","        Returns:\n","            dict: 생성된 user encoder, decoder\n","        \"\"\"\n","\n","        encoder = {}\n","        decoder = {}\n","        ids = self.df[col].unique()\n","\n","        for idx, _id in enumerate(ids):\n","            encoder[_id] = idx\n","            decoder[idx] = _id\n","\n","        return encoder, decoder\n","    \n","    def generate_sequence_data(self) -> dict:\n","        \"\"\"\n","        sequence_data 생성\n","\n","        Returns:\n","            dict: train user sequence / valid user sequence\n","        \"\"\"\n","        users = defaultdict(list)\n","        user_train = {}\n","        user_valid = {}\n","        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n","            users[user].append(item)\n","        \n","        for user in users:\n","            np.random.seed(self.config.seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            user_train[user] = train\n","            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n","\n","        return user_train, user_valid\n","    \n","    def get_train_valid_data(self):\n","        return self.user_train, self.user_valid\n","\n","    def make_matrix(self, user_list, train = True):\n","        \"\"\"\n","        user_item_dict를 바탕으로 행렬 생성\n","        \"\"\"\n","        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n","        for idx, user in enumerate(user_list):\n","            if train:\n","                mat[idx, self.user_train[user.item()]] = 1\n","            else:\n","                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n","        return mat\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1648373521236,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"IldCGmY8u9vh"},"outputs":[],"source":["class AEDataSet(Dataset):\n","    def __init__(self, num_user):\n","        self.num_user = num_user\n","        self.users = [i for i in range(num_user)]\n","\n","    def __len__(self):\n","        return self.num_user\n","\n","    def __getitem__(self, idx): \n","        user = self.users[idx]\n","        return torch.LongTensor([user])"]},{"cell_type":"markdown","metadata":{"id":"Jtf1I824nx5V"},"source":["# 3. 모델"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":651,"status":"ok","timestamp":1648373965721,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"UFFzRy9qUEG6"},"outputs":[],"source":["def swish(x):\n","    return x.mul(torch.sigmoid(x))\n","\n","def log_norm_pdf(x, mu, logvar):\n","    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n","\n","class CompositePrior(nn.Module):\n","    def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n","        super(CompositePrior, self).__init__()\n","        \n","        self.mixture_weights = mixture_weights\n","        \n","        self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n","        self.mu_prior.data.fill_(0)\n","        \n","        self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n","        self.logvar_prior.data.fill_(0)\n","        \n","        self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n","        self.logvar_uniform_prior.data.fill_(10)\n","        \n","        self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n","        self.encoder_old.requires_grad_(False)\n","        \n","    def forward(self, x, z):\n","\n","        post_mu, post_logvar = self.encoder_old(x, dropout_rate = 0)\n","\n","        stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n","        post_prior = log_norm_pdf(z, post_mu, post_logvar)\n","        unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n","        \n","        gaussians = [stnd_prior, post_prior, unif_prior]\n","        gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n","\n","        density_per_gaussian = torch.stack(gaussians, dim=-1)\n","\n","        return torch.logsumexp(density_per_gaussian, dim=-1)\n","\n","    \n","class Encoder(nn.Module):\n","    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n","        super(Encoder, self).__init__()\n","        \n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n","        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n","        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n","        \n","    def forward(self, x, dropout_rate):\n","        norm = x.pow(2).sum(dim=-1).sqrt()\n","        x = x / norm[:, None]\n","    \n","        x = F.dropout(x, p=dropout_rate, training=self.training)\n","        \n","        h1 = self.ln1(swish(self.fc1(x)))\n","        h2 = self.ln2(swish(self.fc2(h1) + h1))\n","        h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n","        h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n","        h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n","        return self.fc_mu(h5), self.fc_logvar(h5)\n","\n","\n","class RecVAE(nn.Module):\n","    def __init__(self, input_dim, hidden_dim = 600, latent_dim = 200):\n","        super(RecVAE, self).__init__()\n","\n","        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n","        self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n","        self.decoder = nn.Linear(latent_dim, input_dim)\n","        \n","    def reparameterize(self, mu, logvar):\n","        if self.training:\n","            std = torch.exp(0.5*logvar)\n","            eps = torch.randn_like(std)\n","            return eps.mul(std).add_(mu)\n","        else:\n","            return mu\n","\n","    def forward(self, user_ratings, beta=None, gamma=0.005, dropout_rate=0.5, calculate_loss=True):\n","        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)    \n","        z = self.reparameterize(mu, logvar)\n","        x_pred = self.decoder(z)\n","\n","        if calculate_loss:\n","            if gamma:\n","                norm = user_ratings.sum(dim=-1)\n","                kl_weight = gamma * norm\n","            elif beta:\n","                kl_weight = beta\n","\n","            mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n","            kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n","            negative_elbo = -(mll - kld)\n","            \n","            return (mll, kld), negative_elbo\n","            \n","        else:\n","            return x_pred\n","\n","    def update_prior(self):\n","        self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))"]},{"cell_type":"markdown","metadata":{"id":"dk-bL5p4nx5W"},"source":["# 4. 학습 함수"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1648373966202,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"Rmooa3n1u9vj"},"outputs":[],"source":["def train(model, optimizer, data_loader, make_matrix_data_set, beta, gamma, dropout_rate):\n","    model.train()\n","    loss_val = 0\n","    for users in data_loader:\n","        mat = make_matrix_data_set.make_matrix(users)\n","        mat = mat.to(device)\n","        _, loss = model(user_ratings = mat, beta = beta, gamma = gamma, dropout_rate = dropout_rate)\n","\n","        optimizer.zero_grad()\n","        loss_val += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    loss_val /= len(data_loader)\n","\n","    return loss_val\n","\n","def get_ndcg(pred_list, true_list):\n","    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n","    dcg = 0\n","    for rank, pred in enumerate(pred_list):\n","        if pred in true_list:\n","            dcg += 1 / np.log2(rank + 2)\n","    ndcg = dcg / idcg\n","    return ndcg\n","\n","# hit == recall == precision\n","def get_hit(pred_list, true_list):\n","    hit_list = set(true_list) & set(pred_list)\n","    hit = len(hit_list) / len(true_list)\n","    return hit\n","\n","def evaluate(model, data_loader, user_train, user_valid, make_matrix_data_set, user_list):\n","    model.eval()\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    with torch.no_grad():\n","        for users in data_loader:\n","            mat = make_matrix_data_set.make_matrix(users)\n","            mat = mat.to(device)\n","\n","            recon_mat = model(mat, calculate_loss = False)\n","            recon_mat[mat == 1] = -np.inf\n","            rec_list = recon_mat.argsort(dim = 1)\n","\n","            for user, rec in zip(users, rec_list):\n","                if user.item() in user_list:\n","                    uv = user_valid[user.item()]\n","                    up = rec[-10:].cpu().numpy().tolist()\n","                    NDCG += get_ndcg(pred_list = up, true_list = uv)\n","                    HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(user_list)\n","    HIT /= len(user_list)\n","\n","    return NDCG, HIT\n","\n","def predict(model, data_loader, user_train, user_valid, make_matrix_data_set):\n","    model.eval()\n","    \n","    user2rec_list = {}\n","    with torch.no_grad():\n","        for users in data_loader:\n","            mat = make_matrix_data_set.make_matrix(users, train = False)\n","            mat = mat.to(device)\n","\n","            recon_mat = model(mat, calculate_loss = False)\n","            recon_mat[mat == 1] = -np.inf\n","            rec_list = recon_mat.argsort(dim = 1)\n","\n","            for user, rec in zip(users, rec_list):\n","                up = rec[-10:].cpu().numpy().tolist()[::-1]\n","                user2rec_list[user.item()] = up\n","    \n","    return user2rec_list"]},{"cell_type":"markdown","metadata":{"id":"ozBvgarCnx5W"},"source":["# 5. 학습"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1810,"status":"ok","timestamp":1648373969106,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"3zXVEf6fu9vk"},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1648373969106,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"3hGPyH54u9vk"},"outputs":[],"source":["ae_dataset = AEDataSet(\n","    num_user = make_matrix_data_set.num_user,\n","    )"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648373969107,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"dyL3vriiu9vl"},"outputs":[],"source":["data_loader = DataLoader(\n","    ae_dataset,\n","    batch_size = config.batch_size, \n","    shuffle = True, \n","    pin_memory = True,\n","    num_workers = config.num_workers,\n","    )"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":651,"status":"ok","timestamp":1648373969755,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"dpiWnBV8u9vm"},"outputs":[],"source":["model = RecVAE(\n","    input_dim = make_matrix_data_set.num_item,\n","    hidden_dim = config.hidden_dim,\n","    latent_dim = config.latent_dim).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay = config.weight_decay) # 0.19213\n","\n","# optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, amsgrad = True) # 0.19194\n","\n","# optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr) # 0.19188\n","\n","# optimizer = torch.optim.RAdam(model.parameters(), lr=config.lr) # 0.19211\n","\n","# optimizer_encoder = torch.optim.Adam(model.encoder.parameters(), lr=config.lr)\n","# optimizer_decoder = torch.optim.Adam(model.decoder.parameters(), lr=config.lr)\n","\n","# model.load_state_dict(torch.load(os.path.join(config.model_path, 'RecVAE_v9.pt')))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["zero_df = pd.read_csv('zero_df.csv')\n","user_list = zero_df['user'].tolist()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150761,"status":"ok","timestamp":1648374121067,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"aE6KYgPAuR7p","outputId":"a208c9c4-b6ec-4280-f9c5-ac1383871ffe"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch:   1| Train loss: 1335.84590| NDCG@10: 0.08204| HIT@10: 0.06911: 100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n","Epoch:   2| Train loss: 1251.05373| NDCG@10: 0.10178| HIT@10: 0.08690: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n","Epoch:   3| Train loss: 1232.65335| NDCG@10: 0.11217| HIT@10: 0.09521: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n","Epoch:   4| Train loss: 1215.79339| NDCG@10: 0.11662| HIT@10: 0.09984: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n","Epoch:   5| Train loss: 1198.47177| NDCG@10: 0.11841| HIT@10: 0.10066: 100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n","Epoch:   6| Train loss: 1201.99280| NDCG@10: 0.12067| HIT@10: 0.10338: 100%|██████████| 1/1 [00:03<00:00,  3.99s/it]\n","Epoch:   7| Train loss: 1190.51726| NDCG@10: 0.11961| HIT@10: 0.10181: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:   8| Train loss: 1197.55256| NDCG@10: 0.12430| HIT@10: 0.10680: 100%|██████████| 1/1 [00:04<00:00,  4.30s/it]\n","Epoch:   9| Train loss: 1186.50349| NDCG@10: 0.12593| HIT@10: 0.10856: 100%|██████████| 1/1 [00:04<00:00,  4.02s/it]\n","Epoch:  10| Train loss: 1201.77633| NDCG@10: 0.12531| HIT@10: 0.10769: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch:  11| Train loss: 1178.46737| NDCG@10: 0.12841| HIT@10: 0.11023: 100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\n","Epoch:  12| Train loss: 1189.94556| NDCG@10: 0.12866| HIT@10: 0.10991: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  13| Train loss: 1175.09164| NDCG@10: 0.13102| HIT@10: 0.11215: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n","Epoch:  14| Train loss: 1184.33587| NDCG@10: 0.12799| HIT@10: 0.10934: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch:  15| Train loss: 1174.78226| NDCG@10: 0.13071| HIT@10: 0.11216: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n","Epoch:  16| Train loss: 1176.56731| NDCG@10: 0.13156| HIT@10: 0.11292: 100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n","Epoch:  17| Train loss: 1177.51839| NDCG@10: 0.13253| HIT@10: 0.11459: 100%|██████████| 1/1 [00:03<00:00,  3.97s/it]\n","Epoch:  18| Train loss: 1186.44740| NDCG@10: 0.13320| HIT@10: 0.11513: 100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n","Epoch:  19| Train loss: 1174.33947| NDCG@10: 0.13333| HIT@10: 0.11523: 100%|██████████| 1/1 [00:04<00:00,  4.00s/it]\n","Epoch:  20| Train loss: 1177.31287| NDCG@10: 0.13350| HIT@10: 0.11586: 100%|██████████| 1/1 [00:03<00:00,  3.99s/it]\n","Epoch:  21| Train loss: 1161.86987| NDCG@10: 0.13356| HIT@10: 0.11554: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  22| Train loss: 1169.69384| NDCG@10: 0.13361| HIT@10: 0.11504: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  23| Train loss: 1160.57722| NDCG@10: 0.13392| HIT@10: 0.11557: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch:  24| Train loss: 1178.44089| NDCG@10: 0.13430| HIT@10: 0.11548: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch:  25| Train loss: 1165.30837| NDCG@10: 0.13661| HIT@10: 0.11790: 100%|██████████| 1/1 [00:03<00:00,  4.00s/it]\n","Epoch:  26| Train loss: 1167.49508| NDCG@10: 0.13700| HIT@10: 0.11826: 100%|██████████| 1/1 [00:03<00:00,  3.99s/it]\n","Epoch:  27| Train loss: 1157.30547| NDCG@10: 0.13559| HIT@10: 0.11754: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  28| Train loss: 1155.79236| NDCG@10: 0.13607| HIT@10: 0.11740: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  29| Train loss: 1157.62077| NDCG@10: 0.13477| HIT@10: 0.11582: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch:  30| Train loss: 1154.14898| NDCG@10: 0.13694| HIT@10: 0.11888: 100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n","Epoch:  31| Train loss: 1151.63354| NDCG@10: 0.13822| HIT@10: 0.11870: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  32| Train loss: 1160.34280| NDCG@10: 0.13739| HIT@10: 0.11842: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  33| Train loss: 1159.09842| NDCG@10: 0.13733| HIT@10: 0.11882: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  34| Train loss: 1155.82704| NDCG@10: 0.13821| HIT@10: 0.12013: 100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n","Epoch:  35| Train loss: 1150.42029| NDCG@10: 0.13679| HIT@10: 0.11864: 100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\n","Epoch:  36| Train loss: 1151.42442| NDCG@10: 0.13770| HIT@10: 0.11948: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  37| Train loss: 1158.10569| NDCG@10: 0.13819| HIT@10: 0.11937: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  38| Train loss: 1153.16518| NDCG@10: 0.13878| HIT@10: 0.12038: 100%|██████████| 1/1 [00:04<00:00,  4.00s/it]\n","Epoch:  39| Train loss: 1151.54592| NDCG@10: 0.13766| HIT@10: 0.11921: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  40| Train loss: 1157.76891| NDCG@10: 0.13827| HIT@10: 0.11934: 100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n","Epoch:  41| Train loss: 1146.78794| NDCG@10: 0.13890| HIT@10: 0.11964: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  42| Train loss: 1150.45594| NDCG@10: 0.13741| HIT@10: 0.11998: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  43| Train loss: 1162.51832| NDCG@10: 0.13754| HIT@10: 0.11968: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  44| Train loss: 1149.70506| NDCG@10: 0.13710| HIT@10: 0.11937: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch:  45| Train loss: 1141.29501| NDCG@10: 0.13814| HIT@10: 0.11961: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  46| Train loss: 1155.53735| NDCG@10: 0.13879| HIT@10: 0.12048: 100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n","Epoch:  47| Train loss: 1145.55559| NDCG@10: 0.13818| HIT@10: 0.12018: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch:  48| Train loss: 1156.50009| NDCG@10: 0.13897| HIT@10: 0.12124: 100%|██████████| 1/1 [00:04<00:00,  4.00s/it]\n","Epoch:  49| Train loss: 1152.05067| NDCG@10: 0.13915| HIT@10: 0.12108: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch:  50| Train loss: 1145.86902| NDCG@10: 0.13886| HIT@10: 0.12066: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n","Epoch:  51| Train loss: 1149.37487| NDCG@10: 0.13830| HIT@10: 0.12002: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n","Epoch:  52| Train loss: 1142.89076| NDCG@10: 0.13883| HIT@10: 0.12051: 100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n","Epoch:  53| Train loss: 1144.24887| NDCG@10: 0.13903| HIT@10: 0.12069: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch:  54| Train loss: 1144.86571| NDCG@10: 0.13824| HIT@10: 0.12002: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  55| Train loss: 1144.60955| NDCG@10: 0.13901| HIT@10: 0.12096: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  56| Train loss: 1139.85035| NDCG@10: 0.13985| HIT@10: 0.12146: 100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\n","Epoch:  57| Train loss: 1139.26182| NDCG@10: 0.13837| HIT@10: 0.12054: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  58| Train loss: 1144.33583| NDCG@10: 0.14090| HIT@10: 0.12159: 100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n","Epoch:  59| Train loss: 1149.30398| NDCG@10: 0.13933| HIT@10: 0.12111: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  60| Train loss: 1141.45731| NDCG@10: 0.13894| HIT@10: 0.12101: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  61| Train loss: 1146.60060| NDCG@10: 0.13945| HIT@10: 0.12135: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  62| Train loss: 1156.59733| NDCG@10: 0.13720| HIT@10: 0.12005: 100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n","Epoch:  63| Train loss: 1140.70773| NDCG@10: 0.13895| HIT@10: 0.12082: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  64| Train loss: 1151.25552| NDCG@10: 0.13763| HIT@10: 0.12029: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  65| Train loss: 1140.02402| NDCG@10: 0.13864| HIT@10: 0.12054: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  66| Train loss: 1149.84997| NDCG@10: 0.13743| HIT@10: 0.11965: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  67| Train loss: 1142.35299| NDCG@10: 0.13856| HIT@10: 0.12008: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  68| Train loss: 1145.73338| NDCG@10: 0.13841| HIT@10: 0.12046: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  69| Train loss: 1151.11705| NDCG@10: 0.13895| HIT@10: 0.12103: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch:  70| Train loss: 1132.95909| NDCG@10: 0.13853| HIT@10: 0.12052: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  71| Train loss: 1140.81372| NDCG@10: 0.13967| HIT@10: 0.12135: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch:  72| Train loss: 1138.02229| NDCG@10: 0.13916| HIT@10: 0.12123: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  73| Train loss: 1149.48974| NDCG@10: 0.13886| HIT@10: 0.12071: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch:  74| Train loss: 1145.50618| NDCG@10: 0.13958| HIT@10: 0.12151: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  75| Train loss: 1149.95821| NDCG@10: 0.14006| HIT@10: 0.12130: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  76| Train loss: 1142.27097| NDCG@10: 0.13910| HIT@10: 0.12142: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch:  77| Train loss: 1138.21112| NDCG@10: 0.13944| HIT@10: 0.12137: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  78| Train loss: 1136.37607| NDCG@10: 0.13916| HIT@10: 0.12110: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  79| Train loss: 1132.30551| NDCG@10: 0.13965| HIT@10: 0.12135: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  80| Train loss: 1144.89831| NDCG@10: 0.14038| HIT@10: 0.12175: 100%|██████████| 1/1 [00:04<00:00,  4.07s/it]\n","Epoch:  81| Train loss: 1138.00268| NDCG@10: 0.14002| HIT@10: 0.12161: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  82| Train loss: 1151.30514| NDCG@10: 0.13799| HIT@10: 0.12070: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  83| Train loss: 1140.13907| NDCG@10: 0.13974| HIT@10: 0.12186: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n","Epoch:  84| Train loss: 1136.80276| NDCG@10: 0.13924| HIT@10: 0.12090: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch:  85| Train loss: 1158.04294| NDCG@10: 0.13920| HIT@10: 0.12163: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  86| Train loss: 1138.80413| NDCG@10: 0.13882| HIT@10: 0.12136: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch:  87| Train loss: 1136.72201| NDCG@10: 0.13888| HIT@10: 0.12130: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  88| Train loss: 1145.35682| NDCG@10: 0.14001| HIT@10: 0.12131: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  89| Train loss: 1141.01304| NDCG@10: 0.13975| HIT@10: 0.12143: 100%|██████████| 1/1 [00:04<00:00,  4.11s/it]\n","Epoch:  90| Train loss: 1140.41354| NDCG@10: 0.14000| HIT@10: 0.12165: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n","Epoch:  91| Train loss: 1140.19864| NDCG@10: 0.13960| HIT@10: 0.12151: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  92| Train loss: 1145.20592| NDCG@10: 0.14021| HIT@10: 0.12209: 100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n","Epoch:  93| Train loss: 1144.82408| NDCG@10: 0.14064| HIT@10: 0.12205: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch:  94| Train loss: 1136.73941| NDCG@10: 0.13972| HIT@10: 0.12141: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch:  95| Train loss: 1134.30537| NDCG@10: 0.13878| HIT@10: 0.12096: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch:  96| Train loss: 1135.12884| NDCG@10: 0.13954| HIT@10: 0.12122: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  97| Train loss: 1145.14927| NDCG@10: 0.13909| HIT@10: 0.12093: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch:  98| Train loss: 1147.48962| NDCG@10: 0.13908| HIT@10: 0.12087: 100%|██████████| 1/1 [00:03<00:00,  3.92s/it]\n","Epoch:  99| Train loss: 1133.66615| NDCG@10: 0.13957| HIT@10: 0.12149: 100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n","Epoch: 100| Train loss: 1135.69195| NDCG@10: 0.13968| HIT@10: 0.12180: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch: 101| Train loss: 1132.47386| NDCG@10: 0.13988| HIT@10: 0.12137: 100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n","Epoch: 102| Train loss: 1135.49613| NDCG@10: 0.13928| HIT@10: 0.12173: 100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n","Epoch: 103| Train loss: 1142.22829| NDCG@10: 0.13937| HIT@10: 0.12158: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch: 104| Train loss: 1132.38527| NDCG@10: 0.14129| HIT@10: 0.12169: 100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n","Epoch: 105| Train loss: 1136.32361| NDCG@10: 0.13990| HIT@10: 0.12173: 100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n","Epoch: 106| Train loss: 1142.34467| NDCG@10: 0.14014| HIT@10: 0.12189: 100%|██████████| 1/1 [00:03<00:00,  3.92s/it]\n","Epoch: 107| Train loss: 1155.36147| NDCG@10: 0.13969| HIT@10: 0.12142: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n","Epoch: 108| Train loss: 1140.46010| NDCG@10: 0.14096| HIT@10: 0.12217: 100%|██████████| 1/1 [00:04<00:00,  4.10s/it]\n","Epoch: 109| Train loss: 1133.20658| NDCG@10: 0.13860| HIT@10: 0.12120: 100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n","Epoch: 110| Train loss: 1140.71835| NDCG@10: 0.13937| HIT@10: 0.12159: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch: 111| Train loss: 1146.54724| NDCG@10: 0.14163| HIT@10: 0.12303: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n","Epoch: 112| Train loss: 1130.35172| NDCG@10: 0.13943| HIT@10: 0.12179: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch: 113| Train loss: 1136.84058| NDCG@10: 0.14009| HIT@10: 0.12211: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n","Epoch: 114| Train loss: 1135.51322| NDCG@10: 0.14066| HIT@10: 0.12187: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 115| Train loss: 1129.59256| NDCG@10: 0.13889| HIT@10: 0.12169: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch: 116| Train loss: 1143.99005| NDCG@10: 0.14058| HIT@10: 0.12227: 100%|██████████| 1/1 [00:04<00:00,  4.10s/it]\n","Epoch: 117| Train loss: 1138.31778| NDCG@10: 0.14003| HIT@10: 0.12207: 100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n","Epoch: 118| Train loss: 1132.48439| NDCG@10: 0.14090| HIT@10: 0.12230: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 119| Train loss: 1143.38371| NDCG@10: 0.14063| HIT@10: 0.12237: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch: 120| Train loss: 1132.61438| NDCG@10: 0.14086| HIT@10: 0.12247: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch: 121| Train loss: 1133.42428| NDCG@10: 0.14002| HIT@10: 0.12201: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 122| Train loss: 1140.28431| NDCG@10: 0.13954| HIT@10: 0.12089: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n","Epoch: 123| Train loss: 1145.95764| NDCG@10: 0.13941| HIT@10: 0.12163: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch: 124| Train loss: 1130.63984| NDCG@10: 0.13944| HIT@10: 0.12152: 100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n","Epoch: 125| Train loss: 1136.90190| NDCG@10: 0.14066| HIT@10: 0.12203: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch: 126| Train loss: 1132.59528| NDCG@10: 0.14047| HIT@10: 0.12221: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 127| Train loss: 1129.86844| NDCG@10: 0.13987| HIT@10: 0.12205: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n","Epoch: 128| Train loss: 1132.40271| NDCG@10: 0.14019| HIT@10: 0.12232: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch: 129| Train loss: 1131.53807| NDCG@10: 0.14027| HIT@10: 0.12232: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch: 130| Train loss: 1140.23045| NDCG@10: 0.14105| HIT@10: 0.12245: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 131| Train loss: 1142.40697| NDCG@10: 0.13957| HIT@10: 0.12164: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 132| Train loss: 1133.34453| NDCG@10: 0.14043| HIT@10: 0.12213: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n","Epoch: 133| Train loss: 1131.01588| NDCG@10: 0.13944| HIT@10: 0.12190: 100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n","Epoch: 134| Train loss: 1132.29637| NDCG@10: 0.14041| HIT@10: 0.12224: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch: 135| Train loss: 1150.08800| NDCG@10: 0.14078| HIT@10: 0.12218: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch: 136| Train loss: 1147.23730| NDCG@10: 0.13989| HIT@10: 0.12176: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n","Epoch: 137| Train loss: 1147.79614| NDCG@10: 0.13992| HIT@10: 0.12218: 100%|██████████| 1/1 [00:03<00:00,  3.87s/it]\n","Epoch: 138| Train loss: 1140.80046| NDCG@10: 0.14022| HIT@10: 0.12239: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch: 139| Train loss: 1142.17975| NDCG@10: 0.13904| HIT@10: 0.12130: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch: 140| Train loss: 1136.34749| NDCG@10: 0.13997| HIT@10: 0.12211: 100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n","Epoch: 141| Train loss: 1135.18564| NDCG@10: 0.13995| HIT@10: 0.12224: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch: 142| Train loss: 1128.98921| NDCG@10: 0.14018| HIT@10: 0.12185: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 143| Train loss: 1135.12903| NDCG@10: 0.13929| HIT@10: 0.12192: 100%|██████████| 1/1 [00:04<00:00,  4.08s/it]\n","Epoch: 144| Train loss: 1135.44517| NDCG@10: 0.14041| HIT@10: 0.12209: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch: 145| Train loss: 1141.83470| NDCG@10: 0.14004| HIT@10: 0.12209: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch: 146| Train loss: 1132.48760| NDCG@10: 0.13965| HIT@10: 0.12187: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 147| Train loss: 1136.74553| NDCG@10: 0.14002| HIT@10: 0.12224: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch: 148| Train loss: 1127.68576| NDCG@10: 0.14043| HIT@10: 0.12277: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 149| Train loss: 1132.13226| NDCG@10: 0.14019| HIT@10: 0.12209: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 150| Train loss: 1136.18902| NDCG@10: 0.14100| HIT@10: 0.12253: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch: 151| Train loss: 1137.51740| NDCG@10: 0.13954| HIT@10: 0.12165: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n","Epoch: 152| Train loss: 1138.07212| NDCG@10: 0.14042| HIT@10: 0.12245: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 153| Train loss: 1128.60086| NDCG@10: 0.14025| HIT@10: 0.12227: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch: 154| Train loss: 1132.42723| NDCG@10: 0.13997| HIT@10: 0.12201: 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n","Epoch: 155| Train loss: 1133.93309| NDCG@10: 0.13947| HIT@10: 0.12163: 100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n","Epoch: 156| Train loss: 1140.45082| NDCG@10: 0.14122| HIT@10: 0.12250: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 157| Train loss: 1132.40555| NDCG@10: 0.14033| HIT@10: 0.12190: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 158| Train loss: 1134.12580| NDCG@10: 0.14091| HIT@10: 0.12263: 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n","Epoch: 159| Train loss: 1133.11608| NDCG@10: 0.13977| HIT@10: 0.12173: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch: 160| Train loss: 1136.96348| NDCG@10: 0.14108| HIT@10: 0.12247: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch: 161| Train loss: 1127.10599| NDCG@10: 0.14000| HIT@10: 0.12153: 100%|██████████| 1/1 [00:03<00:00,  4.00s/it]\n","Epoch: 162| Train loss: 1145.99785| NDCG@10: 0.14068| HIT@10: 0.12232: 100%|██████████| 1/1 [00:04<00:00,  4.02s/it]\n","Epoch: 163| Train loss: 1129.95529| NDCG@10: 0.14032| HIT@10: 0.12211: 100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\n","Epoch: 164| Train loss: 1139.81439| NDCG@10: 0.14130| HIT@10: 0.12256: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n","Epoch: 165| Train loss: 1132.50808| NDCG@10: 0.13936| HIT@10: 0.12190: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n","Epoch: 166| Train loss: 1141.43658| NDCG@10: 0.14124| HIT@10: 0.12264: 100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n","Epoch: 167| Train loss: 1138.05125| NDCG@10: 0.14129| HIT@10: 0.12252: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch: 168| Train loss: 1133.95910| NDCG@10: 0.14060| HIT@10: 0.12266: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n","Epoch: 169| Train loss: 1129.53132| NDCG@10: 0.14078| HIT@10: 0.12278: 100%|██████████| 1/1 [00:03<00:00,  3.92s/it]\n","Epoch: 170| Train loss: 1129.23080| NDCG@10: 0.14006| HIT@10: 0.12268: 100%|██████████| 1/1 [00:04<00:00,  4.16s/it]\n","Epoch: 171| Train loss: 1133.48610| NDCG@10: 0.13980| HIT@10: 0.12192: 100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n","Epoch: 172| Train loss: 1141.19812| NDCG@10: 0.13990| HIT@10: 0.12222: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch: 173| Train loss: 1139.71577| NDCG@10: 0.14020| HIT@10: 0.12211: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 174| Train loss: 1131.40752| NDCG@10: 0.13956| HIT@10: 0.12230: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 175| Train loss: 1133.51083| NDCG@10: 0.14003| HIT@10: 0.12237: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch: 176| Train loss: 1137.34838| NDCG@10: 0.13888| HIT@10: 0.12165: 100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n","Epoch: 177| Train loss: 1129.50833| NDCG@10: 0.14076| HIT@10: 0.12284: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch: 178| Train loss: 1135.59889| NDCG@10: 0.14012| HIT@10: 0.12160: 100%|██████████| 1/1 [00:03<00:00,  3.87s/it]\n","Epoch: 179| Train loss: 1131.25799| NDCG@10: 0.14075| HIT@10: 0.12218: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch: 180| Train loss: 1136.48940| NDCG@10: 0.14068| HIT@10: 0.12187: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n","Epoch: 181| Train loss: 1123.87810| NDCG@10: 0.14045| HIT@10: 0.12237: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch: 182| Train loss: 1135.67063| NDCG@10: 0.14105| HIT@10: 0.12256: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n","Epoch: 183| Train loss: 1134.75151| NDCG@10: 0.14106| HIT@10: 0.12252: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch: 184| Train loss: 1139.83476| NDCG@10: 0.14075| HIT@10: 0.12193: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 185| Train loss: 1142.45042| NDCG@10: 0.14008| HIT@10: 0.12214: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch: 186| Train loss: 1137.88426| NDCG@10: 0.13944| HIT@10: 0.12166: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n","Epoch: 187| Train loss: 1134.25136| NDCG@10: 0.13990| HIT@10: 0.12207: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 188| Train loss: 1140.30230| NDCG@10: 0.14116| HIT@10: 0.12277: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch: 189| Train loss: 1144.28325| NDCG@10: 0.14036| HIT@10: 0.12250: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch: 190| Train loss: 1136.67636| NDCG@10: 0.14102| HIT@10: 0.12260: 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n","Epoch: 191| Train loss: 1143.41550| NDCG@10: 0.14142| HIT@10: 0.12270: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n","Epoch: 192| Train loss: 1131.79878| NDCG@10: 0.14033| HIT@10: 0.12251: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 193| Train loss: 1136.42484| NDCG@10: 0.14099| HIT@10: 0.12246: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch: 194| Train loss: 1127.08760| NDCG@10: 0.14091| HIT@10: 0.12282: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n","Epoch: 195| Train loss: 1127.89726| NDCG@10: 0.14135| HIT@10: 0.12305: 100%|██████████| 1/1 [00:04<00:00,  4.00s/it]\n","Epoch: 196| Train loss: 1130.64212| NDCG@10: 0.13981| HIT@10: 0.12219: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n","Epoch: 197| Train loss: 1142.18001| NDCG@10: 0.14102| HIT@10: 0.12293: 100%|██████████| 1/1 [00:04<00:00,  4.04s/it]\n","Epoch: 198| Train loss: 1137.66756| NDCG@10: 0.14042| HIT@10: 0.12239: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n","Epoch: 199| Train loss: 1147.43905| NDCG@10: 0.13998| HIT@10: 0.12182: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n","Epoch: 200| Train loss: 1140.62239| NDCG@10: 0.13941| HIT@10: 0.12231: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n"]}],"source":["best_hit = 0\n","for epoch in range(1, config.num_epochs + 1):\n","    tbar = tqdm(range(1))\n","    for _ in tbar:\n","        \n","        if config.not_alternating:\n","            train_loss = train(\n","                    model = model,\n","                    optimizer = optimizer, \n","                    data_loader = data_loader,\n","                    make_matrix_data_set = make_matrix_data_set,\n","                    beta = config.beta,\n","                    gamma = config.gamma, \n","                    dropout_rate = config.dropout_rate,\n","                    )\n","        \n","        else:\n","            for _ in range(config.e_num_epochs):\n","                train_loss = train(\n","                        model = model,\n","                        optimizer = optimizer_encoder, \n","                        data_loader = data_loader,\n","                        make_matrix_data_set = make_matrix_data_set,\n","                        beta = config.beta,\n","                        gamma = config.gamma, \n","                        dropout_rate = config.dropout_rate,\n","                        )\n","\n","            model.update_prior()\n","            \n","            for _ in range(config.d_num_epochs):\n","                train_loss = train(\n","                        model = model,\n","                        optimizer = optimizer_decoder, \n","                        data_loader = data_loader,\n","                        make_matrix_data_set = make_matrix_data_set,\n","                        beta = config.beta,\n","                        gamma = config.gamma, \n","                        dropout_rate = 0.0,\n","                        )\n","\n","        ndcg, hit = evaluate(\n","            model = model,\n","            data_loader = data_loader,\n","            user_train = user_train,\n","            user_valid = user_valid,\n","            make_matrix_data_set = make_matrix_data_set,\n","            user_list = user_list,\n","            )\n","\n","        if best_hit < hit:\n","            best_hit = hit\n","            torch.save(model.state_dict(), os.path.join(config.model_path, config.model_name))\n","\n","        tbar.set_description(f'Epoch: {epoch:3d}| Train loss: {train_loss:.5f}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["# 6. 예측"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["model.load_state_dict(torch.load(os.path.join(config.model_path, config.model_name)))\n","\n","submission_data_loader = DataLoader(\n","    ae_dataset,\n","    batch_size = config.batch_size, \n","    shuffle = False, \n","    pin_memory = True,\n","    num_workers = config.num_workers,\n","    )\n","\n","user2rec_list = predict(\n","    model = model, \n","    data_loader = submission_data_loader,\n","    user_train = user_train, \n","    user_valid = user_valid, \n","    make_matrix_data_set = make_matrix_data_set\n","    )\n","\n","submision = []\n","users = [i for i in range(0, make_matrix_data_set.num_user)]\n","for user in users:\n","    rec_item_list = user2rec_list[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>31696</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>5218</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>32587</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>2617</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>3156</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>313595</th>\n","      <td>138493</td>\n","      <td>551</td>\n","    </tr>\n","    <tr>\n","      <th>313596</th>\n","      <td>138493</td>\n","      <td>33615</td>\n","    </tr>\n","    <tr>\n","      <th>313597</th>\n","      <td>138493</td>\n","      <td>2012</td>\n","    </tr>\n","    <tr>\n","      <th>313598</th>\n","      <td>138493</td>\n","      <td>1270</td>\n","    </tr>\n","    <tr>\n","      <th>313599</th>\n","      <td>138493</td>\n","      <td>2011</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>313600 rows × 2 columns</p>\n","</div>"],"text/plain":["          user   item\n","0           11  31696\n","1           11   5218\n","2           11  32587\n","3           11   2617\n","4           11   3156\n","...        ...    ...\n","313595  138493    551\n","313596  138493  33615\n","313597  138493   2012\n","313598  138493   1270\n","313599  138493   2011\n","\n","[313600 rows x 2 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["submision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPM3QPpy4d2rTojqCpQQ3Sd","collapsed_sections":[],"mount_file_id":"1evrCGpMqJ5p9riyjuK5gz4EIiOyfixc1","name":"RecVAE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
