{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ug-br-pPu9vZ"},"outputs":[],"source":["import math\n","import numpy as np\n","import scipy.sparse as sp\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import defaultdict\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from box import Box\n","\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","torch.set_printoptions(sci_mode=True)"]},{"cell_type":"markdown","metadata":{"id":"pbRKDSg4u9vc"},"source":["# 1. 학습 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MEhK_fLIu9vd"},"outputs":[],"source":["config = {\n","    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n","    \n","    'submission_path' : \"../submission\",\n","    'submission_name' : 'Multi-EASE_submission.csv', \n","\n","    'model_path' : \"../model\", # 모델 저장 경로\n","    'model_name' : 'Multi-EASE_v1.pt',\n","    \n","    'weight_decay' : 0.0,\n","    'valid_samples' : 10, # 검증에 사용할 sample 수\n","    'seed' : 22,\n","\n","\n","    'lr' : 0.0005,\n","    'batch_size' : 1000,\n","    'num_epochs' : 200,\n","    'num_workers' : 2,\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","config = Box(config)"]},{"cell_type":"markdown","metadata":{"id":"wjDxy0fJu9vf"},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W64BYWl0u9vg"},"outputs":[],"source":["class MakeMatrixDataSet():\n","    \"\"\"\n","    MatrixDataSet 생성\n","    \"\"\"\n","    def __init__(self, config):\n","        self.config = config\n","        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n","        \n","        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n","        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n","        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n","\n","        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n","        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n","\n","        self.user_train, self.user_valid = self.generate_sequence_data()\n","\n","    def generate_encoder_decoder(self, col : str) -> dict:\n","        \"\"\"\n","        encoder, decoder 생성\n","\n","        Args:\n","            col (str): 생성할 columns 명\n","        Returns:\n","            dict: 생성된 user encoder, decoder\n","        \"\"\"\n","\n","        encoder = {}\n","        decoder = {}\n","        ids = self.df[col].unique()\n","\n","        for idx, _id in enumerate(ids):\n","            encoder[_id] = idx\n","            decoder[idx] = _id\n","\n","        return encoder, decoder\n","    \n","    def generate_sequence_data(self) -> dict:\n","        \"\"\"\n","        sequence_data 생성\n","\n","        Returns:\n","            dict: train user sequence / valid user sequence\n","        \"\"\"\n","        users = defaultdict(list)\n","        user_train = {}\n","        user_valid = {}\n","        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n","            users[user].append(item)\n","        \n","        for user in users:\n","            np.random.seed(self.config.seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            user_train[user] = train\n","            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n","\n","        return user_train, user_valid\n","    \n","    def get_train_valid_data(self):\n","        return self.user_train, self.user_valid\n","\n","    def make_matrix(self, user_list, train = True):\n","        \"\"\"\n","        user_item_dict를 바탕으로 행렬 생성\n","        \"\"\"\n","        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n","        for idx, user in enumerate(user_list):\n","            if train:\n","                mat[idx, self.user_train[user.item()]] = 1\n","            else:\n","                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n","        return mat\n","\n","    def make_sparse_matrix(self, test = False):\n","        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n","        \n","        for user in self.user_train.keys():\n","            item_list = self.user_train[user]\n","            X[user, item_list] = 1.0\n","        \n","        if test:\n","            for user in self.user_valid.keys():\n","                item_list = self.user_valid[user]\n","                X[user, item_list] = 1.0\n","\n","        return X.tocsr()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IldCGmY8u9vh"},"outputs":[],"source":["class AEDataSet(Dataset):\n","    def __init__(self, num_user):\n","        self.num_user = num_user\n","\n","    def __len__(self):\n","        return self.num_user\n","\n","    def __getitem__(self, user):\n","        return torch.LongTensor([user])"]},{"cell_type":"markdown","metadata":{"id":"ysia457Su9vi"},"source":["# 3. 모델"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TVXWUTLpSh8_"},"outputs":[],"source":["class MultiEASE(nn.Module):\n","    def __init__(self, X):\n","        super(MultiEASE, self).__init__()\n","        self.user_emb = nn.Embedding.from_pretrained(X)\n","        self.user_emb.requires_grad_(True)\n","\n","    \n","    def _convert_sp_mat_to_sp_tensor(self, X):\n","        \"\"\"\n","        Convert scipy sparse matrix to PyTorch sparse matrix\n","\n","        Arguments:\n","        ----------\n","        X = Adjacency matrix, scipy sparse matrix\n","        \"\"\"\n","        coo = X.tocoo().astype(np.float32)\n","        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n","        v = torch.FloatTensor(coo.data)\n","        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n","        return res\n","    \n","    def set_B(self, X, reg):\n","        X = self._convert_sp_mat_to_sp_tensor(X)\n","        G = X.to_dense().t() @ X.to_dense()\n","        diagIndices = torch.eye(G.shape[0]) == 1\n","        G[diagIndices] += reg\n","        \n","        P = G.inverse()\n","        B = P / (-1 * P.diag())\n","        B[diagIndices] = 0\n","\n","        self.B = B\n","\n","    def forward(self, user):\n","        user_emb = self.user_emb(user)\n","        output = user_emb @ self.B\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MultiLoss(nn.Module):\n","    def __init__(self):\n","        super(MultiLoss, self).__init__()\n","        \n","    def forward(self, x_pred, user_ratings):\n","        mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n","        return -mll"]},{"cell_type":"markdown","metadata":{"id":"GwSexh43u9vk"},"source":["# 4. 학습 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nws4JO2_rgQP"},"outputs":[],"source":["def train(model, criterion, optimizer, data_loader, make_matrix_data_set):\n","    model.train()\n","    loss_val = 0\n","\n","    for users in data_loader:\n","        mat = make_matrix_data_set.make_matrix(users)\n","        mat = mat.to(device)\n","        \n","        recon_mat = model(users.view(-1).to(device))\n","        \n","        optimizer.zero_grad()\n","        loss = criterion(recon_mat, mat)\n","\n","        loss_val += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    loss_val /= len(data_loader)\n","\n","    return loss_val\n","\n","def get_ndcg(pred_list, true_list):\n","    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n","    dcg = 0\n","    for rank, pred in enumerate(pred_list):\n","        if pred in true_list:\n","            dcg += 1 / np.log2(rank + 2)\n","    ndcg = dcg / idcg\n","    return ndcg\n","\n","# hit == recall == precision\n","def get_hit(pred_list, true_list):\n","    hit_list = set(true_list) & set(pred_list)\n","    hit = len(hit_list) / len(true_list)\n","    return hit\n","\n","def evaluate(model, data_loader, user_train, user_valid, make_matrix_data_set):\n","    model.eval()\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    with torch.no_grad():\n","        for users in data_loader:\n","            mat = make_matrix_data_set.make_matrix(users)\n","            mat = mat.to(device)\n","            \n","            recon_mat = model(users.view(-1).to(device))\n","            recon_mat[mat == 1] = -np.inf\n","            rec_list = recon_mat.argsort(dim = 1)\n","\n","            for user, rec in zip(users, rec_list):\n","                uv = user_valid[user.item()]\n","                up = rec[-10:].cpu().numpy().tolist()[::-1]\n","                NDCG += get_ndcg(pred_list = up, true_list = uv)\n","                HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(data_loader.dataset)\n","    HIT /= len(data_loader.dataset)\n","\n","    return NDCG, HIT"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MultiLoss(nn.Module):\n","    def __init__(self):\n","        super(MultiLoss, self).__init__()\n","        \n","    def forward(self, x_pred, user_ratings):\n","        mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n","        return -mll"]},{"cell_type":"markdown","metadata":{"id":"gupkaJHMslCi"},"source":["# 5. 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFOr6Wmbq9pW"},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n","X = make_matrix_data_set.make_sparse_matrix()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ae_dataset = AEDataSet(\n","    num_user = make_matrix_data_set.num_user,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_loader = DataLoader(\n","    ae_dataset,\n","    batch_size = config.batch_size, \n","    shuffle = True,\n","    pin_memory = True,\n","    num_workers = config.num_workers,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = MultiEASE(\n","    X = torch.from_numpy(X.toarray()).to(device)\n",").to(device)\n","\n","model.set_B(X = X, reg = 680)\n","\n","criterion = MultiLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay = config.weight_decay)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_hit = 0\n","for epoch in range(1, config.num_epochs + 1):\n","    tbar = tqdm(range(1))\n","    for _ in tbar:\n","        train_loss = train(\n","            model = model, \n","            criterion = criterion, \n","            optimizer = optimizer, \n","            data_loader = data_loader,\n","            make_matrix_data_set = make_matrix_data_set,\n","            )\n","        \n","        ndcg, hit = evaluate(\n","            model = model, \n","            data_loader = data_loader,\n","            user_train = user_train,\n","            user_valid = user_valid,\n","            make_matrix_data_set = make_matrix_data_set,\n","            )\n","\n","        if best_hit < hit:\n","            best_hit = hit\n","            torch.save(model.state_dict(), os.path.join(config.model_path, config.model_name))\n","\n","        tbar.set_description(f'Epoch: {epoch:3d}| Train loss: {train_loss:.5f}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NDCG = 0\n","HIT = 0\n","\n","user_data = model.user_emb.weight.data\n","mat = torch.from_numpy(X.toarray()).to(device)\n","user_data[mat == 1] = -np.inf\n","rec_list = user_data.argsort(dim = 1)\n","\n","for user, rec in enumerate(rec_list):\n","    uv = user_valid[user]\n","    up = rec[-10:].cpu().numpy().tolist()[::-1]\n","    NDCG += get_ndcg(pred_list = up, true_list = uv)\n","    HIT += get_hit(pred_list = up, true_list = uv)\n","\n","NDCG /= len(rec_list)\n","HIT /= len(rec_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","for user in range(31360):\n","    output = cos(mat[user], mat)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMB0K8DmOwclQIFyyBerAFJ","collapsed_sections":[],"mount_file_id":"1C1AHkN-z-DCxUIAjFfd7K56P-8-YrAJO","name":"EASE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
