{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ug-br-pPu9vZ"},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import defaultdict\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from box import Box\n","\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","torch.set_printoptions(sci_mode=True)"]},{"cell_type":"markdown","metadata":{"id":"pbRKDSg4u9vc"},"source":["# 1. 학습 설정"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mlm1UrKvoC_O"},"outputs":[],"source":["config = {\n","    'data_path' : \"/opt/ml/input/data/train\" , # 데이터 경로\n","    \n","    'submission_path' : \"../submission\",\n","    'submission_name' : 'AutoRec_v1_submission.csv', \n","\n","    'model_path' : \"../model\", # 모델 저장 경로\n","    'model_name' : 'AutoRec_v1.pt',\n","\n","    'num_factor': 64,\n","\n","    'valid_samples' : 10, # 검증에 사용할 sample 수\n","    'seed' : 22,\n","\n","    'lr' : 0.005,\n","    'batch_size' : 256,\n","    'num_epochs' : 200,\n","    'num_workers' : 2,\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","config = Box(config)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"iqVUlLd9u9ve"},"outputs":[],"source":["if not os.path.isdir(config.model_path):\n","    os.mkdir(config.model_path)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["if not os.path.isdir(config.submission_path):\n","    os.mkdir(config.submission_path)"]},{"cell_type":"markdown","metadata":{"id":"wjDxy0fJu9vf"},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"W64BYWl0u9vg"},"outputs":[],"source":["class MakeMatrixDataSet():\n","    \"\"\"\n","    MatrixDataSet 생성\n","    \"\"\"\n","    def __init__(self, config):\n","        self.config = config\n","        self.df = pd.read_csv(os.path.join(self.config.data_path, 'train_ratings.csv'))\n","\n","        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('item')\n","        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('user')\n","        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n","\n","        self.df['item_idx'] = self.df['item'].apply(lambda x : self.item_encoder[x])\n","        self.df['user_idx'] = self.df['user'].apply(lambda x : self.user_encoder[x])\n","\n","        self.user_train, self.user_valid = self.generate_sequence_data()\n","\n","    def generate_encoder_decoder(self, col : str) -> dict:\n","        \"\"\"\n","        encoder, decoder 생성\n","\n","        Args:\n","            col (str): 생성할 columns 명\n","        Returns:\n","            dict: 생성된 user encoder, decoder\n","        \"\"\"\n","\n","        encoder = {}\n","        decoder = {}\n","        ids = self.df[col].unique()\n","\n","        for idx, _id in enumerate(ids):\n","            encoder[_id] = idx\n","            decoder[idx] = _id\n","\n","        return encoder, decoder\n","    \n","    def generate_sequence_data(self) -> dict:\n","        \"\"\"\n","        sequence_data 생성\n","\n","        Returns:\n","            dict: train user sequence / valid user sequence\n","        \"\"\"\n","        users = defaultdict(list)\n","        user_train = {}\n","        user_valid = {}\n","        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['time']):\n","            users[user].append(item)\n","        \n","        for user in users:\n","            np.random.seed(self.config.seed)\n","\n","            user_total = users[user]\n","            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n","            train = list(set(user_total) - set(valid))\n","\n","            user_train[user] = train\n","            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n","\n","        return user_train, user_valid\n","    \n","    def get_train_valid_data(self):\n","        return self.user_train, self.user_valid\n","\n","    def make_matrix(self, user_list, train = True):\n","        \"\"\"\n","        user_item_dict를 바탕으로 행렬 생성\n","        \"\"\"\n","        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n","        for idx, user in enumerate(user_list):\n","            if train:\n","                mat[idx, self.user_train[user.item()]] = 1\n","            else:\n","                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n","        return mat\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IldCGmY8u9vh"},"outputs":[],"source":["class AEDataSet(Dataset):\n","    def __init__(self, num_user):\n","        self.num_user = num_user\n","        self.users = [i for i in range(num_user)]\n","\n","    def __len__(self):\n","        return self.num_user\n","\n","    def __getitem__(self, idx): \n","        user = self.users[idx]\n","        return torch.LongTensor([user])"]},{"cell_type":"markdown","metadata":{"id":"ysia457Su9vi"},"source":["# 3. 모델"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"_EgjAJ-ju9vj"},"outputs":[],"source":["class AutoRec(nn.Module):\n","    def __init__(self, num, num_factor):\n","        super(AutoRec, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(num, num_factor),\n","            nn.Sigmoid(),\n","            nn.Linear(num_factor, num_factor // 2),\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(num_factor // 2, num_factor),\n","            nn.Sigmoid(),\n","            nn.Linear(num_factor, num),\n","        )\n","\n","        self.init_weights()\n","\n","    def forward(self, mat):\n","        latent = self.encoder(mat)\n","        recont_mat = self.decoder(latent)\n","\n","        return recont_mat\n","\n","    def init_weights(self):\n","        for layer in self.encoder:\n","            if isinstance(layer, nn.Linear):\n","                size = layer.weight.size()\n","                fan_out = size[0]\n","                fan_in = size[1]\n","                std = np.sqrt(2.0/(fan_in + fan_out))\n","                layer.weight.data.normal_(0.0, std)\n","                layer.bias.data.normal_(0.0, 0.001)\n","        \n","        for layer in self.decoder:\n","            if isinstance(layer, nn.Linear):\n","                size = layer.weight.size()\n","                fan_out = size[0]\n","                fan_in = size[1]\n","                std = np.sqrt(2.0/(fan_in + fan_out))\n","                layer.weight.data.normal_(0.0, std)\n","                layer.bias.data.normal_(0.0, 0.001)"]},{"cell_type":"markdown","metadata":{"id":"vw2LhYkau9vj"},"source":["# 4. 학습 함수"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Rmooa3n1u9vj"},"outputs":[],"source":["def train(model, criterion, optimizer, data_loader, make_matrix_data_set):\n","    model.train()\n","    loss_val = 0\n","    for users in data_loader:\n","        mat = make_matrix_data_set.make_matrix(users)\n","        mat = mat.to(device)\n","        recon_mat = model(mat)\n","\n","        optimizer.zero_grad()\n","        loss = criterion(recon_mat, mat)\n","\n","        loss_val += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","    \n","    loss_val /= len(data_loader)\n","\n","    return loss_val\n","\n","def get_ndcg(pred_list, true_list):\n","    ndcg = 0\n","    for rank, pred in enumerate(pred_list):\n","        if pred in true_list:\n","            ndcg += 1 / np.log2(rank + 2)\n","    return ndcg\n","\n","# hit == recall == precision\n","def get_hit(pred_list, true_list):\n","    hit_list = set(true_list) & set(pred_list)\n","    hit = len(hit_list) / len(true_list)\n","    return hit\n","\n","def evaluate(model, data_loader, user_train, user_valid, make_matrix_data_set):\n","    model.eval()\n","\n","    NDCG = 0.0 # NDCG@10\n","    HIT = 0.0 # HIT@10\n","\n","    with torch.no_grad():\n","        for users in data_loader:\n","            mat = make_matrix_data_set.make_matrix(users)\n","            mat = mat.to(device)\n","\n","            recon_mat = model(mat)\n","            recon_mat[mat == 1] = -np.inf\n","            rec_list = recon_mat.argsort(dim = 1)\n","\n","            for user, rec in zip(users, rec_list):\n","                uv = user_valid[user.item()]\n","                up = rec[-10:].cpu().numpy().tolist()\n","                NDCG += get_ndcg(pred_list = up, true_list = uv)\n","                HIT += get_hit(pred_list = up, true_list = uv)\n","\n","    NDCG /= len(data_loader.dataset)\n","    HIT /= len(data_loader.dataset)\n","\n","    return NDCG, HIT\n","\n","def predict(model, data_loader, user_train, user_valid, make_matrix_data_set):\n","    model.eval()\n","    \n","    user2rec_list = {}\n","    with torch.no_grad():\n","        for users in data_loader:\n","            mat = make_matrix_data_set.make_matrix(users, train = False)\n","            mat = mat.to(device)\n","\n","            recon_mat = model(mat)\n","            recon_mat = recon_mat.softmax(dim = 1)\n","            recon_mat[mat == 1] = -1.\n","            rec_list = recon_mat.argsort(dim = 1)\n","\n","            for user, rec in zip(users, rec_list):\n","                up = rec[-10:].cpu().numpy().tolist()\n","                user2rec_list[user.item()] = up\n","    \n","    return user2rec_list"]},{"cell_type":"markdown","metadata":{"id":"GwSexh43u9vk"},"source":["# 5. 학습"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"3zXVEf6fu9vk"},"outputs":[],"source":["make_matrix_data_set = MakeMatrixDataSet(config = config)\n","user_train, user_valid = make_matrix_data_set.get_train_valid_data()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3hGPyH54u9vk"},"outputs":[],"source":["ae_dataset = AEDataSet(\n","    num_user = make_matrix_data_set.num_user,\n","    )"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dyL3vriiu9vl"},"outputs":[],"source":["data_loader = DataLoader(\n","    ae_dataset,\n","    batch_size = config.batch_size, \n","    shuffle = True, \n","    pin_memory = True,\n","    num_workers = config.num_workers,\n","    )"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dpiWnBV8u9vm"},"outputs":[],"source":["model = AutoRec(\n","    num = make_matrix_data_set.num_item, \n","    num_factor = config.num_factor).to(device)\n","\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91728,"status":"ok","timestamp":1648376170738,"user":{"displayName":"이성범","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11166281350151773159"},"user_tz":-540},"id":"L_MtN5IOu9vm","outputId":"d1726d89-f7ba-4d13-b45c-6f3a95aa3330"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch:   1| Train loss: 0.01912| NDCG@10: 0.36197| HIT@10: 0.08800: 100%|██████████| 1/1 [00:05<00:00,  5.76s/it]\n","Epoch:   2| Train loss: 0.01780| NDCG@10: 0.46339| HIT@10: 0.11223: 100%|██████████| 1/1 [00:05<00:00,  5.54s/it]\n","Epoch:   3| Train loss: 0.01694| NDCG@10: 0.49803| HIT@10: 0.12140: 100%|██████████| 1/1 [00:05<00:00,  5.52s/it]\n","Epoch:   4| Train loss: 0.01649| NDCG@10: 0.55305| HIT@10: 0.13531: 100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n","Epoch:   5| Train loss: 0.01616| NDCG@10: 0.57712| HIT@10: 0.14159: 100%|██████████| 1/1 [00:05<00:00,  5.71s/it]\n","Epoch:   6| Train loss: 0.01594| NDCG@10: 0.60069| HIT@10: 0.14739: 100%|██████████| 1/1 [00:05<00:00,  5.90s/it]\n","Epoch:   7| Train loss: 0.01576| NDCG@10: 0.61725| HIT@10: 0.15167: 100%|██████████| 1/1 [00:05<00:00,  5.88s/it]\n","Epoch:   8| Train loss: 0.01563| NDCG@10: 0.62688| HIT@10: 0.15472: 100%|██████████| 1/1 [00:05<00:00,  5.74s/it]\n","Epoch:   9| Train loss: 0.01552| NDCG@10: 0.63828| HIT@10: 0.15730: 100%|██████████| 1/1 [00:05<00:00,  5.88s/it]\n","Epoch:  10| Train loss: 0.01544| NDCG@10: 0.64545| HIT@10: 0.15966: 100%|██████████| 1/1 [00:05<00:00,  5.78s/it]\n","Epoch:  11| Train loss: 0.01536| NDCG@10: 0.65487| HIT@10: 0.16201: 100%|██████████| 1/1 [00:05<00:00,  5.76s/it]\n","Epoch:  12| Train loss: 0.01529| NDCG@10: 0.65995| HIT@10: 0.16336: 100%|██████████| 1/1 [00:05<00:00,  5.80s/it]\n","Epoch:  13| Train loss: 0.01523| NDCG@10: 0.65790| HIT@10: 0.16359: 100%|██████████| 1/1 [00:05<00:00,  5.86s/it]\n","Epoch:  14| Train loss: 0.01519| NDCG@10: 0.66504| HIT@10: 0.16488: 100%|██████████| 1/1 [00:05<00:00,  5.46s/it]\n","Epoch:  15| Train loss: 0.01517| NDCG@10: 0.67064| HIT@10: 0.16580: 100%|██████████| 1/1 [00:05<00:00,  5.85s/it]\n","Epoch:  16| Train loss: 0.01512| NDCG@10: 0.67298| HIT@10: 0.16650: 100%|██████████| 1/1 [00:05<00:00,  5.66s/it]\n","Epoch:  17| Train loss: 0.01507| NDCG@10: 0.67700| HIT@10: 0.16790: 100%|██████████| 1/1 [00:05<00:00,  5.80s/it]\n","Epoch:  18| Train loss: 0.01502| NDCG@10: 0.68189| HIT@10: 0.16918: 100%|██████████| 1/1 [00:05<00:00,  5.62s/it]\n","Epoch:  19| Train loss: 0.01500| NDCG@10: 0.68028| HIT@10: 0.16875: 100%|██████████| 1/1 [00:05<00:00,  5.93s/it]\n","Epoch:  20| Train loss: 0.01497| NDCG@10: 0.68156| HIT@10: 0.16911: 100%|██████████| 1/1 [00:05<00:00,  5.65s/it]\n","Epoch:  21| Train loss: 0.01496| NDCG@10: 0.68049| HIT@10: 0.16923: 100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n","Epoch:  22| Train loss: 0.01494| NDCG@10: 0.68481| HIT@10: 0.17001: 100%|██████████| 1/1 [00:05<00:00,  5.82s/it]\n","Epoch:  23| Train loss: 0.01492| NDCG@10: 0.68665| HIT@10: 0.17033: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n","Epoch:  24| Train loss: 0.01491| NDCG@10: 0.68652| HIT@10: 0.17066: 100%|██████████| 1/1 [00:05<00:00,  5.99s/it]\n","Epoch:  25| Train loss: 0.01489| NDCG@10: 0.69046| HIT@10: 0.17115: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch:  26| Train loss: 0.01489| NDCG@10: 0.68726| HIT@10: 0.17063: 100%|██████████| 1/1 [00:05<00:00,  5.92s/it]\n","Epoch:  27| Train loss: 0.01487| NDCG@10: 0.69088| HIT@10: 0.17140: 100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n","Epoch:  28| Train loss: 0.01485| NDCG@10: 0.68770| HIT@10: 0.17124: 100%|██████████| 1/1 [00:06<00:00,  6.01s/it]\n","Epoch:  29| Train loss: 0.01484| NDCG@10: 0.69092| HIT@10: 0.17178: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it]\n","Epoch:  30| Train loss: 0.01484| NDCG@10: 0.68965| HIT@10: 0.17159: 100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n","Epoch:  31| Train loss: 0.01483| NDCG@10: 0.69302| HIT@10: 0.17206: 100%|██████████| 1/1 [00:05<00:00,  5.94s/it]\n","Epoch:  32| Train loss: 0.01482| NDCG@10: 0.69473| HIT@10: 0.17207: 100%|██████████| 1/1 [00:06<00:00,  6.21s/it]\n","Epoch:  33| Train loss: 0.01480| NDCG@10: 0.69434| HIT@10: 0.17245: 100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n","Epoch:  34| Train loss: 0.01479| NDCG@10: 0.69459| HIT@10: 0.17270: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch:  35| Train loss: 0.01479| NDCG@10: 0.69458| HIT@10: 0.17274: 100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n","Epoch:  36| Train loss: 0.01479| NDCG@10: 0.69204| HIT@10: 0.17170: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it]\n","Epoch:  37| Train loss: 0.01480| NDCG@10: 0.69427| HIT@10: 0.17246: 100%|██████████| 1/1 [00:06<00:00,  6.08s/it]\n","Epoch:  38| Train loss: 0.01478| NDCG@10: 0.69587| HIT@10: 0.17260: 100%|██████████| 1/1 [00:05<00:00,  5.74s/it]\n","Epoch:  39| Train loss: 0.01477| NDCG@10: 0.69468| HIT@10: 0.17250: 100%|██████████| 1/1 [00:05<00:00,  5.89s/it]\n","Epoch:  40| Train loss: 0.01477| NDCG@10: 0.69404| HIT@10: 0.17217: 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]\n","Epoch:  41| Train loss: 0.01477| NDCG@10: 0.69829| HIT@10: 0.17326: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n","Epoch:  42| Train loss: 0.01477| NDCG@10: 0.69711| HIT@10: 0.17284: 100%|██████████| 1/1 [00:05<00:00,  5.73s/it]\n","Epoch:  43| Train loss: 0.01476| NDCG@10: 0.69930| HIT@10: 0.17369: 100%|██████████| 1/1 [00:05<00:00,  5.81s/it]\n","Epoch:  44| Train loss: 0.01476| NDCG@10: 0.69447| HIT@10: 0.17257: 100%|██████████| 1/1 [00:05<00:00,  5.94s/it]\n","Epoch:  45| Train loss: 0.01475| NDCG@10: 0.69699| HIT@10: 0.17333: 100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n","Epoch:  46| Train loss: 0.01475| NDCG@10: 0.69430| HIT@10: 0.17295: 100%|██████████| 1/1 [00:05<00:00,  5.75s/it]\n","Epoch:  47| Train loss: 0.01475| NDCG@10: 0.69784| HIT@10: 0.17348: 100%|██████████| 1/1 [00:05<00:00,  5.74s/it]\n","Epoch:  48| Train loss: 0.01474| NDCG@10: 0.69591| HIT@10: 0.17313: 100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n","Epoch:  49| Train loss: 0.01472| NDCG@10: 0.69983| HIT@10: 0.17355: 100%|██████████| 1/1 [00:06<00:00,  6.14s/it]\n","Epoch:  50| Train loss: 0.01472| NDCG@10: 0.69543| HIT@10: 0.17276: 100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n","Epoch:  51| Train loss: 0.01472| NDCG@10: 0.69855| HIT@10: 0.17312: 100%|██████████| 1/1 [00:05<00:00,  5.99s/it]\n","Epoch:  52| Train loss: 0.01471| NDCG@10: 0.69570| HIT@10: 0.17273: 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]\n","Epoch:  53| Train loss: 0.01471| NDCG@10: 0.69864| HIT@10: 0.17354: 100%|██████████| 1/1 [00:06<00:00,  6.32s/it]\n","Epoch:  54| Train loss: 0.01471| NDCG@10: 0.69401| HIT@10: 0.17241: 100%|██████████| 1/1 [00:06<00:00,  6.29s/it]\n","Epoch:  55| Train loss: 0.01471| NDCG@10: 0.69507| HIT@10: 0.17290: 100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n","Epoch:  56| Train loss: 0.01471| NDCG@10: 0.69900| HIT@10: 0.17326: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch:  57| Train loss: 0.01472| NDCG@10: 0.69577| HIT@10: 0.17210: 100%|██████████| 1/1 [00:06<00:00,  6.27s/it]\n","Epoch:  58| Train loss: 0.01471| NDCG@10: 0.69750| HIT@10: 0.17338: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch:  59| Train loss: 0.01470| NDCG@10: 0.69392| HIT@10: 0.17239: 100%|██████████| 1/1 [00:05<00:00,  5.99s/it]\n","Epoch:  60| Train loss: 0.01470| NDCG@10: 0.70062| HIT@10: 0.17438: 100%|██████████| 1/1 [00:05<00:00,  5.86s/it]\n","Epoch:  61| Train loss: 0.01469| NDCG@10: 0.69544| HIT@10: 0.17273: 100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n","Epoch:  62| Train loss: 0.01469| NDCG@10: 0.69809| HIT@10: 0.17367: 100%|██████████| 1/1 [00:06<00:00,  6.23s/it]\n","Epoch:  63| Train loss: 0.01470| NDCG@10: 0.69975| HIT@10: 0.17373: 100%|██████████| 1/1 [00:06<00:00,  6.21s/it]\n","Epoch:  64| Train loss: 0.01470| NDCG@10: 0.69720| HIT@10: 0.17277: 100%|██████████| 1/1 [00:06<00:00,  6.14s/it]\n","Epoch:  65| Train loss: 0.01469| NDCG@10: 0.69911| HIT@10: 0.17345: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n","Epoch:  66| Train loss: 0.01469| NDCG@10: 0.69624| HIT@10: 0.17312: 100%|██████████| 1/1 [00:05<00:00,  5.93s/it]\n","Epoch:  67| Train loss: 0.01468| NDCG@10: 0.69976| HIT@10: 0.17416: 100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n","Epoch:  68| Train loss: 0.01468| NDCG@10: 0.70139| HIT@10: 0.17422: 100%|██████████| 1/1 [00:06<00:00,  6.11s/it]\n","Epoch:  69| Train loss: 0.01469| NDCG@10: 0.69851| HIT@10: 0.17375: 100%|██████████| 1/1 [00:05<00:00,  5.80s/it]\n","Epoch:  70| Train loss: 0.01468| NDCG@10: 0.69700| HIT@10: 0.17310: 100%|██████████| 1/1 [00:05<00:00,  5.86s/it]\n","Epoch:  71| Train loss: 0.01469| NDCG@10: 0.70091| HIT@10: 0.17436: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n","Epoch:  72| Train loss: 0.01467| NDCG@10: 0.69146| HIT@10: 0.17270: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n","Epoch:  73| Train loss: 0.01466| NDCG@10: 0.69897| HIT@10: 0.17366: 100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n","Epoch:  74| Train loss: 0.01466| NDCG@10: 0.70016| HIT@10: 0.17386: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch:  75| Train loss: 0.01467| NDCG@10: 0.69702| HIT@10: 0.17383: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it]\n","Epoch:  76| Train loss: 0.01467| NDCG@10: 0.69828| HIT@10: 0.17410: 100%|██████████| 1/1 [00:06<00:00,  6.24s/it]\n","Epoch:  77| Train loss: 0.01466| NDCG@10: 0.69902| HIT@10: 0.17360: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n","Epoch:  78| Train loss: 0.01466| NDCG@10: 0.69905| HIT@10: 0.17421: 100%|██████████| 1/1 [00:06<00:00,  6.15s/it]\n","Epoch:  79| Train loss: 0.01466| NDCG@10: 0.70028| HIT@10: 0.17401: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it]\n","Epoch:  80| Train loss: 0.01467| NDCG@10: 0.69937| HIT@10: 0.17399: 100%|██████████| 1/1 [00:05<00:00,  5.99s/it]\n","Epoch:  81| Train loss: 0.01467| NDCG@10: 0.69720| HIT@10: 0.17351: 100%|██████████| 1/1 [00:06<00:00,  6.16s/it]\n","Epoch:  82| Train loss: 0.01467| NDCG@10: 0.69824| HIT@10: 0.17310: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch:  83| Train loss: 0.01467| NDCG@10: 0.69945| HIT@10: 0.17380: 100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n","Epoch:  84| Train loss: 0.01465| NDCG@10: 0.69975| HIT@10: 0.17406: 100%|██████████| 1/1 [00:05<00:00,  5.85s/it]\n","Epoch:  85| Train loss: 0.01465| NDCG@10: 0.69986| HIT@10: 0.17365: 100%|██████████| 1/1 [00:05<00:00,  5.94s/it]\n","Epoch:  86| Train loss: 0.01464| NDCG@10: 0.69903| HIT@10: 0.17385: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n","Epoch:  87| Train loss: 0.01465| NDCG@10: 0.70240| HIT@10: 0.17472: 100%|██████████| 1/1 [00:05<00:00,  5.95s/it]\n","Epoch:  88| Train loss: 0.01465| NDCG@10: 0.70087| HIT@10: 0.17374: 100%|██████████| 1/1 [00:05<00:00,  5.99s/it]\n","Epoch:  89| Train loss: 0.01465| NDCG@10: 0.70052| HIT@10: 0.17387: 100%|██████████| 1/1 [00:05<00:00,  5.87s/it]\n","Epoch:  90| Train loss: 0.01465| NDCG@10: 0.70018| HIT@10: 0.17396: 100%|██████████| 1/1 [00:05<00:00,  5.89s/it]\n","Epoch:  91| Train loss: 0.01464| NDCG@10: 0.70049| HIT@10: 0.17451: 100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n","Epoch:  92| Train loss: 0.01464| NDCG@10: 0.70336| HIT@10: 0.17447: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n","Epoch:  93| Train loss: 0.01465| NDCG@10: 0.69961| HIT@10: 0.17403: 100%|██████████| 1/1 [00:05<00:00,  5.94s/it]\n","Epoch:  94| Train loss: 0.01464| NDCG@10: 0.69963| HIT@10: 0.17420: 100%|██████████| 1/1 [00:05<00:00,  5.74s/it]\n","Epoch:  95| Train loss: 0.01464| NDCG@10: 0.69807| HIT@10: 0.17318: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n","Epoch:  96| Train loss: 0.01465| NDCG@10: 0.69992| HIT@10: 0.17379: 100%|██████████| 1/1 [00:06<00:00,  6.01s/it]\n","Epoch:  97| Train loss: 0.01464| NDCG@10: 0.70244| HIT@10: 0.17373: 100%|██████████| 1/1 [00:05<00:00,  5.93s/it]\n","Epoch:  98| Train loss: 0.01464| NDCG@10: 0.70301| HIT@10: 0.17411: 100%|██████████| 1/1 [00:05<00:00,  5.87s/it]\n","Epoch:  99| Train loss: 0.01464| NDCG@10: 0.69918| HIT@10: 0.17371: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n","Epoch: 100| Train loss: 0.01464| NDCG@10: 0.69940| HIT@10: 0.17386: 100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n","Epoch: 101| Train loss: 0.01465| NDCG@10: 0.69952| HIT@10: 0.17401: 100%|██████████| 1/1 [00:06<00:00,  6.26s/it]\n","Epoch: 102| Train loss: 0.01464| NDCG@10: 0.70280| HIT@10: 0.17432: 100%|██████████| 1/1 [00:06<00:00,  6.13s/it]\n","Epoch: 103| Train loss: 0.01464| NDCG@10: 0.70076| HIT@10: 0.17392: 100%|██████████| 1/1 [00:05<00:00,  5.75s/it]\n","Epoch: 104| Train loss: 0.01463| NDCG@10: 0.69746| HIT@10: 0.17327: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it]\n","Epoch: 105| Train loss: 0.01463| NDCG@10: 0.69926| HIT@10: 0.17394: 100%|██████████| 1/1 [00:05<00:00,  5.95s/it]\n","Epoch: 106| Train loss: 0.01463| NDCG@10: 0.70078| HIT@10: 0.17381: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch: 107| Train loss: 0.01463| NDCG@10: 0.70066| HIT@10: 0.17393: 100%|██████████| 1/1 [00:05<00:00,  5.92s/it]\n","Epoch: 108| Train loss: 0.01463| NDCG@10: 0.70148| HIT@10: 0.17413: 100%|██████████| 1/1 [00:06<00:00,  6.59s/it]\n","Epoch: 109| Train loss: 0.01463| NDCG@10: 0.70258| HIT@10: 0.17461: 100%|██████████| 1/1 [00:05<00:00,  5.80s/it]\n","Epoch: 110| Train loss: 0.01463| NDCG@10: 0.69943| HIT@10: 0.17364: 100%|██████████| 1/1 [00:05<00:00,  5.79s/it]\n","Epoch: 111| Train loss: 0.01463| NDCG@10: 0.69696| HIT@10: 0.17329: 100%|██████████| 1/1 [00:05<00:00,  5.89s/it]\n","Epoch: 112| Train loss: 0.01464| NDCG@10: 0.69938| HIT@10: 0.17358: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n","Epoch: 113| Train loss: 0.01465| NDCG@10: 0.70047| HIT@10: 0.17396: 100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n","Epoch: 114| Train loss: 0.01463| NDCG@10: 0.70146| HIT@10: 0.17412: 100%|██████████| 1/1 [00:05<00:00,  5.96s/it]\n","Epoch: 115| Train loss: 0.01463| NDCG@10: 0.70248| HIT@10: 0.17410: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch: 116| Train loss: 0.01462| NDCG@10: 0.70046| HIT@10: 0.17403: 100%|██████████| 1/1 [00:06<00:00,  6.32s/it]\n","Epoch: 117| Train loss: 0.01463| NDCG@10: 0.70148| HIT@10: 0.17400: 100%|██████████| 1/1 [00:05<00:00,  5.89s/it]\n","Epoch: 118| Train loss: 0.01464| NDCG@10: 0.69971| HIT@10: 0.17386: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n","Epoch: 119| Train loss: 0.01464| NDCG@10: 0.70466| HIT@10: 0.17440: 100%|██████████| 1/1 [00:05<00:00,  5.92s/it]\n","Epoch: 120| Train loss: 0.01462| NDCG@10: 0.70199| HIT@10: 0.17430: 100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n","Epoch: 121| Train loss: 0.01462| NDCG@10: 0.70052| HIT@10: 0.17382: 100%|██████████| 1/1 [00:06<00:00,  6.43s/it]\n","Epoch: 122| Train loss: 0.01462| NDCG@10: 0.70285| HIT@10: 0.17443: 100%|██████████| 1/1 [00:05<00:00,  5.88s/it]\n","Epoch: 123| Train loss: 0.01462| NDCG@10: 0.69869| HIT@10: 0.17342: 100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n","Epoch: 124| Train loss: 0.01461| NDCG@10: 0.70240| HIT@10: 0.17400: 100%|██████████| 1/1 [00:06<00:00,  6.48s/it]\n","Epoch: 125| Train loss: 0.01461| NDCG@10: 0.70111| HIT@10: 0.17410: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n","Epoch: 126| Train loss: 0.01462| NDCG@10: 0.70386| HIT@10: 0.17419: 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]\n","Epoch: 127| Train loss: 0.01462| NDCG@10: 0.69841| HIT@10: 0.17373: 100%|██████████| 1/1 [00:06<00:00,  6.39s/it]\n","Epoch: 128| Train loss: 0.01462| NDCG@10: 0.70088| HIT@10: 0.17375: 100%|██████████| 1/1 [00:06<00:00,  6.16s/it]\n","Epoch: 129| Train loss: 0.01462| NDCG@10: 0.70231| HIT@10: 0.17444: 100%|██████████| 1/1 [00:05<00:00,  5.93s/it]\n","Epoch: 130| Train loss: 0.01462| NDCG@10: 0.69990| HIT@10: 0.17378: 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]\n","Epoch: 131| Train loss: 0.01462| NDCG@10: 0.70021| HIT@10: 0.17366: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n","Epoch: 132| Train loss: 0.01462| NDCG@10: 0.69940| HIT@10: 0.17400: 100%|██████████| 1/1 [00:05<00:00,  5.72s/it]\n","Epoch: 133| Train loss: 0.01461| NDCG@10: 0.70361| HIT@10: 0.17454: 100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n","Epoch: 134| Train loss: 0.01462| NDCG@10: 0.69700| HIT@10: 0.17345: 100%|██████████| 1/1 [00:06<00:00,  6.24s/it]\n","Epoch: 135| Train loss: 0.01462| NDCG@10: 0.70092| HIT@10: 0.17434: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch: 136| Train loss: 0.01461| NDCG@10: 0.70176| HIT@10: 0.17370: 100%|██████████| 1/1 [00:06<00:00,  6.19s/it]\n","Epoch: 137| Train loss: 0.01462| NDCG@10: 0.70114| HIT@10: 0.17391: 100%|██████████| 1/1 [00:05<00:00,  5.71s/it]\n","Epoch: 138| Train loss: 0.01461| NDCG@10: 0.69894| HIT@10: 0.17367: 100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n","Epoch: 139| Train loss: 0.01462| NDCG@10: 0.69839| HIT@10: 0.17284: 100%|██████████| 1/1 [00:05<00:00,  5.96s/it]\n","Epoch: 140| Train loss: 0.01461| NDCG@10: 0.70291| HIT@10: 0.17459: 100%|██████████| 1/1 [00:05<00:00,  5.61s/it]\n","Epoch: 141| Train loss: 0.01461| NDCG@10: 0.70003| HIT@10: 0.17380: 100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n","Epoch: 142| Train loss: 0.01462| NDCG@10: 0.70076| HIT@10: 0.17405: 100%|██████████| 1/1 [00:05<00:00,  5.94s/it]\n","Epoch: 143| Train loss: 0.01460| NDCG@10: 0.70140| HIT@10: 0.17433: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch: 144| Train loss: 0.01462| NDCG@10: 0.69672| HIT@10: 0.17299: 100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n","Epoch: 145| Train loss: 0.01462| NDCG@10: 0.69932| HIT@10: 0.17346: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n","Epoch: 146| Train loss: 0.01461| NDCG@10: 0.69969| HIT@10: 0.17384: 100%|██████████| 1/1 [00:06<00:00,  6.14s/it]\n","Epoch: 147| Train loss: 0.01461| NDCG@10: 0.70286| HIT@10: 0.17473: 100%|██████████| 1/1 [00:06<00:00,  6.11s/it]\n","Epoch: 148| Train loss: 0.01460| NDCG@10: 0.70090| HIT@10: 0.17384: 100%|██████████| 1/1 [00:06<00:00,  6.07s/it]\n","Epoch: 149| Train loss: 0.01461| NDCG@10: 0.69967| HIT@10: 0.17392: 100%|██████████| 1/1 [00:06<00:00,  6.17s/it]\n","Epoch: 150| Train loss: 0.01461| NDCG@10: 0.69950| HIT@10: 0.17392: 100%|██████████| 1/1 [00:05<00:00,  5.74s/it]\n","Epoch: 151| Train loss: 0.01461| NDCG@10: 0.69989| HIT@10: 0.17375: 100%|██████████| 1/1 [00:05<00:00,  5.70s/it]\n","Epoch: 152| Train loss: 0.01461| NDCG@10: 0.70441| HIT@10: 0.17444: 100%|██████████| 1/1 [00:06<00:00,  6.00s/it]\n","Epoch: 153| Train loss: 0.01460| NDCG@10: 0.70425| HIT@10: 0.17455: 100%|██████████| 1/1 [00:05<00:00,  5.90s/it]\n","Epoch: 154| Train loss: 0.01460| NDCG@10: 0.70358| HIT@10: 0.17436: 100%|██████████| 1/1 [00:05<00:00,  5.86s/it]\n","Epoch: 155| Train loss: 0.01460| NDCG@10: 0.69883| HIT@10: 0.17373: 100%|██████████| 1/1 [00:06<00:00,  6.32s/it]\n","Epoch: 156| Train loss: 0.01460| NDCG@10: 0.69614| HIT@10: 0.17286: 100%|██████████| 1/1 [00:06<00:00,  6.33s/it]\n","Epoch: 157| Train loss: 0.01460| NDCG@10: 0.69932| HIT@10: 0.17392: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n","Epoch: 158| Train loss: 0.01459| NDCG@10: 0.69916| HIT@10: 0.17379: 100%|██████████| 1/1 [00:06<00:00,  6.23s/it]\n","Epoch: 159| Train loss: 0.01461| NDCG@10: 0.69841| HIT@10: 0.17387: 100%|██████████| 1/1 [00:06<00:00,  6.32s/it]\n","Epoch: 160| Train loss: 0.01460| NDCG@10: 0.70160| HIT@10: 0.17387: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n","Epoch: 161| Train loss: 0.01461| NDCG@10: 0.70077| HIT@10: 0.17396: 100%|██████████| 1/1 [00:06<00:00,  6.28s/it]\n","Epoch: 162| Train loss: 0.01461| NDCG@10: 0.70168| HIT@10: 0.17450: 100%|██████████| 1/1 [00:06<00:00,  6.46s/it]\n","Epoch: 163| Train loss: 0.01461| NDCG@10: 0.70000| HIT@10: 0.17338: 100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n","Epoch: 164| Train loss: 0.01460| NDCG@10: 0.70177| HIT@10: 0.17454: 100%|██████████| 1/1 [00:06<00:00,  6.27s/it]\n","Epoch: 165| Train loss: 0.01460| NDCG@10: 0.69874| HIT@10: 0.17321: 100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n","Epoch: 166| Train loss: 0.01459| NDCG@10: 0.70197| HIT@10: 0.17417: 100%|██████████| 1/1 [00:06<00:00,  6.61s/it]\n","Epoch: 167| Train loss: 0.01460| NDCG@10: 0.70098| HIT@10: 0.17412: 100%|██████████| 1/1 [00:06<00:00,  6.30s/it]\n","Epoch: 168| Train loss: 0.01461| NDCG@10: 0.69876| HIT@10: 0.17373: 100%|██████████| 1/1 [00:06<00:00,  6.16s/it]\n","Epoch: 169| Train loss: 0.01460| NDCG@10: 0.70099| HIT@10: 0.17357: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n","Epoch: 170| Train loss: 0.01459| NDCG@10: 0.70554| HIT@10: 0.17476: 100%|██████████| 1/1 [00:06<00:00,  6.15s/it]\n","Epoch: 171| Train loss: 0.01460| NDCG@10: 0.69975| HIT@10: 0.17393: 100%|██████████| 1/1 [00:06<00:00,  6.27s/it]\n","Epoch: 172| Train loss: 0.01460| NDCG@10: 0.70365| HIT@10: 0.17474: 100%|██████████| 1/1 [00:06<00:00,  6.01s/it]\n","Epoch: 173| Train loss: 0.01460| NDCG@10: 0.70159| HIT@10: 0.17415: 100%|██████████| 1/1 [00:05<00:00,  5.70s/it]\n","Epoch: 174| Train loss: 0.01460| NDCG@10: 0.70021| HIT@10: 0.17405: 100%|██████████| 1/1 [00:05<00:00,  5.95s/it]\n","Epoch: 175| Train loss: 0.01459| NDCG@10: 0.70026| HIT@10: 0.17393: 100%|██████████| 1/1 [00:05<00:00,  5.66s/it]\n","Epoch: 176| Train loss: 0.01459| NDCG@10: 0.70225| HIT@10: 0.17386: 100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n","Epoch: 177| Train loss: 0.01459| NDCG@10: 0.70220| HIT@10: 0.17444: 100%|██████████| 1/1 [00:05<00:00,  5.82s/it]\n","Epoch: 178| Train loss: 0.01459| NDCG@10: 0.70308| HIT@10: 0.17405: 100%|██████████| 1/1 [00:06<00:00,  6.22s/it]\n","Epoch: 179| Train loss: 0.01459| NDCG@10: 0.70262| HIT@10: 0.17455: 100%|██████████| 1/1 [00:06<00:00,  6.18s/it]\n","Epoch: 180| Train loss: 0.01459| NDCG@10: 0.70122| HIT@10: 0.17405: 100%|██████████| 1/1 [00:05<00:00,  5.86s/it]\n","Epoch: 181| Train loss: 0.01458| NDCG@10: 0.69931| HIT@10: 0.17390: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n","Epoch: 182| Train loss: 0.01460| NDCG@10: 0.69872| HIT@10: 0.17337: 100%|██████████| 1/1 [00:06<00:00,  6.11s/it]\n","Epoch: 183| Train loss: 0.01460| NDCG@10: 0.69895| HIT@10: 0.17379: 100%|██████████| 1/1 [00:05<00:00,  5.76s/it]\n","Epoch: 184| Train loss: 0.01460| NDCG@10: 0.70026| HIT@10: 0.17396: 100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n","Epoch: 185| Train loss: 0.01460| NDCG@10: 0.69931| HIT@10: 0.17363: 100%|██████████| 1/1 [00:05<00:00,  5.86s/it]\n","Epoch: 186| Train loss: 0.01458| NDCG@10: 0.70258| HIT@10: 0.17455: 100%|██████████| 1/1 [00:06<00:00,  6.11s/it]\n","Epoch: 187| Train loss: 0.01459| NDCG@10: 0.69891| HIT@10: 0.17383: 100%|██████████| 1/1 [00:06<00:00,  6.28s/it]\n","Epoch: 188| Train loss: 0.01460| NDCG@10: 0.70337| HIT@10: 0.17443: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n","Epoch: 189| Train loss: 0.01459| NDCG@10: 0.70470| HIT@10: 0.17467: 100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n","Epoch: 190| Train loss: 0.01459| NDCG@10: 0.69877| HIT@10: 0.17398: 100%|██████████| 1/1 [00:05<00:00,  5.92s/it]\n","Epoch: 191| Train loss: 0.01459| NDCG@10: 0.69746| HIT@10: 0.17310: 100%|██████████| 1/1 [00:06<00:00,  6.24s/it]\n","Epoch: 192| Train loss: 0.01458| NDCG@10: 0.69988| HIT@10: 0.17416: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n","Epoch: 193| Train loss: 0.01459| NDCG@10: 0.70203| HIT@10: 0.17401: 100%|██████████| 1/1 [00:05<00:00,  5.67s/it]\n","Epoch: 194| Train loss: 0.01459| NDCG@10: 0.70319| HIT@10: 0.17438: 100%|██████████| 1/1 [00:06<00:00,  6.20s/it]\n","Epoch: 195| Train loss: 0.01460| NDCG@10: 0.70118| HIT@10: 0.17443: 100%|██████████| 1/1 [00:05<00:00,  5.93s/it]\n","Epoch: 196| Train loss: 0.01459| NDCG@10: 0.70511| HIT@10: 0.17434: 100%|██████████| 1/1 [00:06<00:00,  6.13s/it]\n","Epoch: 197| Train loss: 0.01458| NDCG@10: 0.70357| HIT@10: 0.17454: 100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n","Epoch: 198| Train loss: 0.01458| NDCG@10: 0.70226| HIT@10: 0.17445: 100%|██████████| 1/1 [00:05<00:00,  5.95s/it]\n","Epoch: 199| Train loss: 0.01458| NDCG@10: 0.70310| HIT@10: 0.17414: 100%|██████████| 1/1 [00:06<00:00,  6.10s/it]\n","Epoch: 200| Train loss: 0.01458| NDCG@10: 0.69689| HIT@10: 0.17336: 100%|██████████| 1/1 [00:07<00:00,  7.19s/it]\n"]}],"source":["best_hit = 0\n","for epoch in range(1, config.num_epochs + 1):\n","    tbar = tqdm(range(1))\n","    for _ in tbar:\n","        train_loss = train(\n","            model = model, \n","            criterion = criterion, \n","            optimizer = optimizer, \n","            data_loader = data_loader,\n","            make_matrix_data_set = make_matrix_data_set\n","            )\n","        \n","        ndcg, hit = evaluate(\n","            model = model,\n","            data_loader = data_loader,\n","            user_train = user_train,\n","            user_valid = user_valid,\n","            make_matrix_data_set = make_matrix_data_set,\n","            )\n","\n","        if best_hit < hit:\n","            best_hit = hit\n","            torch.save(model.state_dict(), os.path.join(config.model_path, config.model_name))\n","\n","        tbar.set_description(f'Epoch: {epoch:3d}| Train loss: {train_loss:.5f}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["# 6. 예측"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["model.load_state_dict(torch.load(os.path.join(config.model_path, config.model_name)))\n","\n","submission_data_loader = DataLoader(\n","    ae_dataset,\n","    batch_size = config.batch_size, \n","    shuffle = False, \n","    pin_memory = True,\n","    num_workers = config.num_workers,\n","    )\n","\n","user2rec_list = predict(\n","    model = model, \n","    data_loader = submission_data_loader,\n","    user_train = user_train, \n","    user_valid = user_valid, \n","    make_matrix_data_set = make_matrix_data_set\n","    )\n","\n","submision = []\n","users = [i for i in range(0, make_matrix_data_set.num_user)]\n","for user in users:\n","    rec_item_list = user2rec_list[user]\n","    for item in rec_item_list:\n","        submision.append(\n","            {   \n","                'user' : make_matrix_data_set.user_decoder[user],\n","                'item' : make_matrix_data_set.item_decoder[item],\n","            }\n","        )\n","\n","submision = pd.DataFrame(submision)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["submision.to_csv(os.path.join(config.submission_path, config.submission_name), index=False)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>5218</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>8360</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>6373</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>924</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>313595</th>\n","      <td>138493</td>\n","      <td>7147</td>\n","    </tr>\n","    <tr>\n","      <th>313596</th>\n","      <td>138493</td>\n","      <td>1270</td>\n","    </tr>\n","    <tr>\n","      <th>313597</th>\n","      <td>138493</td>\n","      <td>551</td>\n","    </tr>\n","    <tr>\n","      <th>313598</th>\n","      <td>138493</td>\n","      <td>32587</td>\n","    </tr>\n","    <tr>\n","      <th>313599</th>\n","      <td>138493</td>\n","      <td>8961</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>313600 rows × 2 columns</p>\n","</div>"],"text/plain":["          user   item\n","0           11   5218\n","1           11      2\n","2           11   8360\n","3           11   6373\n","4           11    924\n","...        ...    ...\n","313595  138493   7147\n","313596  138493   1270\n","313597  138493    551\n","313598  138493  32587\n","313599  138493   8961\n","\n","[313600 rows x 2 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["submision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMuMyJZEVeJ9IVfHX0fvKVf","collapsed_sections":[],"mount_file_id":"1NR3Q7bKCQaa_LqFUlzXBLu6wIPXHGkAn","name":"AutoRec-for-implicit-feedback.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
